{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GM-VAE for SMBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGzTb0oswH5J"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThVeaB3CwI4j"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yangz2/projects/gmvae_and_gmmvae/pytorch/')\n",
    "sys.path.append('../../1906-pcgml/pcgml-gmmVae-exp/modules/')\n",
    "import vglc_with_path_encodings\n",
    "\n",
    "sys.path.append('../experiments')\n",
    "import smba_gmprior_effect_on_rec\n",
    "\n",
    "from model.GMVAE import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json_as_nparray(json_fname):\n",
    "    with open(json_fname, 'r') as json_f:\n",
    "        return np.array(json.load(json_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SMB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smb_int = open_json_as_nparray('smbWithPath-allLevels-chunks-int.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 16, 16, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = np.eye(len(np.unique(smb_int)))[smb_int]\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = smb_onehot.reshape(\n",
    "    smb_onehot.shape[0], \n",
    "    smb_onehot.shape[1] * smb_onehot.shape[2] * smb_onehot.shape[3]\n",
    ")\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2698,),\n",
       " array([ 6, 19, 14, 10,  7, 20,  6, 25, 18, 22, 10, 10, 23, 20,  3,  7, 23,\n",
       "         2, 21, 20]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "smb_labels = np.random.randint(num_components, size=smb_onehot.shape[0])\n",
    "smb_labels.shape, smb_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, labels = smb_onehot, smb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(num_components), np.bincount(smb_labels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QNKItMHwQU2"
   },
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tBHkTQ4wVIG"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Input Parameters\n",
    "#########################################################\n",
    "parser = argparse.ArgumentParser(description='PyTorch Implementation of DGM Clustering')\n",
    "\n",
    "## Used only in notebooks\n",
    "parser.add_argument('-f', '--file',\n",
    "                    help='Path for input file. First line should contain number of lines to search in')\n",
    "\n",
    "## Dataset\n",
    "parser.add_argument('--dataset', type=str, choices=['mnist'],\n",
    "                    default='mnist', help='dataset (default: mnist)')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "\n",
    "## GPU\n",
    "parser.add_argument('--cuda', type=int, default=1,\n",
    "                    help='use of cuda (default: 1)')\n",
    "parser.add_argument('--gpuID', type=int, default=0,\n",
    "                    help='set gpu id to use (default: 0)')\n",
    "\n",
    "## Training\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of total epochs to run (default: 200)')\n",
    "parser.add_argument('--batch_size', default=64, type=int,\n",
    "                    help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--batch_size_val', default=200, type=int,\n",
    "                    help='mini-batch size of validation (default: 200)')\n",
    "parser.add_argument('--learning_rate', default=1e-3, type=float,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay_epoch', default=-1, type=int, \n",
    "                    help='Reduces the learning rate every decay_epoch')\n",
    "parser.add_argument('--lr_decay', default=0.5, type=float,\n",
    "                    help='Learning rate decay for training (default: 0.5)')\n",
    "\n",
    "## Architecture\n",
    "parser.add_argument('--num_classes', type=int, default=num_components,\n",
    "                    help='number of classes (default: 10)')  # edited for this task\n",
    "parser.add_argument('--gaussian_size', default=64, type=int,\n",
    "                    help='gaussian size (default: 64)')\n",
    "parser.add_argument('--input_size', default=3072, type=int,\n",
    "                    help='input size (default: 784)')  # edited for this task\n",
    "\n",
    "## Partition parameters\n",
    "parser.add_argument('--train_proportion', default=0.9, type=float,\n",
    "                    help='proportion of examples to consider for training only (default: 1.0)')\n",
    "\n",
    "## Gumbel parameters\n",
    "parser.add_argument('--init_temp', default=1.0, type=float,\n",
    "                    help='Initial temperature used in gumbel-softmax (recommended 0.5-1.0, default:1.0)')\n",
    "parser.add_argument('--decay_temp', default=1, type=int, \n",
    "                    help='Set 1 to decay gumbel temperature at every epoch (default: 1)')\n",
    "parser.add_argument('--hard_gumbel', default=0, type=int, \n",
    "                    help='Set 1 to use the hard version of gumbel-softmax (default: 1)')\n",
    "parser.add_argument('--min_temp', default=0.5, type=float, \n",
    "                    help='Minimum temperature of gumbel-softmax after annealing (default: 0.5)' )\n",
    "parser.add_argument('--decay_temp_rate', default=0.013862944, type=float,\n",
    "                    help='Temperature decay rate at every epoch (default: 0.013862944)')\n",
    "\n",
    "## Loss function parameters\n",
    "parser.add_argument('--w_gauss', default=2, type=float,\n",
    "                    help='weight of gaussian loss (default: 1)')\n",
    "parser.add_argument('--w_categ', default=1, type=float,\n",
    "                    help='weight of categorical loss (default: 1)')\n",
    "parser.add_argument('--w_rec', default=1, type=float,\n",
    "                    help='weight of reconstruction loss (default: 1)')\n",
    "parser.add_argument('--rec_type', type=str, choices=['bce', 'mse'],\n",
    "                    default='bce', help='desired reconstruction loss function (default: bce)')\n",
    "\n",
    "## Others\n",
    "parser.add_argument('--verbose', default=0, type=int,\n",
    "                    help='print extra information at every epoch.(default: 0)')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bti6lPHawc9z"
   },
   "source": [
    "Set random seed in case it was specified in the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpWPxTy1wgbJ"
   },
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "SEED = args.seed\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmrkmhttwkiD"
   },
   "source": [
    "## Data Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUuTFMBhb2vZ"
   },
   "source": [
    "We split the training data into train and validation according to the *train_proportion* parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.train_proportion != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8F6pjC7cNX7"
   },
   "outputs": [],
   "source": [
    "def partition_dataset(n, proportion=1):\n",
    "   train_num = int(n * proportion)\n",
    "   indices = np.random.permutation(n)\n",
    "   train_indices, val_indices = indices[:train_num], indices[train_num:]\n",
    "   return train_indices, val_indices\n",
    "\n",
    "train_indices, val_indices = partition_dataset(len(chunks), args.train_proportion)\n",
    "train_ds = TensorDataset(torch.from_numpy(chunks).float(), torch.from_numpy(labels).long())\n",
    "train_dl = DataLoader(train_ds, batch_size=args.batch_size, sampler=SubsetRandomSampler(train_indices))\n",
    "valid_dl = DataLoader(train_ds, batch_size=args.batch_size_val, sampler=SubsetRandomSampler(val_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pt7sEfZWw_U7"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTncRSCuxFEL"
   },
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "gmvae = GMVAE(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1 / 100) Train_Loss: 471.728; Val_Loss: 237.428   Train_ACC: 7.002; Val_ACC: 5.556   Train_NMI: 3.039; Val_NMI: 0.000\n",
      "(Epoch 2 / 100) Train_Loss: 229.567; Val_Loss: 233.236   Train_ACC: 5.766; Val_ACC: 8.148   Train_NMI: 1.391; Val_NMI: 8.559\n",
      "(Epoch 3 / 100) Train_Loss: 225.393; Val_Loss: 223.853   Train_ACC: 6.425; Val_ACC: 6.667   Train_NMI: 3.541; Val_NMI: 2.776\n",
      "(Epoch 4 / 100) Train_Loss: 222.327; Val_Loss: 224.123   Train_ACC: 5.643; Val_ACC: 7.037   Train_NMI: 1.976; Val_NMI: 5.546\n",
      "(Epoch 5 / 100) Train_Loss: 215.659; Val_Loss: 217.622   Train_ACC: 5.848; Val_ACC: 8.889   Train_NMI: 2.606; Val_NMI: 10.253\n",
      "(Epoch 6 / 100) Train_Loss: 212.333; Val_Loss: 217.707   Train_ACC: 6.013; Val_ACC: 8.519   Train_NMI: 3.104; Val_NMI: 8.510\n",
      "(Epoch 7 / 100) Train_Loss: 209.201; Val_Loss: 206.997   Train_ACC: 5.807; Val_ACC: 9.630   Train_NMI: 2.381; Val_NMI: 11.429\n",
      "(Epoch 8 / 100) Train_Loss: 204.463; Val_Loss: 204.126   Train_ACC: 5.684; Val_ACC: 10.370   Train_NMI: 2.123; Val_NMI: 12.279\n",
      "(Epoch 9 / 100) Train_Loss: 202.389; Val_Loss: 206.998   Train_ACC: 5.725; Val_ACC: 8.519   Train_NMI: 2.315; Val_NMI: 9.715\n",
      "(Epoch 10 / 100) Train_Loss: 198.674; Val_Loss: 198.743   Train_ACC: 5.807; Val_ACC: 11.111   Train_NMI: 2.633; Val_NMI: 14.005\n",
      "(Epoch 11 / 100) Train_Loss: 196.290; Val_Loss: 202.989   Train_ACC: 6.096; Val_ACC: 10.741   Train_NMI: 2.680; Val_NMI: 14.937\n",
      "(Epoch 12 / 100) Train_Loss: 194.197; Val_Loss: 200.072   Train_ACC: 6.178; Val_ACC: 11.481   Train_NMI: 2.316; Val_NMI: 16.526\n",
      "(Epoch 13 / 100) Train_Loss: 192.194; Val_Loss: 198.960   Train_ACC: 6.384; Val_ACC: 12.222   Train_NMI: 2.899; Val_NMI: 15.619\n",
      "(Epoch 14 / 100) Train_Loss: 190.410; Val_Loss: 189.535   Train_ACC: 5.972; Val_ACC: 11.852   Train_NMI: 2.511; Val_NMI: 15.758\n",
      "(Epoch 15 / 100) Train_Loss: 189.292; Val_Loss: 196.420   Train_ACC: 6.054; Val_ACC: 10.741   Train_NMI: 2.523; Val_NMI: 13.525\n",
      "(Epoch 16 / 100) Train_Loss: 186.450; Val_Loss: 194.863   Train_ACC: 6.384; Val_ACC: 10.741   Train_NMI: 2.563; Val_NMI: 12.590\n",
      "(Epoch 17 / 100) Train_Loss: 184.169; Val_Loss: 193.143   Train_ACC: 6.672; Val_ACC: 10.741   Train_NMI: 3.398; Val_NMI: 16.357\n",
      "(Epoch 18 / 100) Train_Loss: 182.359; Val_Loss: 191.700   Train_ACC: 6.507; Val_ACC: 12.963   Train_NMI: 2.823; Val_NMI: 16.499\n",
      "(Epoch 19 / 100) Train_Loss: 179.764; Val_Loss: 187.272   Train_ACC: 6.466; Val_ACC: 12.963   Train_NMI: 2.672; Val_NMI: 17.786\n",
      "(Epoch 20 / 100) Train_Loss: 176.769; Val_Loss: 189.592   Train_ACC: 6.260; Val_ACC: 13.704   Train_NMI: 3.034; Val_NMI: 20.202\n",
      "(Epoch 21 / 100) Train_Loss: 174.749; Val_Loss: 184.169   Train_ACC: 6.755; Val_ACC: 13.333   Train_NMI: 2.764; Val_NMI: 20.198\n",
      "(Epoch 22 / 100) Train_Loss: 173.064; Val_Loss: 180.017   Train_ACC: 6.796; Val_ACC: 12.963   Train_NMI: 3.697; Val_NMI: 18.865\n",
      "(Epoch 23 / 100) Train_Loss: 171.235; Val_Loss: 181.898   Train_ACC: 6.755; Val_ACC: 12.963   Train_NMI: 3.527; Val_NMI: 19.825\n",
      "(Epoch 24 / 100) Train_Loss: 170.084; Val_Loss: 186.604   Train_ACC: 6.672; Val_ACC: 11.852   Train_NMI: 3.332; Val_NMI: 17.408\n",
      "(Epoch 25 / 100) Train_Loss: 168.662; Val_Loss: 179.181   Train_ACC: 6.507; Val_ACC: 12.222   Train_NMI: 3.442; Val_NMI: 17.666\n",
      "(Epoch 26 / 100) Train_Loss: 167.251; Val_Loss: 173.087   Train_ACC: 6.631; Val_ACC: 11.852   Train_NMI: 3.457; Val_NMI: 17.777\n",
      "(Epoch 27 / 100) Train_Loss: 165.378; Val_Loss: 174.609   Train_ACC: 6.466; Val_ACC: 13.704   Train_NMI: 2.609; Val_NMI: 21.080\n",
      "(Epoch 28 / 100) Train_Loss: 165.119; Val_Loss: 174.780   Train_ACC: 6.425; Val_ACC: 12.222   Train_NMI: 3.187; Val_NMI: 18.348\n",
      "(Epoch 29 / 100) Train_Loss: 163.265; Val_Loss: 172.871   Train_ACC: 6.549; Val_ACC: 13.704   Train_NMI: 3.158; Val_NMI: 18.271\n",
      "(Epoch 30 / 100) Train_Loss: 161.756; Val_Loss: 176.396   Train_ACC: 6.631; Val_ACC: 14.444   Train_NMI: 3.859; Val_NMI: 20.863\n",
      "(Epoch 31 / 100) Train_Loss: 161.717; Val_Loss: 174.114   Train_ACC: 7.084; Val_ACC: 12.593   Train_NMI: 3.972; Val_NMI: 18.928\n",
      "(Epoch 32 / 100) Train_Loss: 160.940; Val_Loss: 171.495   Train_ACC: 6.713; Val_ACC: 14.074   Train_NMI: 3.769; Val_NMI: 20.896\n",
      "(Epoch 33 / 100) Train_Loss: 159.670; Val_Loss: 171.666   Train_ACC: 6.466; Val_ACC: 13.704   Train_NMI: 3.583; Val_NMI: 21.669\n",
      "(Epoch 34 / 100) Train_Loss: 158.463; Val_Loss: 173.054   Train_ACC: 6.507; Val_ACC: 12.963   Train_NMI: 3.140; Val_NMI: 17.658\n",
      "(Epoch 35 / 100) Train_Loss: 157.350; Val_Loss: 172.152   Train_ACC: 6.878; Val_ACC: 14.815   Train_NMI: 4.016; Val_NMI: 20.885\n",
      "(Epoch 36 / 100) Train_Loss: 156.637; Val_Loss: 169.058   Train_ACC: 6.672; Val_ACC: 13.704   Train_NMI: 3.407; Val_NMI: 20.474\n",
      "(Epoch 37 / 100) Train_Loss: 155.147; Val_Loss: 169.930   Train_ACC: 6.631; Val_ACC: 13.704   Train_NMI: 3.456; Val_NMI: 20.673\n",
      "(Epoch 38 / 100) Train_Loss: 153.961; Val_Loss: 161.873   Train_ACC: 6.755; Val_ACC: 14.074   Train_NMI: 3.557; Val_NMI: 21.166\n",
      "(Epoch 39 / 100) Train_Loss: 152.625; Val_Loss: 171.993   Train_ACC: 6.301; Val_ACC: 13.704   Train_NMI: 3.202; Val_NMI: 20.596\n",
      "(Epoch 40 / 100) Train_Loss: 152.300; Val_Loss: 165.061   Train_ACC: 6.796; Val_ACC: 13.704   Train_NMI: 3.850; Val_NMI: 20.921\n",
      "(Epoch 41 / 100) Train_Loss: 151.274; Val_Loss: 163.892   Train_ACC: 6.878; Val_ACC: 13.704   Train_NMI: 4.013; Val_NMI: 22.028\n",
      "(Epoch 42 / 100) Train_Loss: 150.596; Val_Loss: 165.957   Train_ACC: 6.672; Val_ACC: 14.074   Train_NMI: 3.980; Val_NMI: 22.570\n",
      "(Epoch 43 / 100) Train_Loss: 148.552; Val_Loss: 158.902   Train_ACC: 6.960; Val_ACC: 15.556   Train_NMI: 3.909; Val_NMI: 22.896\n",
      "(Epoch 44 / 100) Train_Loss: 147.068; Val_Loss: 166.738   Train_ACC: 6.837; Val_ACC: 14.444   Train_NMI: 3.858; Val_NMI: 21.248\n",
      "(Epoch 45 / 100) Train_Loss: 147.261; Val_Loss: 162.307   Train_ACC: 6.590; Val_ACC: 14.074   Train_NMI: 3.489; Val_NMI: 22.804\n",
      "(Epoch 46 / 100) Train_Loss: 145.327; Val_Loss: 160.889   Train_ACC: 6.960; Val_ACC: 14.815   Train_NMI: 3.532; Val_NMI: 22.662\n",
      "(Epoch 47 / 100) Train_Loss: 144.351; Val_Loss: 165.626   Train_ACC: 6.590; Val_ACC: 14.074   Train_NMI: 2.913; Val_NMI: 21.237\n",
      "(Epoch 48 / 100) Train_Loss: 142.803; Val_Loss: 161.484   Train_ACC: 6.755; Val_ACC: 13.704   Train_NMI: 3.476; Val_NMI: 21.010\n",
      "(Epoch 49 / 100) Train_Loss: 142.257; Val_Loss: 159.024   Train_ACC: 7.002; Val_ACC: 14.444   Train_NMI: 4.113; Val_NMI: 21.259\n",
      "(Epoch 50 / 100) Train_Loss: 141.554; Val_Loss: 162.432   Train_ACC: 7.084; Val_ACC: 13.704   Train_NMI: 4.183; Val_NMI: 21.942\n",
      "(Epoch 51 / 100) Train_Loss: 140.180; Val_Loss: 159.701   Train_ACC: 7.166; Val_ACC: 15.185   Train_NMI: 3.774; Val_NMI: 23.271\n",
      "(Epoch 52 / 100) Train_Loss: 139.527; Val_Loss: 155.672   Train_ACC: 7.043; Val_ACC: 15.556   Train_NMI: 4.340; Val_NMI: 23.469\n",
      "(Epoch 53 / 100) Train_Loss: 139.396; Val_Loss: 157.674   Train_ACC: 6.796; Val_ACC: 14.815   Train_NMI: 4.181; Val_NMI: 24.250\n",
      "(Epoch 54 / 100) Train_Loss: 138.108; Val_Loss: 158.294   Train_ACC: 7.208; Val_ACC: 14.815   Train_NMI: 4.231; Val_NMI: 23.520\n",
      "(Epoch 55 / 100) Train_Loss: 136.863; Val_Loss: 156.153   Train_ACC: 7.166; Val_ACC: 16.296   Train_NMI: 4.370; Val_NMI: 26.264\n",
      "(Epoch 56 / 100) Train_Loss: 136.496; Val_Loss: 161.970   Train_ACC: 6.590; Val_ACC: 15.926   Train_NMI: 3.663; Val_NMI: 23.928\n",
      "(Epoch 57 / 100) Train_Loss: 136.331; Val_Loss: 163.928   Train_ACC: 7.166; Val_ACC: 15.185   Train_NMI: 4.150; Val_NMI: 23.716\n",
      "(Epoch 58 / 100) Train_Loss: 134.822; Val_Loss: 157.697   Train_ACC: 6.755; Val_ACC: 15.556   Train_NMI: 3.731; Val_NMI: 23.219\n",
      "(Epoch 59 / 100) Train_Loss: 133.752; Val_Loss: 154.910   Train_ACC: 7.002; Val_ACC: 15.556   Train_NMI: 4.288; Val_NMI: 24.983\n",
      "(Epoch 60 / 100) Train_Loss: 133.943; Val_Loss: 155.536   Train_ACC: 7.043; Val_ACC: 14.444   Train_NMI: 4.040; Val_NMI: 23.071\n",
      "(Epoch 61 / 100) Train_Loss: 133.110; Val_Loss: 160.110   Train_ACC: 7.043; Val_ACC: 15.556   Train_NMI: 4.236; Val_NMI: 26.224\n",
      "(Epoch 62 / 100) Train_Loss: 132.575; Val_Loss: 157.394   Train_ACC: 7.208; Val_ACC: 15.185   Train_NMI: 4.277; Val_NMI: 23.801\n",
      "(Epoch 63 / 100) Train_Loss: 130.725; Val_Loss: 155.648   Train_ACC: 6.960; Val_ACC: 15.185   Train_NMI: 3.947; Val_NMI: 24.334\n",
      "(Epoch 64 / 100) Train_Loss: 130.497; Val_Loss: 155.966   Train_ACC: 7.208; Val_ACC: 14.074   Train_NMI: 3.835; Val_NMI: 25.052\n",
      "(Epoch 65 / 100) Train_Loss: 129.931; Val_Loss: 156.264   Train_ACC: 7.290; Val_ACC: 15.926   Train_NMI: 4.829; Val_NMI: 27.647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 66 / 100) Train_Loss: 128.546; Val_Loss: 155.044   Train_ACC: 6.919; Val_ACC: 14.815   Train_NMI: 4.075; Val_NMI: 25.876\n",
      "(Epoch 67 / 100) Train_Loss: 127.569; Val_Loss: 153.686   Train_ACC: 7.208; Val_ACC: 14.815   Train_NMI: 4.624; Val_NMI: 26.684\n",
      "(Epoch 68 / 100) Train_Loss: 127.469; Val_Loss: 160.249   Train_ACC: 7.125; Val_ACC: 15.556   Train_NMI: 4.199; Val_NMI: 25.092\n",
      "(Epoch 69 / 100) Train_Loss: 126.952; Val_Loss: 156.087   Train_ACC: 7.414; Val_ACC: 15.556   Train_NMI: 4.315; Val_NMI: 27.123\n",
      "(Epoch 70 / 100) Train_Loss: 125.905; Val_Loss: 156.353   Train_ACC: 7.166; Val_ACC: 15.556   Train_NMI: 4.094; Val_NMI: 25.719\n",
      "(Epoch 71 / 100) Train_Loss: 125.281; Val_Loss: 158.573   Train_ACC: 7.414; Val_ACC: 15.556   Train_NMI: 4.268; Val_NMI: 24.830\n",
      "(Epoch 72 / 100) Train_Loss: 124.804; Val_Loss: 159.132   Train_ACC: 6.919; Val_ACC: 15.926   Train_NMI: 4.046; Val_NMI: 27.677\n",
      "(Epoch 73 / 100) Train_Loss: 123.788; Val_Loss: 152.173   Train_ACC: 7.208; Val_ACC: 15.185   Train_NMI: 4.530; Val_NMI: 26.165\n",
      "(Epoch 74 / 100) Train_Loss: 122.653; Val_Loss: 152.627   Train_ACC: 7.043; Val_ACC: 15.556   Train_NMI: 4.275; Val_NMI: 26.070\n",
      "(Epoch 75 / 100) Train_Loss: 122.213; Val_Loss: 154.629   Train_ACC: 6.960; Val_ACC: 16.667   Train_NMI: 4.126; Val_NMI: 24.838\n",
      "(Epoch 76 / 100) Train_Loss: 122.140; Val_Loss: 161.473   Train_ACC: 6.960; Val_ACC: 15.185   Train_NMI: 4.212; Val_NMI: 25.068\n",
      "(Epoch 77 / 100) Train_Loss: 121.851; Val_Loss: 159.231   Train_ACC: 7.331; Val_ACC: 16.296   Train_NMI: 4.971; Val_NMI: 26.545\n",
      "(Epoch 78 / 100) Train_Loss: 121.159; Val_Loss: 156.954   Train_ACC: 7.537; Val_ACC: 15.926   Train_NMI: 4.409; Val_NMI: 26.760\n",
      "(Epoch 79 / 100) Train_Loss: 119.896; Val_Loss: 158.129   Train_ACC: 7.455; Val_ACC: 16.667   Train_NMI: 4.631; Val_NMI: 26.905\n",
      "(Epoch 80 / 100) Train_Loss: 119.003; Val_Loss: 156.144   Train_ACC: 7.249; Val_ACC: 15.556   Train_NMI: 4.396; Val_NMI: 26.503\n",
      "(Epoch 81 / 100) Train_Loss: 119.111; Val_Loss: 157.579   Train_ACC: 7.166; Val_ACC: 15.926   Train_NMI: 4.272; Val_NMI: 26.232\n",
      "(Epoch 82 / 100) Train_Loss: 117.611; Val_Loss: 156.179   Train_ACC: 7.496; Val_ACC: 15.556   Train_NMI: 4.461; Val_NMI: 25.691\n",
      "(Epoch 83 / 100) Train_Loss: 116.503; Val_Loss: 153.089   Train_ACC: 7.290; Val_ACC: 15.185   Train_NMI: 4.823; Val_NMI: 24.244\n",
      "(Epoch 84 / 100) Train_Loss: 116.046; Val_Loss: 158.605   Train_ACC: 7.331; Val_ACC: 15.926   Train_NMI: 4.344; Val_NMI: 25.051\n",
      "(Epoch 85 / 100) Train_Loss: 115.203; Val_Loss: 157.291   Train_ACC: 7.455; Val_ACC: 15.556   Train_NMI: 5.016; Val_NMI: 27.759\n",
      "(Epoch 86 / 100) Train_Loss: 114.978; Val_Loss: 162.068   Train_ACC: 7.414; Val_ACC: 15.556   Train_NMI: 4.403; Val_NMI: 27.348\n",
      "(Epoch 87 / 100) Train_Loss: 114.091; Val_Loss: 160.924   Train_ACC: 7.455; Val_ACC: 17.407   Train_NMI: 4.800; Val_NMI: 29.197\n",
      "(Epoch 88 / 100) Train_Loss: 113.109; Val_Loss: 158.140   Train_ACC: 7.331; Val_ACC: 16.296   Train_NMI: 4.978; Val_NMI: 27.526\n",
      "(Epoch 89 / 100) Train_Loss: 113.794; Val_Loss: 158.406   Train_ACC: 7.414; Val_ACC: 16.296   Train_NMI: 4.177; Val_NMI: 27.690\n",
      "(Epoch 90 / 100) Train_Loss: 112.473; Val_Loss: 163.060   Train_ACC: 7.166; Val_ACC: 16.296   Train_NMI: 4.671; Val_NMI: 24.703\n",
      "(Epoch 91 / 100) Train_Loss: 112.114; Val_Loss: 153.320   Train_ACC: 7.372; Val_ACC: 17.407   Train_NMI: 4.939; Val_NMI: 26.399\n",
      "(Epoch 92 / 100) Train_Loss: 110.901; Val_Loss: 158.824   Train_ACC: 7.537; Val_ACC: 17.037   Train_NMI: 5.093; Val_NMI: 27.019\n",
      "(Epoch 93 / 100) Train_Loss: 110.275; Val_Loss: 159.184   Train_ACC: 7.290; Val_ACC: 17.037   Train_NMI: 4.712; Val_NMI: 29.429\n",
      "(Epoch 94 / 100) Train_Loss: 109.199; Val_Loss: 155.581   Train_ACC: 7.372; Val_ACC: 16.296   Train_NMI: 4.579; Val_NMI: 27.894\n",
      "(Epoch 95 / 100) Train_Loss: 108.561; Val_Loss: 159.912   Train_ACC: 7.537; Val_ACC: 16.667   Train_NMI: 4.398; Val_NMI: 26.387\n",
      "(Epoch 96 / 100) Train_Loss: 108.933; Val_Loss: 158.612   Train_ACC: 7.496; Val_ACC: 16.296   Train_NMI: 4.870; Val_NMI: 27.621\n",
      "(Epoch 97 / 100) Train_Loss: 108.842; Val_Loss: 155.912   Train_ACC: 7.537; Val_ACC: 15.185   Train_NMI: 5.040; Val_NMI: 27.059\n",
      "(Epoch 98 / 100) Train_Loss: 107.163; Val_Loss: 167.028   Train_ACC: 7.537; Val_ACC: 15.556   Train_NMI: 4.929; Val_NMI: 25.853\n",
      "(Epoch 99 / 100) Train_Loss: 105.085; Val_Loss: 157.834   Train_ACC: 7.414; Val_ACC: 16.296   Train_NMI: 4.691; Val_NMI: 26.999\n",
      "(Epoch 100 / 100) Train_Loss: 104.872; Val_Loss: 158.374   Train_ACC: 7.455; Val_ACC: 16.667   Train_NMI: 4.837; Val_NMI: 27.565\n"
     ]
    }
   ],
   "source": [
    "history_loss = gmvae.train(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smba_gmprior_effect_on_rec.save_history_json(history_loss, num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gmvae.network.state_dict(), 'smba_gmvae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmvae.network.load_state_dict(torch.load('smba_gmvae.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bHWNxV-gAl2"
   },
   "source": [
    "## Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "wd5jQFFHgCbD",
    "outputId": "8e1d4654-fb01-49dc-b512-e8e4bb259e0f"
   },
   "outputs": [],
   "source": [
    "original, reconstructed = gmvae.reconstruct_data(train_dl, 15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_int = original.reshape(15, 16, 16, 12).argmax(axis=-1)\n",
    "reconstructed_int = reconstructed.reshape(15, 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(chunks_int):\n",
    "    classes = []\n",
    "    for i in chunks_int:\n",
    "        if i.max() == 6:\n",
    "            classes.append('kia')\n",
    "        else:\n",
    "            classes.append('smba')\n",
    "    return np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_classes = get_classes(original_int)\n",
    "rec_classes = get_classes(reconstructed_int)\n",
    "assert np.sum(org_classes == rec_classes) == len(org_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(chunks_int):\n",
    "    images = []\n",
    "    for game, chunk in zip(get_classes(chunks_int), chunks_int):\n",
    "        images.append(vglc_with_path_encodings.array_to_image([chunk], game=game)[0])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_images = get_images(original_int)\n",
    "rec_images = get_images(reconstructed_int)\n",
    "len(org_images), len(rec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=10, figsize=(24, 8))\n",
    "axes = axes.flatten()\n",
    "nrows, ncols = 3, 10\n",
    "\n",
    "org_idxs = np.arange(0, 29, 2)\n",
    "rec_idxs = org_idxs + 1\n",
    "\n",
    "for idx in org_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(org_images[idx // 2]))\n",
    "    ax.set_title(f'Org {idx // 2 + 1}')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "for idx in rec_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(rec_images[idx // 2]))\n",
    "    ax.set_title(f'Rec {idx // 2 + 1}')\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAyoGFFRgMgC"
   },
   "source": [
    "## Random Generation per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "xE84c3U2gLjA",
    "outputId": "cd52f356-e53a-4844-9db2-3723d15ddb00"
   },
   "outputs": [],
   "source": [
    "def display_random_generation(generated, num_classes, n=10):\n",
    "    plt.figure(figsize=[24,24])\n",
    "    for c in range(num_classes):\n",
    "        for i in range(n):\n",
    "            plt.subplot(num_classes, n, (c * n) + i + 1)\n",
    "            chunk_int = generated[(c * n) + i].reshape(16, 16, 12).argmax(axis=-1)\n",
    "            chunk_pix = vglc_with_path_encodings.array_to_image([chunk_int], game='smba')[0]\n",
    "            plt.imshow(chunk_pix)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "elem_per_category = 1\n",
    "generated = gmvae.random_generation(elem_per_category)\n",
    "display_random_generation(generated, args.num_classes, elem_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_per_category = 10000 // num_components\n",
    "generated = gmvae.random_generation(elem_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_int = generated.reshape(-1, 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this code chunk depends on random seed, it shouldn't be run again\n",
    "with open(f'../smba_generations/smba_gmvae_{num_components}.json', 'w+') as json_f:\n",
    "    json.dump(generated_int.tolist(), json_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SbXR7FkhIcq"
   },
   "source": [
    "## Visualization of the feature latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTkEBA9JhQ2C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([248., 375., 146.,  58., 311., 103.,  55., 148., 480., 504.]),\n",
       " array([ 0. ,  2.7,  5.4,  8.1, 10.8, 13.5, 16.2, 18.9, 21.6, 24.3, 27. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get feature representations\n",
    "test_features, test_labels = gmvae.latent_features(train_dl, return_learned_labels=True)\n",
    "plt.hist(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNmsz5rahZAY"
   },
   "outputs": [],
   "source": [
    "# import TSNE from scikit-learn library\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# reduce dimensionality to 2D, we consider a subset of data because TSNE\n",
    "# is a slow algorithm\n",
    "\n",
    "first_n = 1000\n",
    "tsne_features = TSNE(n_components=2).fit_transform(test_features[:first_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_subset = test_labels[:first_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_, Z_ = np.s_[:,0], np.s_[:,1], np.s_[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.unique(test_labels_subset), np.bincount(test_labels_subset))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "wyTtDdwyha-L",
    "outputId": "350e806a-6dd3-47f2-bd91-444aaf61b3dd"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "plt.scatter(tsne_features[X_], tsne_features[Y_], c=test_labels_subset, cmap='hsv')\n",
    "for x, y, label in zip(tsne_features[X_], tsne_features[Y_], test_labels_subset):\n",
    "    plt.annotate(label, xy=(x, y))\n",
    "\n",
    "plt.title('Projection from latent space to 2D')\n",
    "plt.show()\n",
    "\n",
    "ax.view_init?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GMVAE_Pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
