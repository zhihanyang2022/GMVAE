{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for SMBA\n",
    "\n",
    "This VAE is adapted from the GM-VAE implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGzTb0oswH5J"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThVeaB3CwI4j"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from cma import CMAEvolutionStrategy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "\n",
    "pathfinder_dir = '/home/yangz2/projects/1906-pcgml/pcgml-gmmVae-exp/demos/anurag_pathfinder_smba'\n",
    "sys.path.append(pathfinder_dir)\n",
    "import test_level_smb as astar\n",
    "\n",
    "sys.path.append('../pytorch')\n",
    "from model.VAE_kld_loss_v2 import *\n",
    "\n",
    "sys.path.append('../../1906-pcgml/pcgml-gmmVae-exp/modules/')\n",
    "import vglc_with_path_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json_as_nparray(json_fname):\n",
    "    with open(json_fname, 'r') as json_f:\n",
    "        return np.array(json.load(json_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SMB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smb_int = open_json_as_nparray('smbWithPath-allLevels-chunks-int.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 16, 16, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = np.eye(len(np.unique(smb_int)))[smb_int]\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 3072)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = smb_onehot.reshape(\n",
    "    smb_onehot.shape[0], \n",
    "    smb_onehot.shape[1] * smb_onehot.shape[2] * smb_onehot.shape[3]\n",
    ")\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = smb_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QNKItMHwQU2"
   },
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tBHkTQ4wVIG"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Input Parameters\n",
    "#########################################################\n",
    "parser = argparse.ArgumentParser(description='PyTorch Implementation of DGM Clustering')\n",
    "\n",
    "## Used only in notebooks\n",
    "parser.add_argument('-f', '--file',\n",
    "                    help='Path for input file. First line should contain number of lines to search in')\n",
    "\n",
    "## Dataset\n",
    "parser.add_argument('--dataset', type=str, choices=['mnist'],\n",
    "                    default='mnist', help='dataset (default: mnist)')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "\n",
    "## GPU\n",
    "parser.add_argument('--cuda', type=int, default=0,\n",
    "                    help='use of cuda (default: 1)')\n",
    "parser.add_argument('--gpuID', type=int, default=0,\n",
    "                    help='set gpu id to use (default: 0)')\n",
    "\n",
    "## Training\n",
    "parser.add_argument('--epochs', type=int, default=num_epochs,\n",
    "                    help='number of total epochs to run (default: 200)')\n",
    "parser.add_argument('--batch_size', default=64, type=int,\n",
    "                    help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--batch_size_val', default=200, type=int,\n",
    "                    help='mini-batch size of validation (default: 200)')\n",
    "parser.add_argument('--learning_rate', default=1e-3, type=float,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay_epoch', default=-1, type=int, \n",
    "                    help='Reduces the learning rate every decay_epoch')\n",
    "parser.add_argument('--lr_decay', default=0.5, type=float,\n",
    "                    help='Learning rate decay for training (default: 0.5)')\n",
    "\n",
    "## Architecture\n",
    "parser.add_argument('--gaussian_size', default=64, type=int,\n",
    "                    help='gaussian size (default: 64)')\n",
    "parser.add_argument('--input_size', default=3072, type=int,\n",
    "                    help='input size (default: 784)')  # edited for this task\n",
    "\n",
    "## Partition parameters\n",
    "parser.add_argument('--train_proportion', default=0.9, type=float,\n",
    "                    help='proportion of examples to consider for training only (default: 1.0)')\n",
    "\n",
    "## Loss function parameters\n",
    "parser.add_argument('--w_gauss', default=2, type=float,\n",
    "                    help='weight of gaussian loss (default: 1)')\n",
    "parser.add_argument('--w_categ', default=1, type=float,\n",
    "                    help='weight of categorical loss (default: 1)')\n",
    "parser.add_argument('--w_rec', default=1, type=float,\n",
    "                    help='weight of reconstruction loss (default: 1)')\n",
    "parser.add_argument('--rec_type', type=str, choices=['bce', 'mse'],\n",
    "                    default='bce', help='desired reconstruction loss function (default: bce)')\n",
    "\n",
    "## Others\n",
    "parser.add_argument('--verbose', default=0, type=int,\n",
    "                    help='print extra information at every epoch.(default: 0)')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bti6lPHawc9z"
   },
   "source": [
    "Set random seed in case it was specified in the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpWPxTy1wgbJ"
   },
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "SEED = args.seed\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmrkmhttwkiD"
   },
   "source": [
    "## Data Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUuTFMBhb2vZ"
   },
   "source": [
    "We split the training data into train and validation according to the *train_proportion* parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.train_proportion != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8F6pjC7cNX7"
   },
   "outputs": [],
   "source": [
    "def partition_dataset(n, proportion=0.9):\n",
    "   train_num = int(n * proportion)\n",
    "   indices = np.random.permutation(n)\n",
    "   train_indices, val_indices = indices[:train_num], indices[train_num:]\n",
    "   return train_indices, val_indices\n",
    "\n",
    "train_indices, val_indices = partition_dataset(len(chunks), args.train_proportion)\n",
    "train_ds = TensorDataset(torch.from_numpy(chunks).float())\n",
    "train_dl = DataLoader(train_ds, batch_size=args.batch_size, sampler=SubsetRandomSampler(train_indices))\n",
    "valid_dl = DataLoader(train_ds, batch_size=args.batch_size_val, sampler=SubsetRandomSampler(val_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pt7sEfZWw_U7"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTncRSCuxFEL"
   },
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "vae = VAE(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_loss = vae.train(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vae.network.state_dict(), f'smba_vae_kld_loss_v2_{num_epochs}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.network.load_state_dict(torch.load(f'smba_vae_kld_loss_v2_{num_epochs}.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bHWNxV-gAl2"
   },
   "source": [
    "## Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "wd5jQFFHgCbD",
    "outputId": "8e1d4654-fb01-49dc-b512-e8e4bb259e0f"
   },
   "outputs": [],
   "source": [
    "original, reconstructed = vae.reconstruct_data(train_dl, len(train_ds))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_int = original.reshape(len(train_ds), 16, 16, 12).argmax(axis=-1)\n",
    "reconstructed_int = reconstructed.reshape(len(train_ds), 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(original_int != reconstructed_int) / len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(chunks_int):\n",
    "    classes = []\n",
    "    for i in chunks_int:\n",
    "        if i.max() == 6:\n",
    "            classes.append('kia')\n",
    "        else:\n",
    "            classes.append('smba')\n",
    "    return np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_classes = get_classes(original_int)\n",
    "rec_classes = get_classes(reconstructed_int)\n",
    "assert np.sum(org_classes == rec_classes) == len(org_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(chunks_int):\n",
    "    images = []\n",
    "    for game, chunk in zip(get_classes(chunks_int), chunks_int):\n",
    "        images.append(vglc_with_path_encodings.array_to_image([chunk], game=game)[0])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_images = get_images(original_int)\n",
    "rec_images = get_images(reconstructed_int)\n",
    "len(org_images), len(rec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=10, figsize=(24, 8))\n",
    "axes = axes.flatten()\n",
    "nrows, ncols = 3, 10\n",
    "\n",
    "org_idxs = np.arange(0, 29, 2)\n",
    "rec_idxs = org_idxs + 1\n",
    "\n",
    "for idx in org_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(org_images[idx // 2]))\n",
    "    ax.set_title(f'Org {idx // 2 + 1}')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "for idx in rec_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(rec_images[idx // 2]))\n",
    "    ax.set_title(f'Rec {idx // 2 + 1}')\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAyoGFFRgMgC"
   },
   "source": [
    "## Random Generation per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "xE84c3U2gLjA",
    "outputId": "cd52f356-e53a-4844-9db2-3723d15ddb00"
   },
   "outputs": [],
   "source": [
    "def display_random_generation(generated, num_classes, n=10):\n",
    "    plt.figure(figsize=[24,5])\n",
    "    for c in range(num_classes):\n",
    "        for i in range(n):\n",
    "            plt.subplot(num_classes, n, (c * n) + i + 1)\n",
    "            chunk_int = generated[(c * n) + i].reshape(16, 16, 12).argmax(axis=-1)\n",
    "            chunk_pix = vglc_with_path_encodings.array_to_image([chunk_int], game='smba')[0]\n",
    "            plt.imshow(chunk_pix)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "elem_per_category = 15\n",
    "generated = gmvae.random_generation(elem_per_category)\n",
    "display_random_generation(generated, args.num_classes, elem_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = vae.random_generation(10000)\n",
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_int = generated.reshape(-1, 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this code chunk depends on random seed, it shouldn't be run again\n",
    "with open(f'../smba_generations/smba_vae_kld_loss_v2_{num_epochs}.json', 'w+') as json_f:\n",
    "    json.dump(generated_int.tolist(), json_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SbXR7FkhIcq"
   },
   "source": [
    "## Visualization of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_variance_kept = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(level_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTkEBA9JhQ2C"
   },
   "outputs": [],
   "source": [
    "features = vae.latent_features(DataLoader(train_ds, batch_size=128, shuffle=False))\n",
    "type1 = np.where(level_idxs == 0)[0]\n",
    "type2 = np.where(level_idxs == 1)[0]\n",
    "type3 = np.where(level_idxs == 2)[0]\n",
    "\n",
    "np.random.seed(30)\n",
    "random_idxs_1 = np.random.choice(type1, size=333, replace=True)\n",
    "random_idxs_2 = np.random.choice(type2, size=333, replace=True)\n",
    "random_idxs_3 = np.random.choice(type3, size=333, replace=True)\n",
    "random_idxs = np.concatenate([random_idxs_1, random_idxs_2, random_idxs_3])\n",
    "\n",
    "features_for_pca = features[random_idxs].copy()\n",
    "features_for_pca -= features_for_pca.mean(axis=0)\n",
    "features_for_pca /= features_for_pca.std(axis=0)\n",
    "pca_features = PCA(pca_variance_kept).fit_transform(features_for_pca[:1000])\n",
    "print(pca_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmeans_labels(X, num_clusters):\n",
    "    from sklearn.cluster import KMeans\n",
    "    distances_to_centroids = KMeans(n_clusters=num_clusters, n_init=20).fit_transform(X)\n",
    "    predicted_labels = distances_to_centroids.argmin(axis=1)\n",
    "    return distances_to_centroids, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "num_clusters_range = np.arange(1, 21)\n",
    "costs = []\n",
    "for num_clusters in tqdm_notebook(num_clusters_range, leave=False):\n",
    "    distances_to_centroids, predicted_labels = get_kmeans_labels(pca_features, num_clusters)\n",
    "    distances_to_closest_centroids = distances_to_centroids[np.arange(len(pca_features)), predicted_labels]\n",
    "    costs.append(np.sum(distances_to_closest_centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_clusters_range, costs)\n",
    "plt.xticks(num_clusters_range)\n",
    "# plt.title(f'K-means elbow plot for SMB latent vectors (PCA {int(pca_variance_kept * 100)}%)')\n",
    "plt.xlabel('Number of clusters'); plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.savefig(f'K-means elbow plot for SMB latent vectors (PCA {int(pca_variance_kept * 100)}%).png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNmsz5rahZAY"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(30)\n",
    "tsne_features = TSNE(n_components=2).fit_transform(features[random_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_labels = get_kmeans_labels(pca_features, num_clusters=3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../1906-pcgml/pcgml-gmmVae-exp/data/smba_level_idx_per_chunk.json', 'r') as json_f:\n",
    "    level_idxs = np.array(json.load(json_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_idxs_sub = level_idxs[random_idxs]\n",
    "print(np.bincount(level_idxs) / len(level_idxs))\n",
    "print(np.bincount(level_idxs_sub) / len(level_idxs_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.s_[:,0], np.s_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "labels = ['Underword', 'Overworld', 'Jumpy']\n",
    "colors = [u'#1f77b4', u'#ff7f0e', u'#2ca02c']\n",
    "\n",
    "for i in range(3):\n",
    "    plt.scatter(\n",
    "        tsne_features[level_idxs_sub == i][X], \n",
    "        tsne_features[level_idxs_sub == i][Y],\n",
    "        label=labels[i],\n",
    "        s=20, alpha=0.7, color=colors[i]\n",
    "    )\n",
    "\n",
    "# plt.title('SMB latent vectors color-coded by level-type label')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('SMB latent vectors (VAE) color-coded by level type label.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "wyTtDdwyha-L",
    "outputId": "350e806a-6dd3-47f2-bd91-444aaf61b3dd"
   },
   "outputs": [],
   "source": [
    "from metrics.Metrics import *\n",
    "metrics = Metrics()\n",
    "acc = metrics.cluster_acc(level_idxs_sub, kmeans_labels)\n",
    "print(acc)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "colors = [u'#1f77b4', u'#ff7f0e', u'#2ca02c']\n",
    "\n",
    "for i in range(3):\n",
    "    plt.scatter(\n",
    "        tsne_features[kmeans_labels == i][X], \n",
    "        tsne_features[kmeans_labels == i][Y],\n",
    "        label=f'Cluster {i+1}',\n",
    "        s=20, alpha=0.7, color=colors[i]\n",
    "    )\n",
    "\n",
    "# plt.title(f'SMB latent vectors color-coded by K-means cluster index (PCA {int(pca_variance_kept * 100)}%)\\nClustering accuracy: {round(acc * 100, 1)}%')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'SMB latent vectors (VAE) color-coded by K-means cluster index (PCA {int(pca_variance_kept * 100)}) Clustering accuracy: {round(acc * 100, 1)}.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bics = []\n",
    "for i in tqdm_notebook(np.arange(1, 21)):\n",
    "    gmm = GaussianMixture(n_components=i, covariance_type='full', n_init=20).fit(pca_features)\n",
    "    bics.append(gmm.bic(pca_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load the bics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 21), bics)\n",
    "plt.xticks(np.arange(1, 21))\n",
    "plt.xlabel('Number of components'); plt.ylabel('BIC score')\n",
    "plt.grid()\n",
    "plt.savefig(f'BIC plot for SMB latent vectors (PCA {int(pca_variance_kept * 100)}%).png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_labels = GaussianMixture(n_components=3, covariance_type='full', n_init=20).fit_predict(pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "acc = metrics.cluster_acc(level_idxs_sub, gmm_labels)\n",
    "print(acc)\n",
    "\n",
    "for i in range(3):\n",
    "    plt.scatter(\n",
    "        tsne_features[gmm_labels == i][X], \n",
    "        tsne_features[gmm_labels == i][Y],\n",
    "        label=f'Component {i+1}',\n",
    "        s=20, alpha=0.7\n",
    "    )\n",
    "\n",
    "# plt.title(f'SMB latent vectors color-coded by GMM component index (PCA {int(pca_variance_kept * 100)}%)\\nClustering accuracy: {round(acc * 100, 1)}%')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(f'SMB latent vectors (VAE) color-coded by GMM component index (PCA {int(pca_variance_kept * 100)}) Clustering accuracy: {round(acc * 100, 1)}.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE-GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = '/home/yangz2/projects/gmvae_and_gmmvae/results'\n",
    "GAME = 'smba'\n",
    "MODEL = 'vae_gmm'\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../1906-pcgml/pcgml-gmmVae-exp/modules/')\n",
    "import vglc_with_path_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2698, 9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46712407bd9946ec8b71deab7eab6d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = vae.latent_features(DataLoader(train_ds, batch_size=128, shuffle=False))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "means = features.mean(axis=0)\n",
    "stds = features.std(axis=0)\n",
    "features = pca.fit_transform((features - means) / stds)\n",
    "print(features.shape)\n",
    "\n",
    "gmms = []\n",
    "num_components_s = [40, 50]\n",
    "for i in tqdm_notebook(num_components_s):\n",
    "    gmm = GaussianMixture(n_components=i, covariance_type='full', n_init=10)\n",
    "    gmm.fit(features)\n",
    "    gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e8b8d220a4ba6957c74025c10f7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c8b13136a141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mchunks_by_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "for i, num_components in tqdm_notebook(list(enumerate(num_components_s))):\n",
    "    \n",
    "    gens_s = []\n",
    "    gmm = gmms[i]\n",
    "    for mean, cov in zip(gmm.means_, gmm.covariances_):\n",
    "        gens = multivariate_normal(mean=mean, cov=cov).rvs(500)\n",
    "        gens = pca.inverse_transform(gens)\n",
    "        \n",
    "        gens = gens * stds + means\n",
    "        gens = vae.network.generative.pxz(torch.from_numpy(gens).float()).reshape(gens.shape[0], 16, 16, -1).detach().numpy()\n",
    "        gens = gens.argmax(axis=-1)\n",
    "        gens_s.append(gens)\n",
    "        \n",
    "    gens = np.concatenate(gens_s)\n",
    "    \n",
    "    chunks_by_comp = []\n",
    "    for label in np.unique(labels):\n",
    "        which = labels == label\n",
    "        assert np.sum(which) >= 500\n",
    "        chunks_by_comp.append(gens[which][:500])\n",
    "    chunks_by_comp = np.array(chunks_by_comp)\n",
    "    \n",
    "    with open(f'{RESULTS_DIR}/{GAME}_{MODEL}_generations/{GAME}_{MODEL}_{num_components}.json', 'w+') as json_f:\n",
    "        json.dump(chunks_by_comp.tolist(), json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "char2int_smb = { \n",
    "    \"X\": 0,  # smb unpassable\n",
    "    \"S\": 1,  # smb breakable\n",
    "    \"-\": 2,  # smb background\n",
    "    \"?\": 3,  # smb question\n",
    "    \"Q\": 4,  # smb question\n",
    "    \"E\": 5,\n",
    "    \"<\": 6,\n",
    "    \">\": 7,\n",
    "    \"[\": 8,\n",
    "    \"]\": 9,\n",
    "    \"o\": 10,\n",
    "    \"P\": 11,  # for smb path (from Anurag's email)\n",
    "}\n",
    "int2char_smba = {v:k for k, v in char2int_smb.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def chunk_int_to_chunk_char(chunk_int):\n",
    "    chunk_char = []\n",
    "    for row in chunk_int:\n",
    "        row_char = []\n",
    "        for entry in row:\n",
    "            row_char.append(int2char_smba[int(entry)])\n",
    "        row_char = ''.join(row_char)\n",
    "        chunk_char.append(row_char)\n",
    "    return chunk_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_starting_tile(chunk:np.array)->tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the starting point of mario given a chunk.\n",
    "    :param chunk: an 16-by-16 numpy array of integers\n",
    "    :return a tuple describing a possible starting point of mario in the chunk (col_idx, row_idx)\n",
    "    \"\"\"\n",
    "    \n",
    "    for col_idx in range(chunk.shape[1]):  # loop over the columns of the chunk\n",
    "        col = chunk[:, col_idx]\n",
    "        \n",
    "        # if 5 columns have been searched and no appropriate starting points have\n",
    "        # been found, consider the chunk as unplayable\n",
    "        # (need more thoughts on how to deal with such cases)\n",
    "        if col_idx == 5: return None\n",
    "        \n",
    "        for row_idx, entry in enumerate(col):  # loop over the entries of the column, from top to bottom\n",
    "            if entry in [0, 1, 3, 4, 6, 7, 8, 9]:  # tiles on which mario can stand (see above for meaning)\n",
    "                # the pathfinding code works with starting points of the format (col_idx, row_idx)\n",
    "                return col_idx, row_idx - 1  # set mario's starting point to be above that tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{pathfinder_dir}/SMB.json') as data_file:    \n",
    "    platformerDescription = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_path_from_chunk(chunk:list, chunk_int:np.array, debug=False)->np.array:\n",
    "    \n",
    "    # chunk must be in the format of a list of strings\n",
    "    # chunk is used for pathfinding\n",
    "    \n",
    "    try:\n",
    "        # the following line will fail if no path exist\n",
    "        starting_tile = get_starting_tile(chunk_int)\n",
    "        if debug: print(starting_tile)\n",
    "        \n",
    "        paths = astar.findPaths(\n",
    "            10, \n",
    "            platformerDescription['solid'], \n",
    "            platformerDescription['jumps'], \n",
    "            chunk, \n",
    "            src=starting_tile\n",
    "        )[0]\n",
    "        if debug: print(paths)\n",
    "    \n",
    "    except:\n",
    "        # if no path exist, None will be returned\n",
    "        return None\n",
    "\n",
    "    output = np.zeros((16, 16))\n",
    "    for p in paths:\n",
    "        output[p[1], p[0]] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_int_from_latent_vec(vec):\n",
    "    latent_vec = torch.Tensor(vec).reshape(1, 64)\n",
    "    chunk_int = vae.network.generative(latent_vec)['x_rec'].squeeze().detach().numpy().reshape(16, 16, 12).argmax(-1)\n",
    "    return chunk_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_path_scoring_func(ideal_path:np.array):\n",
    "    def path_scoring_func(vec):\n",
    "        \n",
    "        latent_vec = torch.Tensor(vec).reshape(1, 64)\n",
    "        chunk_int = vae.network.generative(latent_vec)['x_rec'].squeeze().detach().numpy().reshape(16, 16, 12).argmax(-1)\n",
    "        chunk_int[chunk_int == 11] = 2\n",
    "        chunk_char = chunk_int_to_chunk_char(chunk_int)\n",
    "\n",
    "        try:\n",
    "            generated_path = get_path_from_chunk(chunk_char, chunk_int)\n",
    "            score = np.mean(np.abs((generated_path.argmax(axis=0) - ideal_path.argmax(axis=0))))\n",
    "            return score\n",
    "        except:\n",
    "            return 1000000\n",
    "    \n",
    "    return path_scoring_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "ideal_path = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    \n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "])\n",
    "plt.matshow(ideal_path); plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_scoring_func = get_path_scoring_func(ideal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = CMAEvolutionStrategy(list(np.random.normal(size=64)), 10).optimize(path_scoring_func).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vglc_with_path_encodings.array_to_image([get_chunk_int_from_latent_vec(res[0])], game='smba')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunk = get_chunk_int_from_latent_vec(res[0])\n",
    "new_chunk[new_chunk == 11] = 2\n",
    "get_path_from_chunk(chunk_int_to_chunk_char(new_chunk), new_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_int_to_chunk_char(new_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_starting_tile(new_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GMVAE_Pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
