{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GM-VAE for SMBA, 8 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGzTb0oswH5J"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThVeaB3CwI4j"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yangz2/projects/gmvae_and_gmmvae/pytorch/')\n",
    "sys.path.append('../../1906-pcgml/pcgml-gmmVae-exp/modules/')\n",
    "import vglc_with_path_encodings\n",
    "\n",
    "from model.GMVAE import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json_as_nparray(json_fname):\n",
    "    with open(json_fname, 'r') as json_f:\n",
    "        return np.array(json.load(json_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SMB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smb_int = open_json_as_nparray('smbWithPath-allLevels-chunks-int.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 16, 16, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = np.eye(len(np.unique(smb_int)))[smb_int]\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2698, 3072)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smb_onehot = smb_onehot.reshape(\n",
    "    smb_onehot.shape[0], \n",
    "    smb_onehot.shape[1] * smb_onehot.shape[2] * smb_onehot.shape[3]\n",
    ")\n",
    "smb_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2698,), array([6, 3, 4, 6, 2, 7, 4, 4, 6, 1, 2, 6, 2, 2, 7, 4, 3, 7, 7, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "smb_labels = np.random.randint(8, size=smb_onehot.shape[0])\n",
    "smb_labels.shape, smb_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, labels = smb_onehot, smb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(8), np.bincount(smb_labels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QNKItMHwQU2"
   },
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tBHkTQ4wVIG"
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Input Parameters\n",
    "#########################################################\n",
    "parser = argparse.ArgumentParser(description='PyTorch Implementation of DGM Clustering')\n",
    "\n",
    "## Used only in notebooks\n",
    "parser.add_argument('-f', '--file',\n",
    "                    help='Path for input file. First line should contain number of lines to search in')\n",
    "\n",
    "## Dataset\n",
    "parser.add_argument('--dataset', type=str, choices=['mnist'],\n",
    "                    default='mnist', help='dataset (default: mnist)')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed (default: 1)')\n",
    "\n",
    "## GPU\n",
    "parser.add_argument('--cuda', type=int, default=1,\n",
    "                    help='use of cuda (default: 1)')\n",
    "parser.add_argument('--gpuID', type=int, default=0,\n",
    "                    help='set gpu id to use (default: 0)')\n",
    "\n",
    "## Training\n",
    "parser.add_argument('--epochs', type=int, default=num_epochs,\n",
    "                    help='number of total epochs to run (default: 200)')\n",
    "parser.add_argument('--batch_size', default=64, type=int,\n",
    "                    help='mini-batch size (default: 64)')\n",
    "parser.add_argument('--batch_size_val', default=200, type=int,\n",
    "                    help='mini-batch size of validation (default: 200)')\n",
    "parser.add_argument('--learning_rate', default=1e-3, type=float,\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--decay_epoch', default=-1, type=int, \n",
    "                    help='Reduces the learning rate every decay_epoch')\n",
    "parser.add_argument('--lr_decay', default=0.5, type=float,\n",
    "                    help='Learning rate decay for training (default: 0.5)')\n",
    "\n",
    "## Architecture\n",
    "parser.add_argument('--num_classes', type=int, default=num_components,\n",
    "                    help='number of classes (default: 10)')  # edited for this task\n",
    "parser.add_argument('--gaussian_size', default=64, type=int,\n",
    "                    help='gaussian size (default: 64)')\n",
    "parser.add_argument('--input_size', default=3072, type=int,\n",
    "                    help='input size (default: 784)')  # edited for this task\n",
    "\n",
    "## Partition parameters\n",
    "parser.add_argument('--train_proportion', default=0.9, type=float,\n",
    "                    help='proportion of examples to consider for training only (default: 1.0)')\n",
    "\n",
    "## Gumbel parameters\n",
    "parser.add_argument('--init_temp', default=1.0, type=float,\n",
    "                    help='Initial temperature used in gumbel-softmax (recommended 0.5-1.0, default:1.0)')\n",
    "parser.add_argument('--decay_temp', default=1, type=int, \n",
    "                    help='Set 1 to decay gumbel temperature at every epoch (default: 1)')\n",
    "parser.add_argument('--hard_gumbel', default=0, type=int, \n",
    "                    help='Set 1 to use the hard version of gumbel-softmax (default: 1)')\n",
    "parser.add_argument('--min_temp', default=0.5, type=float, \n",
    "                    help='Minimum temperature of gumbel-softmax after annealing (default: 0.5)' )\n",
    "parser.add_argument('--decay_temp_rate', default=0.013862944, type=float,\n",
    "                    help='Temperature decay rate at every epoch (default: 0.013862944)')\n",
    "\n",
    "## Loss function parameters\n",
    "parser.add_argument('--w_gauss', default=2, type=float,\n",
    "                    help='weight of gaussian loss (default: 1)')\n",
    "parser.add_argument('--w_categ', default=1, type=float,\n",
    "                    help='weight of categorical loss (default: 1)')\n",
    "parser.add_argument('--w_rec', default=1, type=float,\n",
    "                    help='weight of reconstruction loss (default: 1)')\n",
    "parser.add_argument('--rec_type', type=str, choices=['bce', 'mse'],\n",
    "                    default='bce', help='desired reconstruction loss function (default: bce)')\n",
    "\n",
    "## Others\n",
    "parser.add_argument('--verbose', default=0, type=int,\n",
    "                    help='print extra information at every epoch.(default: 0)')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bti6lPHawc9z"
   },
   "source": [
    "Set random seed in case it was specified in the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpWPxTy1wgbJ"
   },
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "SEED = args.seed\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmrkmhttwkiD"
   },
   "source": [
    "## Data Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUuTFMBhb2vZ"
   },
   "source": [
    "We split the training data into train and validation according to the *train_proportion* parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.train_proportion != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8F6pjC7cNX7"
   },
   "outputs": [],
   "source": [
    "def partition_dataset(n, proportion=1):\n",
    "   train_num = int(n * proportion)\n",
    "   indices = np.random.permutation(n)\n",
    "   train_indices, val_indices = indices[:train_num], indices[train_num:]\n",
    "   return train_indices, val_indices\n",
    "\n",
    "train_indices, val_indices = partition_dataset(len(chunks), args.train_proportion)\n",
    "train_ds = TensorDataset(torch.from_numpy(chunks).float(), torch.from_numpy(labels).long())\n",
    "train_dl = DataLoader(train_ds, batch_size=args.batch_size, sampler=SubsetRandomSampler(train_indices))\n",
    "valid_dl = DataLoader(train_ds, batch_size=args.batch_size_val, sampler=SubsetRandomSampler(val_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pt7sEfZWw_U7"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTncRSCuxFEL"
   },
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "gmvae = GMVAE(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1 / 10000) Train_Loss: 485.278; Val_Loss: 240.016   Train_ACC: 14.786; Val_ACC: 14.815   Train_NMI: 0.707; Val_NMI: 1.388\n",
      "(Epoch 2 / 10000) Train_Loss: 230.533; Val_Loss: 227.010   Train_ACC: 14.415; Val_ACC: 15.185   Train_NMI: 0.408; Val_NMI: 0.375\n",
      "(Epoch 3 / 10000) Train_Loss: 226.405; Val_Loss: 227.659   Train_ACC: 14.127; Val_ACC: 15.926   Train_NMI: 0.324; Val_NMI: 1.224\n",
      "(Epoch 4 / 10000) Train_Loss: 222.295; Val_Loss: 225.466   Train_ACC: 14.662; Val_ACC: 17.778   Train_NMI: 0.610; Val_NMI: 2.965\n",
      "(Epoch 5 / 10000) Train_Loss: 215.178; Val_Loss: 212.209   Train_ACC: 14.209; Val_ACC: 18.889   Train_NMI: 0.325; Val_NMI: 3.928\n",
      "(Epoch 6 / 10000) Train_Loss: 210.584; Val_Loss: 212.660   Train_ACC: 13.880; Val_ACC: 15.556   Train_NMI: 0.424; Val_NMI: 1.081\n",
      "(Epoch 7 / 10000) Train_Loss: 206.127; Val_Loss: 207.296   Train_ACC: 14.498; Val_ACC: 17.778   Train_NMI: 0.579; Val_NMI: 3.142\n",
      "(Epoch 8 / 10000) Train_Loss: 202.711; Val_Loss: 198.676   Train_ACC: 14.044; Val_ACC: 19.630   Train_NMI: 0.338; Val_NMI: 2.258\n",
      "(Epoch 9 / 10000) Train_Loss: 199.911; Val_Loss: 204.698   Train_ACC: 14.498; Val_ACC: 18.519   Train_NMI: 0.564; Val_NMI: 2.389\n",
      "(Epoch 10 / 10000) Train_Loss: 197.699; Val_Loss: 200.881   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.488; Val_NMI: 4.142\n",
      "(Epoch 11 / 10000) Train_Loss: 194.007; Val_Loss: 200.034   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.499; Val_NMI: 4.350\n",
      "(Epoch 12 / 10000) Train_Loss: 191.099; Val_Loss: 195.201   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.668; Val_NMI: 2.610\n",
      "(Epoch 13 / 10000) Train_Loss: 188.962; Val_Loss: 198.938   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.509; Val_NMI: 3.766\n",
      "(Epoch 14 / 10000) Train_Loss: 187.275; Val_Loss: 196.157   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.407; Val_NMI: 3.594\n",
      "(Epoch 15 / 10000) Train_Loss: 184.860; Val_Loss: 191.694   Train_ACC: 15.033; Val_ACC: 18.148   Train_NMI: 0.601; Val_NMI: 2.521\n",
      "(Epoch 16 / 10000) Train_Loss: 182.214; Val_Loss: 191.445   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.446; Val_NMI: 2.857\n",
      "(Epoch 17 / 10000) Train_Loss: 180.515; Val_Loss: 188.520   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.599; Val_NMI: 4.317\n",
      "(Epoch 18 / 10000) Train_Loss: 179.389; Val_Loss: 189.823   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.706; Val_NMI: 3.983\n",
      "(Epoch 19 / 10000) Train_Loss: 177.436; Val_Loss: 187.899   Train_ACC: 15.280; Val_ACC: 19.630   Train_NMI: 0.662; Val_NMI: 4.989\n",
      "(Epoch 20 / 10000) Train_Loss: 175.790; Val_Loss: 185.218   Train_ACC: 15.445; Val_ACC: 19.259   Train_NMI: 0.562; Val_NMI: 5.095\n",
      "(Epoch 21 / 10000) Train_Loss: 174.717; Val_Loss: 189.616   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.713\n",
      "(Epoch 22 / 10000) Train_Loss: 173.426; Val_Loss: 181.217   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.494; Val_NMI: 4.617\n",
      "(Epoch 23 / 10000) Train_Loss: 172.831; Val_Loss: 183.698   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 4.574\n",
      "(Epoch 24 / 10000) Train_Loss: 172.071; Val_Loss: 183.039   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.500; Val_NMI: 5.654\n",
      "(Epoch 25 / 10000) Train_Loss: 169.864; Val_Loss: 175.459   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.456; Val_NMI: 5.819\n",
      "(Epoch 26 / 10000) Train_Loss: 169.746; Val_Loss: 177.306   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.394; Val_NMI: 4.231\n",
      "(Epoch 27 / 10000) Train_Loss: 170.463; Val_Loss: 179.948   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.410; Val_NMI: 6.110\n",
      "(Epoch 28 / 10000) Train_Loss: 167.920; Val_Loss: 175.926   Train_ACC: 14.909; Val_ACC: 18.148   Train_NMI: 0.418; Val_NMI: 3.642\n",
      "(Epoch 29 / 10000) Train_Loss: 166.793; Val_Loss: 179.394   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 5.080\n",
      "(Epoch 30 / 10000) Train_Loss: 166.611; Val_Loss: 181.324   Train_ACC: 14.415; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.787\n",
      "(Epoch 31 / 10000) Train_Loss: 165.113; Val_Loss: 179.075   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.353; Val_NMI: 3.672\n",
      "(Epoch 32 / 10000) Train_Loss: 164.159; Val_Loss: 175.571   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 4.068\n",
      "(Epoch 33 / 10000) Train_Loss: 163.000; Val_Loss: 175.565   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.579\n",
      "(Epoch 34 / 10000) Train_Loss: 161.651; Val_Loss: 174.191   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.420; Val_NMI: 4.307\n",
      "(Epoch 35 / 10000) Train_Loss: 161.605; Val_Loss: 176.758   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.447; Val_NMI: 4.333\n",
      "(Epoch 36 / 10000) Train_Loss: 159.106; Val_Loss: 171.842   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 4.863\n",
      "(Epoch 37 / 10000) Train_Loss: 158.867; Val_Loss: 169.607   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 4.159\n",
      "(Epoch 38 / 10000) Train_Loss: 157.291; Val_Loss: 170.679   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.466; Val_NMI: 4.198\n",
      "(Epoch 39 / 10000) Train_Loss: 156.481; Val_Loss: 166.006   Train_ACC: 14.415; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.486\n",
      "(Epoch 40 / 10000) Train_Loss: 155.093; Val_Loss: 167.835   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 3.667\n",
      "(Epoch 41 / 10000) Train_Loss: 153.747; Val_Loss: 170.086   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.469; Val_NMI: 4.073\n",
      "(Epoch 42 / 10000) Train_Loss: 152.951; Val_Loss: 167.906   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.398; Val_NMI: 3.849\n",
      "(Epoch 43 / 10000) Train_Loss: 152.065; Val_Loss: 170.614   Train_ACC: 14.745; Val_ACC: 18.519   Train_NMI: 0.383; Val_NMI: 3.722\n",
      "(Epoch 44 / 10000) Train_Loss: 150.944; Val_Loss: 167.171   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.418; Val_NMI: 3.983\n",
      "(Epoch 45 / 10000) Train_Loss: 149.751; Val_Loss: 171.485   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.373; Val_NMI: 3.942\n",
      "(Epoch 46 / 10000) Train_Loss: 149.005; Val_Loss: 165.336   Train_ACC: 14.703; Val_ACC: 18.148   Train_NMI: 0.387; Val_NMI: 3.846\n",
      "(Epoch 47 / 10000) Train_Loss: 147.770; Val_Loss: 165.121   Train_ACC: 14.992; Val_ACC: 18.148   Train_NMI: 0.362; Val_NMI: 3.742\n",
      "(Epoch 48 / 10000) Train_Loss: 148.050; Val_Loss: 167.906   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 4.596\n",
      "(Epoch 49 / 10000) Train_Loss: 146.756; Val_Loss: 163.581   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.563\n",
      "(Epoch 50 / 10000) Train_Loss: 145.300; Val_Loss: 161.258   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.403; Val_NMI: 3.826\n",
      "(Epoch 51 / 10000) Train_Loss: 144.092; Val_Loss: 163.000   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.416; Val_NMI: 4.915\n",
      "(Epoch 52 / 10000) Train_Loss: 143.345; Val_Loss: 167.706   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.141\n",
      "(Epoch 53 / 10000) Train_Loss: 142.940; Val_Loss: 163.978   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 5.276\n",
      "(Epoch 54 / 10000) Train_Loss: 141.497; Val_Loss: 159.729   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.362; Val_NMI: 4.704\n",
      "(Epoch 55 / 10000) Train_Loss: 140.835; Val_Loss: 157.852   Train_ACC: 15.033; Val_ACC: 18.519   Train_NMI: 0.393; Val_NMI: 4.810\n",
      "(Epoch 56 / 10000) Train_Loss: 139.794; Val_Loss: 162.244   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.452; Val_NMI: 3.857\n",
      "(Epoch 57 / 10000) Train_Loss: 138.674; Val_Loss: 158.134   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.459; Val_NMI: 3.344\n",
      "(Epoch 58 / 10000) Train_Loss: 138.212; Val_Loss: 157.400   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 4.420\n",
      "(Epoch 59 / 10000) Train_Loss: 137.012; Val_Loss: 160.961   Train_ACC: 15.198; Val_ACC: 18.148   Train_NMI: 0.458; Val_NMI: 4.016\n",
      "(Epoch 60 / 10000) Train_Loss: 136.216; Val_Loss: 159.550   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.332; Val_NMI: 4.177\n",
      "(Epoch 61 / 10000) Train_Loss: 135.184; Val_Loss: 159.114   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.419; Val_NMI: 3.796\n",
      "(Epoch 62 / 10000) Train_Loss: 134.733; Val_Loss: 156.535   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.383; Val_NMI: 4.314\n",
      "(Epoch 63 / 10000) Train_Loss: 133.379; Val_Loss: 157.001   Train_ACC: 14.827; Val_ACC: 18.148   Train_NMI: 0.388; Val_NMI: 4.580\n",
      "(Epoch 64 / 10000) Train_Loss: 132.940; Val_Loss: 160.175   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.343; Val_NMI: 4.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 65 / 10000) Train_Loss: 131.888; Val_Loss: 159.203   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 6.143\n",
      "(Epoch 66 / 10000) Train_Loss: 131.928; Val_Loss: 163.298   Train_ACC: 15.198; Val_ACC: 18.519   Train_NMI: 0.469; Val_NMI: 5.199\n",
      "(Epoch 67 / 10000) Train_Loss: 131.522; Val_Loss: 159.118   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.377; Val_NMI: 3.838\n",
      "(Epoch 68 / 10000) Train_Loss: 130.011; Val_Loss: 160.355   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.455; Val_NMI: 5.394\n",
      "(Epoch 69 / 10000) Train_Loss: 129.003; Val_Loss: 156.794   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.440; Val_NMI: 5.159\n",
      "(Epoch 70 / 10000) Train_Loss: 128.258; Val_Loss: 158.752   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 5.684\n",
      "(Epoch 71 / 10000) Train_Loss: 128.248; Val_Loss: 150.440   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.751\n",
      "(Epoch 72 / 10000) Train_Loss: 126.921; Val_Loss: 155.730   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 4.969\n",
      "(Epoch 73 / 10000) Train_Loss: 126.106; Val_Loss: 156.146   Train_ACC: 15.280; Val_ACC: 19.259   Train_NMI: 0.455; Val_NMI: 4.691\n",
      "(Epoch 74 / 10000) Train_Loss: 125.918; Val_Loss: 155.404   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.205\n",
      "(Epoch 75 / 10000) Train_Loss: 124.897; Val_Loss: 155.893   Train_ACC: 15.404; Val_ACC: 18.148   Train_NMI: 0.527; Val_NMI: 4.382\n",
      "(Epoch 76 / 10000) Train_Loss: 123.255; Val_Loss: 159.126   Train_ACC: 15.486; Val_ACC: 19.259   Train_NMI: 0.484; Val_NMI: 4.935\n",
      "(Epoch 77 / 10000) Train_Loss: 122.378; Val_Loss: 158.700   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.408; Val_NMI: 4.713\n",
      "(Epoch 78 / 10000) Train_Loss: 122.511; Val_Loss: 158.072   Train_ACC: 15.362; Val_ACC: 18.519   Train_NMI: 0.406; Val_NMI: 4.129\n",
      "(Epoch 79 / 10000) Train_Loss: 122.076; Val_Loss: 157.734   Train_ACC: 15.280; Val_ACC: 18.519   Train_NMI: 0.459; Val_NMI: 4.327\n",
      "(Epoch 80 / 10000) Train_Loss: 122.199; Val_Loss: 161.482   Train_ACC: 15.568; Val_ACC: 18.519   Train_NMI: 0.520; Val_NMI: 4.106\n",
      "(Epoch 81 / 10000) Train_Loss: 120.661; Val_Loss: 159.811   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 4.929\n",
      "(Epoch 82 / 10000) Train_Loss: 119.626; Val_Loss: 159.918   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 5.108\n",
      "(Epoch 83 / 10000) Train_Loss: 118.622; Val_Loss: 156.876   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 4.582\n",
      "(Epoch 84 / 10000) Train_Loss: 118.444; Val_Loss: 159.612   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 5.370\n",
      "(Epoch 85 / 10000) Train_Loss: 118.351; Val_Loss: 165.190   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.671\n",
      "(Epoch 86 / 10000) Train_Loss: 117.461; Val_Loss: 159.517   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 4.619\n",
      "(Epoch 87 / 10000) Train_Loss: 116.927; Val_Loss: 153.399   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 4.874\n",
      "(Epoch 88 / 10000) Train_Loss: 115.386; Val_Loss: 157.199   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.435; Val_NMI: 4.592\n",
      "(Epoch 89 / 10000) Train_Loss: 114.236; Val_Loss: 158.118   Train_ACC: 15.362; Val_ACC: 19.630   Train_NMI: 0.449; Val_NMI: 5.724\n",
      "(Epoch 90 / 10000) Train_Loss: 114.454; Val_Loss: 156.227   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.356; Val_NMI: 4.425\n",
      "(Epoch 91 / 10000) Train_Loss: 114.506; Val_Loss: 159.286   Train_ACC: 15.280; Val_ACC: 18.519   Train_NMI: 0.440; Val_NMI: 4.236\n",
      "(Epoch 92 / 10000) Train_Loss: 113.890; Val_Loss: 162.624   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.444; Val_NMI: 4.770\n",
      "(Epoch 93 / 10000) Train_Loss: 112.858; Val_Loss: 160.203   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 5.078\n",
      "(Epoch 94 / 10000) Train_Loss: 111.314; Val_Loss: 161.428   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.425; Val_NMI: 4.944\n",
      "(Epoch 95 / 10000) Train_Loss: 110.910; Val_Loss: 161.428   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 4.913\n",
      "(Epoch 96 / 10000) Train_Loss: 110.814; Val_Loss: 157.810   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.430; Val_NMI: 4.340\n",
      "(Epoch 97 / 10000) Train_Loss: 110.218; Val_Loss: 168.102   Train_ACC: 15.362; Val_ACC: 20.000   Train_NMI: 0.538; Val_NMI: 5.035\n",
      "(Epoch 98 / 10000) Train_Loss: 109.686; Val_Loss: 159.807   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.411; Val_NMI: 5.758\n",
      "(Epoch 99 / 10000) Train_Loss: 108.609; Val_Loss: 160.129   Train_ACC: 15.445; Val_ACC: 20.000   Train_NMI: 0.453; Val_NMI: 5.346\n",
      "(Epoch 100 / 10000) Train_Loss: 107.562; Val_Loss: 165.428   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 4.839\n",
      "(Epoch 101 / 10000) Train_Loss: 107.473; Val_Loss: 161.786   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.387; Val_NMI: 4.285\n",
      "(Epoch 102 / 10000) Train_Loss: 106.275; Val_Loss: 163.523   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.448; Val_NMI: 5.534\n",
      "(Epoch 103 / 10000) Train_Loss: 105.866; Val_Loss: 160.424   Train_ACC: 15.198; Val_ACC: 20.741   Train_NMI: 0.469; Val_NMI: 5.486\n",
      "(Epoch 104 / 10000) Train_Loss: 105.733; Val_Loss: 163.902   Train_ACC: 15.486; Val_ACC: 20.741   Train_NMI: 0.418; Val_NMI: 5.259\n",
      "(Epoch 105 / 10000) Train_Loss: 104.871; Val_Loss: 164.800   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.750\n",
      "(Epoch 106 / 10000) Train_Loss: 104.974; Val_Loss: 161.040   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.398; Val_NMI: 4.654\n",
      "(Epoch 107 / 10000) Train_Loss: 103.605; Val_Loss: 167.268   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.410; Val_NMI: 5.738\n",
      "(Epoch 108 / 10000) Train_Loss: 103.797; Val_Loss: 162.725   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.423; Val_NMI: 5.043\n",
      "(Epoch 109 / 10000) Train_Loss: 102.872; Val_Loss: 169.054   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 4.932\n",
      "(Epoch 110 / 10000) Train_Loss: 101.821; Val_Loss: 163.733   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.434; Val_NMI: 4.987\n",
      "(Epoch 111 / 10000) Train_Loss: 102.250; Val_Loss: 170.341   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 5.524\n",
      "(Epoch 112 / 10000) Train_Loss: 100.805; Val_Loss: 169.415   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.305; Val_NMI: 5.160\n",
      "(Epoch 113 / 10000) Train_Loss: 99.855; Val_Loss: 167.915   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.459; Val_NMI: 5.449\n",
      "(Epoch 114 / 10000) Train_Loss: 99.743; Val_Loss: 169.937   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.403; Val_NMI: 5.412\n",
      "(Epoch 115 / 10000) Train_Loss: 99.556; Val_Loss: 172.119   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.414; Val_NMI: 5.057\n",
      "(Epoch 116 / 10000) Train_Loss: 99.060; Val_Loss: 164.857   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.473; Val_NMI: 5.253\n",
      "(Epoch 117 / 10000) Train_Loss: 99.002; Val_Loss: 173.085   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.444; Val_NMI: 4.950\n",
      "(Epoch 118 / 10000) Train_Loss: 97.718; Val_Loss: 175.400   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.448; Val_NMI: 4.543\n",
      "(Epoch 119 / 10000) Train_Loss: 96.942; Val_Loss: 176.444   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.438; Val_NMI: 4.768\n",
      "(Epoch 120 / 10000) Train_Loss: 96.213; Val_Loss: 178.578   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.438; Val_NMI: 4.697\n",
      "(Epoch 121 / 10000) Train_Loss: 95.467; Val_Loss: 173.834   Train_ACC: 15.404; Val_ACC: 18.889   Train_NMI: 0.473; Val_NMI: 4.518\n",
      "(Epoch 122 / 10000) Train_Loss: 95.417; Val_Loss: 174.574   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.387; Val_NMI: 5.063\n",
      "(Epoch 123 / 10000) Train_Loss: 95.818; Val_Loss: 176.634   Train_ACC: 15.280; Val_ACC: 20.741   Train_NMI: 0.383; Val_NMI: 4.560\n",
      "(Epoch 124 / 10000) Train_Loss: 95.157; Val_Loss: 171.896   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.427; Val_NMI: 5.882\n",
      "(Epoch 125 / 10000) Train_Loss: 94.363; Val_Loss: 177.508   Train_ACC: 15.198; Val_ACC: 20.741   Train_NMI: 0.440; Val_NMI: 5.098\n",
      "(Epoch 126 / 10000) Train_Loss: 93.922; Val_Loss: 179.638   Train_ACC: 15.445; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.954\n",
      "(Epoch 127 / 10000) Train_Loss: 93.310; Val_Loss: 180.152   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 5.279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 128 / 10000) Train_Loss: 92.263; Val_Loss: 181.293   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.425; Val_NMI: 5.086\n",
      "(Epoch 129 / 10000) Train_Loss: 91.838; Val_Loss: 182.697   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.403; Val_NMI: 4.755\n",
      "(Epoch 130 / 10000) Train_Loss: 92.923; Val_Loss: 177.794   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 4.823\n",
      "(Epoch 131 / 10000) Train_Loss: 92.354; Val_Loss: 179.809   Train_ACC: 15.568; Val_ACC: 20.370   Train_NMI: 0.472; Val_NMI: 4.872\n",
      "(Epoch 132 / 10000) Train_Loss: 91.087; Val_Loss: 182.543   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.413; Val_NMI: 5.096\n",
      "(Epoch 133 / 10000) Train_Loss: 90.111; Val_Loss: 180.490   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.340; Val_NMI: 5.761\n",
      "(Epoch 134 / 10000) Train_Loss: 89.185; Val_Loss: 182.536   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.459; Val_NMI: 4.718\n",
      "(Epoch 135 / 10000) Train_Loss: 88.756; Val_Loss: 184.611   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.436; Val_NMI: 5.059\n",
      "(Epoch 136 / 10000) Train_Loss: 89.320; Val_Loss: 191.556   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.505\n",
      "(Epoch 137 / 10000) Train_Loss: 88.600; Val_Loss: 191.125   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.372\n",
      "(Epoch 138 / 10000) Train_Loss: 87.766; Val_Loss: 188.465   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.409; Val_NMI: 5.663\n",
      "(Epoch 139 / 10000) Train_Loss: 87.231; Val_Loss: 195.553   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.209\n",
      "(Epoch 140 / 10000) Train_Loss: 87.658; Val_Loss: 190.358   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.404; Val_NMI: 4.670\n",
      "(Epoch 141 / 10000) Train_Loss: 88.081; Val_Loss: 191.479   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.505; Val_NMI: 4.443\n",
      "(Epoch 142 / 10000) Train_Loss: 87.874; Val_Loss: 196.159   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 5.017\n",
      "(Epoch 143 / 10000) Train_Loss: 85.886; Val_Loss: 183.110   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.465; Val_NMI: 4.862\n",
      "(Epoch 144 / 10000) Train_Loss: 85.293; Val_Loss: 191.016   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.410; Val_NMI: 4.702\n",
      "(Epoch 145 / 10000) Train_Loss: 85.197; Val_Loss: 192.659   Train_ACC: 15.321; Val_ACC: 19.259   Train_NMI: 0.439; Val_NMI: 4.729\n",
      "(Epoch 146 / 10000) Train_Loss: 84.668; Val_Loss: 201.319   Train_ACC: 15.280; Val_ACC: 18.889   Train_NMI: 0.483; Val_NMI: 4.295\n",
      "(Epoch 147 / 10000) Train_Loss: 84.151; Val_Loss: 199.970   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.408; Val_NMI: 4.156\n",
      "(Epoch 148 / 10000) Train_Loss: 83.458; Val_Loss: 195.621   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.414; Val_NMI: 4.780\n",
      "(Epoch 149 / 10000) Train_Loss: 83.398; Val_Loss: 192.617   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.390; Val_NMI: 5.141\n",
      "(Epoch 150 / 10000) Train_Loss: 82.585; Val_Loss: 199.936   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.158\n",
      "(Epoch 151 / 10000) Train_Loss: 82.071; Val_Loss: 199.912   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.414; Val_NMI: 5.235\n",
      "(Epoch 152 / 10000) Train_Loss: 82.274; Val_Loss: 204.878   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 4.946\n",
      "(Epoch 153 / 10000) Train_Loss: 82.489; Val_Loss: 199.993   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 4.447\n",
      "(Epoch 154 / 10000) Train_Loss: 80.293; Val_Loss: 198.386   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.482; Val_NMI: 5.506\n",
      "(Epoch 155 / 10000) Train_Loss: 80.319; Val_Loss: 206.457   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 4.898\n",
      "(Epoch 156 / 10000) Train_Loss: 79.844; Val_Loss: 200.270   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.372; Val_NMI: 4.963\n",
      "(Epoch 157 / 10000) Train_Loss: 80.109; Val_Loss: 211.917   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.917\n",
      "(Epoch 158 / 10000) Train_Loss: 80.231; Val_Loss: 205.782   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.963\n",
      "(Epoch 159 / 10000) Train_Loss: 79.159; Val_Loss: 206.852   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 4.654\n",
      "(Epoch 160 / 10000) Train_Loss: 79.754; Val_Loss: 197.439   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.698\n",
      "(Epoch 161 / 10000) Train_Loss: 79.845; Val_Loss: 210.848   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.411; Val_NMI: 4.856\n",
      "(Epoch 162 / 10000) Train_Loss: 79.395; Val_Loss: 206.619   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.823\n",
      "(Epoch 163 / 10000) Train_Loss: 78.114; Val_Loss: 208.116   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 5.180\n",
      "(Epoch 164 / 10000) Train_Loss: 77.628; Val_Loss: 206.222   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.719\n",
      "(Epoch 165 / 10000) Train_Loss: 76.813; Val_Loss: 222.646   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 4.759\n",
      "(Epoch 166 / 10000) Train_Loss: 76.120; Val_Loss: 217.127   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.819\n",
      "(Epoch 167 / 10000) Train_Loss: 76.819; Val_Loss: 212.970   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.332; Val_NMI: 4.763\n",
      "(Epoch 168 / 10000) Train_Loss: 76.239; Val_Loss: 220.476   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.338; Val_NMI: 4.649\n",
      "(Epoch 169 / 10000) Train_Loss: 75.803; Val_Loss: 217.357   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.415; Val_NMI: 4.684\n",
      "(Epoch 170 / 10000) Train_Loss: 76.032; Val_Loss: 220.771   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.470; Val_NMI: 5.193\n",
      "(Epoch 171 / 10000) Train_Loss: 76.197; Val_Loss: 225.454   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 5.087\n",
      "(Epoch 172 / 10000) Train_Loss: 74.491; Val_Loss: 222.067   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 4.345\n",
      "(Epoch 173 / 10000) Train_Loss: 75.024; Val_Loss: 225.692   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.346; Val_NMI: 4.473\n",
      "(Epoch 174 / 10000) Train_Loss: 74.462; Val_Loss: 233.087   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 4.852\n",
      "(Epoch 175 / 10000) Train_Loss: 74.212; Val_Loss: 229.319   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 5.945\n",
      "(Epoch 176 / 10000) Train_Loss: 72.623; Val_Loss: 223.696   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.892\n",
      "(Epoch 177 / 10000) Train_Loss: 72.318; Val_Loss: 228.229   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.897\n",
      "(Epoch 178 / 10000) Train_Loss: 73.255; Val_Loss: 222.903   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.556\n",
      "(Epoch 179 / 10000) Train_Loss: 73.488; Val_Loss: 230.406   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.435; Val_NMI: 4.157\n",
      "(Epoch 180 / 10000) Train_Loss: 73.118; Val_Loss: 236.830   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.394; Val_NMI: 4.595\n",
      "(Epoch 181 / 10000) Train_Loss: 72.078; Val_Loss: 237.698   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.234\n",
      "(Epoch 182 / 10000) Train_Loss: 71.058; Val_Loss: 233.402   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 5.106\n",
      "(Epoch 183 / 10000) Train_Loss: 72.719; Val_Loss: 231.691   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 5.074\n",
      "(Epoch 184 / 10000) Train_Loss: 70.894; Val_Loss: 235.343   Train_ACC: 15.280; Val_ACC: 19.630   Train_NMI: 0.435; Val_NMI: 3.933\n",
      "(Epoch 185 / 10000) Train_Loss: 70.275; Val_Loss: 243.290   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.400; Val_NMI: 4.140\n",
      "(Epoch 186 / 10000) Train_Loss: 72.418; Val_Loss: 243.112   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.382; Val_NMI: 5.296\n",
      "(Epoch 187 / 10000) Train_Loss: 71.427; Val_Loss: 242.529   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 5.065\n",
      "(Epoch 188 / 10000) Train_Loss: 70.202; Val_Loss: 247.986   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 5.332\n",
      "(Epoch 189 / 10000) Train_Loss: 67.989; Val_Loss: 244.186   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.750\n",
      "(Epoch 190 / 10000) Train_Loss: 68.327; Val_Loss: 250.867   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 5.000\n",
      "(Epoch 191 / 10000) Train_Loss: 67.812; Val_Loss: 256.063   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 192 / 10000) Train_Loss: 68.213; Val_Loss: 242.640   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.446\n",
      "(Epoch 193 / 10000) Train_Loss: 69.653; Val_Loss: 247.628   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.381; Val_NMI: 4.194\n",
      "(Epoch 194 / 10000) Train_Loss: 70.400; Val_Loss: 249.313   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.430; Val_NMI: 4.450\n",
      "(Epoch 195 / 10000) Train_Loss: 68.442; Val_Loss: 247.511   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.454; Val_NMI: 4.613\n",
      "(Epoch 196 / 10000) Train_Loss: 67.712; Val_Loss: 259.629   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.347; Val_NMI: 4.855\n",
      "(Epoch 197 / 10000) Train_Loss: 68.229; Val_Loss: 260.737   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.117\n",
      "(Epoch 198 / 10000) Train_Loss: 67.056; Val_Loss: 248.536   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 5.207\n",
      "(Epoch 199 / 10000) Train_Loss: 66.550; Val_Loss: 256.884   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.964\n",
      "(Epoch 200 / 10000) Train_Loss: 68.164; Val_Loss: 268.484   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.709\n",
      "(Epoch 201 / 10000) Train_Loss: 67.129; Val_Loss: 275.541   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 4.977\n",
      "(Epoch 202 / 10000) Train_Loss: 67.017; Val_Loss: 249.422   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 4.032\n",
      "(Epoch 203 / 10000) Train_Loss: 67.049; Val_Loss: 260.005   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 5.855\n",
      "(Epoch 204 / 10000) Train_Loss: 68.257; Val_Loss: 274.203   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.443\n",
      "(Epoch 205 / 10000) Train_Loss: 67.380; Val_Loss: 263.071   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.712\n",
      "(Epoch 206 / 10000) Train_Loss: 65.481; Val_Loss: 253.065   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.422\n",
      "(Epoch 207 / 10000) Train_Loss: 65.939; Val_Loss: 263.867   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.772\n",
      "(Epoch 208 / 10000) Train_Loss: 65.715; Val_Loss: 268.352   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.480\n",
      "(Epoch 209 / 10000) Train_Loss: 64.714; Val_Loss: 270.376   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 4.351\n",
      "(Epoch 210 / 10000) Train_Loss: 64.882; Val_Loss: 276.047   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.398; Val_NMI: 4.803\n",
      "(Epoch 211 / 10000) Train_Loss: 64.840; Val_Loss: 279.545   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.429; Val_NMI: 4.950\n",
      "(Epoch 212 / 10000) Train_Loss: 63.433; Val_Loss: 269.318   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.439\n",
      "(Epoch 213 / 10000) Train_Loss: 63.554; Val_Loss: 267.529   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 5.454\n",
      "(Epoch 214 / 10000) Train_Loss: 65.047; Val_Loss: 282.487   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.431\n",
      "(Epoch 215 / 10000) Train_Loss: 64.687; Val_Loss: 278.573   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 4.268\n",
      "(Epoch 216 / 10000) Train_Loss: 64.043; Val_Loss: 281.675   Train_ACC: 15.033; Val_ACC: 18.148   Train_NMI: 0.419; Val_NMI: 4.706\n",
      "(Epoch 217 / 10000) Train_Loss: 62.750; Val_Loss: 271.417   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 5.158\n",
      "(Epoch 218 / 10000) Train_Loss: 62.286; Val_Loss: 278.390   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.382; Val_NMI: 4.464\n",
      "(Epoch 219 / 10000) Train_Loss: 63.140; Val_Loss: 278.191   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 4.742\n",
      "(Epoch 220 / 10000) Train_Loss: 62.169; Val_Loss: 294.465   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.020\n",
      "(Epoch 221 / 10000) Train_Loss: 64.394; Val_Loss: 280.908   Train_ACC: 14.745; Val_ACC: 18.519   Train_NMI: 0.377; Val_NMI: 4.639\n",
      "(Epoch 222 / 10000) Train_Loss: 62.270; Val_Loss: 288.495   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.392; Val_NMI: 4.250\n",
      "(Epoch 223 / 10000) Train_Loss: 63.386; Val_Loss: 271.817   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.451; Val_NMI: 5.128\n",
      "(Epoch 224 / 10000) Train_Loss: 62.068; Val_Loss: 292.118   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.341; Val_NMI: 5.360\n",
      "(Epoch 225 / 10000) Train_Loss: 62.191; Val_Loss: 288.858   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.344\n",
      "(Epoch 226 / 10000) Train_Loss: 63.110; Val_Loss: 286.069   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.413; Val_NMI: 5.340\n",
      "(Epoch 227 / 10000) Train_Loss: 62.576; Val_Loss: 271.562   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.449; Val_NMI: 5.176\n",
      "(Epoch 228 / 10000) Train_Loss: 62.355; Val_Loss: 289.388   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 5.138\n",
      "(Epoch 229 / 10000) Train_Loss: 61.573; Val_Loss: 286.647   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 4.562\n",
      "(Epoch 230 / 10000) Train_Loss: 61.447; Val_Loss: 293.233   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.415; Val_NMI: 5.294\n",
      "(Epoch 231 / 10000) Train_Loss: 60.403; Val_Loss: 302.810   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.343; Val_NMI: 5.268\n",
      "(Epoch 232 / 10000) Train_Loss: 59.509; Val_Loss: 290.830   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.973\n",
      "(Epoch 233 / 10000) Train_Loss: 59.764; Val_Loss: 289.564   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.880\n",
      "(Epoch 234 / 10000) Train_Loss: 59.333; Val_Loss: 320.990   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.314; Val_NMI: 4.323\n",
      "(Epoch 235 / 10000) Train_Loss: 59.597; Val_Loss: 300.764   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.402; Val_NMI: 4.074\n",
      "(Epoch 236 / 10000) Train_Loss: 58.738; Val_Loss: 303.478   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.763\n",
      "(Epoch 237 / 10000) Train_Loss: 58.080; Val_Loss: 300.267   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.830\n",
      "(Epoch 238 / 10000) Train_Loss: 58.347; Val_Loss: 312.284   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 4.005\n",
      "(Epoch 239 / 10000) Train_Loss: 58.734; Val_Loss: 316.783   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.424; Val_NMI: 4.133\n",
      "(Epoch 240 / 10000) Train_Loss: 59.439; Val_Loss: 305.941   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 4.356\n",
      "(Epoch 241 / 10000) Train_Loss: 59.469; Val_Loss: 317.610   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.536\n",
      "(Epoch 242 / 10000) Train_Loss: 60.447; Val_Loss: 290.605   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.358; Val_NMI: 4.384\n",
      "(Epoch 243 / 10000) Train_Loss: 58.959; Val_Loss: 301.637   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.303; Val_NMI: 4.597\n",
      "(Epoch 244 / 10000) Train_Loss: 58.302; Val_Loss: 307.953   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 4.291\n",
      "(Epoch 245 / 10000) Train_Loss: 59.315; Val_Loss: 304.760   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 4.347\n",
      "(Epoch 246 / 10000) Train_Loss: 58.122; Val_Loss: 302.386   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 4.194\n",
      "(Epoch 247 / 10000) Train_Loss: 56.729; Val_Loss: 320.651   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.358; Val_NMI: 4.674\n",
      "(Epoch 248 / 10000) Train_Loss: 57.189; Val_Loss: 297.358   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.373; Val_NMI: 4.641\n",
      "(Epoch 249 / 10000) Train_Loss: 56.356; Val_Loss: 333.425   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.785\n",
      "(Epoch 250 / 10000) Train_Loss: 56.399; Val_Loss: 331.084   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 4.198\n",
      "(Epoch 251 / 10000) Train_Loss: 57.685; Val_Loss: 327.411   Train_ACC: 14.292; Val_ACC: 18.889   Train_NMI: 0.310; Val_NMI: 4.177\n",
      "(Epoch 252 / 10000) Train_Loss: 58.163; Val_Loss: 320.440   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.808\n",
      "(Epoch 253 / 10000) Train_Loss: 57.825; Val_Loss: 315.916   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.721\n",
      "(Epoch 254 / 10000) Train_Loss: 57.415; Val_Loss: 340.555   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.290; Val_NMI: 4.638\n",
      "(Epoch 255 / 10000) Train_Loss: 56.967; Val_Loss: 324.191   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 5.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 256 / 10000) Train_Loss: 56.664; Val_Loss: 335.167   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.449; Val_NMI: 4.758\n",
      "(Epoch 257 / 10000) Train_Loss: 56.761; Val_Loss: 324.367   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.646\n",
      "(Epoch 258 / 10000) Train_Loss: 56.556; Val_Loss: 317.353   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.309; Val_NMI: 4.839\n",
      "(Epoch 259 / 10000) Train_Loss: 56.854; Val_Loss: 331.782   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.377; Val_NMI: 4.534\n",
      "(Epoch 260 / 10000) Train_Loss: 56.191; Val_Loss: 322.213   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.315; Val_NMI: 4.683\n",
      "(Epoch 261 / 10000) Train_Loss: 55.724; Val_Loss: 331.254   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.939\n",
      "(Epoch 262 / 10000) Train_Loss: 54.768; Val_Loss: 320.391   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.693\n",
      "(Epoch 263 / 10000) Train_Loss: 55.794; Val_Loss: 343.088   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.545\n",
      "(Epoch 264 / 10000) Train_Loss: 56.559; Val_Loss: 335.098   Train_ACC: 14.415; Val_ACC: 20.000   Train_NMI: 0.292; Val_NMI: 5.570\n",
      "(Epoch 265 / 10000) Train_Loss: 55.511; Val_Loss: 351.909   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 5.311\n",
      "(Epoch 266 / 10000) Train_Loss: 54.796; Val_Loss: 338.643   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.287; Val_NMI: 5.292\n",
      "(Epoch 267 / 10000) Train_Loss: 54.803; Val_Loss: 341.372   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.280; Val_NMI: 5.070\n",
      "(Epoch 268 / 10000) Train_Loss: 54.006; Val_Loss: 344.774   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 4.552\n",
      "(Epoch 269 / 10000) Train_Loss: 55.099; Val_Loss: 326.915   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.406; Val_NMI: 4.914\n",
      "(Epoch 270 / 10000) Train_Loss: 55.473; Val_Loss: 341.660   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 4.799\n",
      "(Epoch 271 / 10000) Train_Loss: 55.408; Val_Loss: 343.844   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 5.484\n",
      "(Epoch 272 / 10000) Train_Loss: 55.320; Val_Loss: 368.473   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.352; Val_NMI: 5.624\n",
      "(Epoch 273 / 10000) Train_Loss: 56.073; Val_Loss: 342.034   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.507\n",
      "(Epoch 274 / 10000) Train_Loss: 55.510; Val_Loss: 360.178   Train_ACC: 14.456; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 5.085\n",
      "(Epoch 275 / 10000) Train_Loss: 54.184; Val_Loss: 336.702   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 5.587\n",
      "(Epoch 276 / 10000) Train_Loss: 53.596; Val_Loss: 333.080   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 3.996\n",
      "(Epoch 277 / 10000) Train_Loss: 53.159; Val_Loss: 341.039   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.565\n",
      "(Epoch 278 / 10000) Train_Loss: 53.610; Val_Loss: 348.604   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.391; Val_NMI: 4.853\n",
      "(Epoch 279 / 10000) Train_Loss: 52.730; Val_Loss: 339.189   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.901\n",
      "(Epoch 280 / 10000) Train_Loss: 54.832; Val_Loss: 327.379   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.407; Val_NMI: 5.015\n",
      "(Epoch 281 / 10000) Train_Loss: 54.388; Val_Loss: 357.766   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.682\n",
      "(Epoch 282 / 10000) Train_Loss: 54.585; Val_Loss: 353.389   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 4.865\n",
      "(Epoch 283 / 10000) Train_Loss: 56.735; Val_Loss: 355.324   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.691\n",
      "(Epoch 284 / 10000) Train_Loss: 55.578; Val_Loss: 353.346   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 4.853\n",
      "(Epoch 285 / 10000) Train_Loss: 53.356; Val_Loss: 353.931   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.893\n",
      "(Epoch 286 / 10000) Train_Loss: 52.306; Val_Loss: 347.016   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.420; Val_NMI: 4.167\n",
      "(Epoch 287 / 10000) Train_Loss: 53.463; Val_Loss: 360.148   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.441; Val_NMI: 5.066\n",
      "(Epoch 288 / 10000) Train_Loss: 52.300; Val_Loss: 356.130   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 5.367\n",
      "(Epoch 289 / 10000) Train_Loss: 51.766; Val_Loss: 361.467   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 5.242\n",
      "(Epoch 290 / 10000) Train_Loss: 51.446; Val_Loss: 362.598   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.433; Val_NMI: 5.343\n",
      "(Epoch 291 / 10000) Train_Loss: 52.795; Val_Loss: 368.687   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 5.712\n",
      "(Epoch 292 / 10000) Train_Loss: 52.642; Val_Loss: 366.060   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.461; Val_NMI: 5.052\n",
      "(Epoch 293 / 10000) Train_Loss: 51.610; Val_Loss: 362.702   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 4.817\n",
      "(Epoch 294 / 10000) Train_Loss: 52.038; Val_Loss: 370.087   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.290; Val_NMI: 4.729\n",
      "(Epoch 295 / 10000) Train_Loss: 50.685; Val_Loss: 370.785   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 4.929\n",
      "(Epoch 296 / 10000) Train_Loss: 52.567; Val_Loss: 360.592   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 4.986\n",
      "(Epoch 297 / 10000) Train_Loss: 51.466; Val_Loss: 374.827   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 5.061\n",
      "(Epoch 298 / 10000) Train_Loss: 51.069; Val_Loss: 372.604   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 5.467\n",
      "(Epoch 299 / 10000) Train_Loss: 51.332; Val_Loss: 347.512   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.338; Val_NMI: 5.152\n",
      "(Epoch 300 / 10000) Train_Loss: 51.212; Val_Loss: 367.005   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.906\n",
      "(Epoch 301 / 10000) Train_Loss: 50.943; Val_Loss: 382.472   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.481; Val_NMI: 5.751\n",
      "(Epoch 302 / 10000) Train_Loss: 50.194; Val_Loss: 406.883   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.376; Val_NMI: 5.201\n",
      "(Epoch 303 / 10000) Train_Loss: 51.689; Val_Loss: 406.074   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 4.809\n",
      "(Epoch 304 / 10000) Train_Loss: 50.722; Val_Loss: 387.179   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 5.529\n",
      "(Epoch 305 / 10000) Train_Loss: 50.087; Val_Loss: 379.502   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.145\n",
      "(Epoch 306 / 10000) Train_Loss: 50.794; Val_Loss: 372.880   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 4.854\n",
      "(Epoch 307 / 10000) Train_Loss: 51.544; Val_Loss: 367.782   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 5.356\n",
      "(Epoch 308 / 10000) Train_Loss: 50.636; Val_Loss: 371.099   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 5.035\n",
      "(Epoch 309 / 10000) Train_Loss: 50.237; Val_Loss: 381.884   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.962\n",
      "(Epoch 310 / 10000) Train_Loss: 49.389; Val_Loss: 363.342   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.440; Val_NMI: 5.516\n",
      "(Epoch 311 / 10000) Train_Loss: 49.488; Val_Loss: 365.023   Train_ACC: 15.321; Val_ACC: 19.630   Train_NMI: 0.515; Val_NMI: 4.858\n",
      "(Epoch 312 / 10000) Train_Loss: 51.305; Val_Loss: 384.560   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.448; Val_NMI: 5.360\n",
      "(Epoch 313 / 10000) Train_Loss: 50.937; Val_Loss: 373.739   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 4.950\n",
      "(Epoch 314 / 10000) Train_Loss: 50.356; Val_Loss: 379.359   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.425; Val_NMI: 4.561\n",
      "(Epoch 315 / 10000) Train_Loss: 51.532; Val_Loss: 369.305   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.425; Val_NMI: 3.815\n",
      "(Epoch 316 / 10000) Train_Loss: 50.024; Val_Loss: 388.378   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.520\n",
      "(Epoch 317 / 10000) Train_Loss: 49.232; Val_Loss: 384.117   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.446; Val_NMI: 4.602\n",
      "(Epoch 318 / 10000) Train_Loss: 48.382; Val_Loss: 388.947   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 4.690\n",
      "(Epoch 319 / 10000) Train_Loss: 49.100; Val_Loss: 395.652   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 320 / 10000) Train_Loss: 49.030; Val_Loss: 377.318   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 4.700\n",
      "(Epoch 321 / 10000) Train_Loss: 49.461; Val_Loss: 398.126   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 5.456\n",
      "(Epoch 322 / 10000) Train_Loss: 48.684; Val_Loss: 370.624   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.393; Val_NMI: 4.204\n",
      "(Epoch 323 / 10000) Train_Loss: 47.931; Val_Loss: 403.398   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.314; Val_NMI: 5.632\n",
      "(Epoch 324 / 10000) Train_Loss: 48.238; Val_Loss: 390.438   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.595\n",
      "(Epoch 325 / 10000) Train_Loss: 49.658; Val_Loss: 396.127   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.416; Val_NMI: 5.693\n",
      "(Epoch 326 / 10000) Train_Loss: 49.280; Val_Loss: 409.767   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 4.914\n",
      "(Epoch 327 / 10000) Train_Loss: 49.809; Val_Loss: 387.810   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 4.784\n",
      "(Epoch 328 / 10000) Train_Loss: 50.705; Val_Loss: 398.323   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.852\n",
      "(Epoch 329 / 10000) Train_Loss: 49.519; Val_Loss: 432.815   Train_ACC: 14.415; Val_ACC: 19.630   Train_NMI: 0.291; Val_NMI: 4.909\n",
      "(Epoch 330 / 10000) Train_Loss: 50.797; Val_Loss: 418.826   Train_ACC: 15.239; Val_ACC: 20.741   Train_NMI: 0.394; Val_NMI: 5.422\n",
      "(Epoch 331 / 10000) Train_Loss: 50.563; Val_Loss: 405.222   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.728\n",
      "(Epoch 332 / 10000) Train_Loss: 50.252; Val_Loss: 415.466   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.890\n",
      "(Epoch 333 / 10000) Train_Loss: 49.614; Val_Loss: 413.032   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 4.554\n",
      "(Epoch 334 / 10000) Train_Loss: 48.905; Val_Loss: 421.818   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.442; Val_NMI: 4.751\n",
      "(Epoch 335 / 10000) Train_Loss: 48.964; Val_Loss: 417.056   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.377; Val_NMI: 4.978\n",
      "(Epoch 336 / 10000) Train_Loss: 49.355; Val_Loss: 403.009   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 4.629\n",
      "(Epoch 337 / 10000) Train_Loss: 49.882; Val_Loss: 401.838   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 5.086\n",
      "(Epoch 338 / 10000) Train_Loss: 50.507; Val_Loss: 404.895   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 3.970\n",
      "(Epoch 339 / 10000) Train_Loss: 50.318; Val_Loss: 415.555   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.351; Val_NMI: 3.735\n",
      "(Epoch 340 / 10000) Train_Loss: 50.225; Val_Loss: 417.286   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.286; Val_NMI: 4.898\n",
      "(Epoch 341 / 10000) Train_Loss: 48.023; Val_Loss: 420.667   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.618\n",
      "(Epoch 342 / 10000) Train_Loss: 48.150; Val_Loss: 432.645   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.388; Val_NMI: 4.843\n",
      "(Epoch 343 / 10000) Train_Loss: 48.835; Val_Loss: 396.135   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.734\n",
      "(Epoch 344 / 10000) Train_Loss: 48.103; Val_Loss: 399.603   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 5.216\n",
      "(Epoch 345 / 10000) Train_Loss: 47.103; Val_Loss: 417.397   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.487\n",
      "(Epoch 346 / 10000) Train_Loss: 47.210; Val_Loss: 433.635   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.441; Val_NMI: 4.443\n",
      "(Epoch 347 / 10000) Train_Loss: 46.184; Val_Loss: 398.181   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.703\n",
      "(Epoch 348 / 10000) Train_Loss: 46.004; Val_Loss: 408.950   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.398; Val_NMI: 4.158\n",
      "(Epoch 349 / 10000) Train_Loss: 44.997; Val_Loss: 382.789   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.306\n",
      "(Epoch 350 / 10000) Train_Loss: 45.339; Val_Loss: 432.838   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.151\n",
      "(Epoch 351 / 10000) Train_Loss: 44.970; Val_Loss: 419.372   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.419; Val_NMI: 4.422\n",
      "(Epoch 352 / 10000) Train_Loss: 45.648; Val_Loss: 428.220   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.368; Val_NMI: 4.905\n",
      "(Epoch 353 / 10000) Train_Loss: 46.215; Val_Loss: 434.933   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.418\n",
      "(Epoch 354 / 10000) Train_Loss: 45.871; Val_Loss: 430.182   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.297\n",
      "(Epoch 355 / 10000) Train_Loss: 46.004; Val_Loss: 428.200   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.406; Val_NMI: 4.811\n",
      "(Epoch 356 / 10000) Train_Loss: 47.138; Val_Loss: 429.728   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.167\n",
      "(Epoch 357 / 10000) Train_Loss: 47.730; Val_Loss: 431.675   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.402; Val_NMI: 4.331\n",
      "(Epoch 358 / 10000) Train_Loss: 48.567; Val_Loss: 450.924   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.398; Val_NMI: 4.486\n",
      "(Epoch 359 / 10000) Train_Loss: 46.379; Val_Loss: 438.705   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.562\n",
      "(Epoch 360 / 10000) Train_Loss: 49.927; Val_Loss: 410.120   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.673\n",
      "(Epoch 361 / 10000) Train_Loss: 51.022; Val_Loss: 438.980   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 4.919\n",
      "(Epoch 362 / 10000) Train_Loss: 52.211; Val_Loss: 454.506   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 5.111\n",
      "(Epoch 363 / 10000) Train_Loss: 50.981; Val_Loss: 429.033   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.608\n",
      "(Epoch 364 / 10000) Train_Loss: 49.166; Val_Loss: 450.838   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.386; Val_NMI: 4.645\n",
      "(Epoch 365 / 10000) Train_Loss: 46.275; Val_Loss: 428.078   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.371; Val_NMI: 4.436\n",
      "(Epoch 366 / 10000) Train_Loss: 44.476; Val_Loss: 433.911   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 4.736\n",
      "(Epoch 367 / 10000) Train_Loss: 44.328; Val_Loss: 448.399   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.369; Val_NMI: 4.827\n",
      "(Epoch 368 / 10000) Train_Loss: 45.956; Val_Loss: 448.065   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.450; Val_NMI: 4.973\n",
      "(Epoch 369 / 10000) Train_Loss: 46.503; Val_Loss: 446.029   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.775\n",
      "(Epoch 370 / 10000) Train_Loss: 47.120; Val_Loss: 411.723   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 4.615\n",
      "(Epoch 371 / 10000) Train_Loss: 45.731; Val_Loss: 424.424   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.405; Val_NMI: 4.811\n",
      "(Epoch 372 / 10000) Train_Loss: 44.212; Val_Loss: 421.212   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.422; Val_NMI: 4.381\n",
      "(Epoch 373 / 10000) Train_Loss: 43.808; Val_Loss: 474.403   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.403; Val_NMI: 4.436\n",
      "(Epoch 374 / 10000) Train_Loss: 44.572; Val_Loss: 430.534   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 4.575\n",
      "(Epoch 375 / 10000) Train_Loss: 44.282; Val_Loss: 439.362   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.366; Val_NMI: 3.984\n",
      "(Epoch 376 / 10000) Train_Loss: 43.884; Val_Loss: 435.359   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.983\n",
      "(Epoch 377 / 10000) Train_Loss: 43.533; Val_Loss: 452.158   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.784\n",
      "(Epoch 378 / 10000) Train_Loss: 44.743; Val_Loss: 476.934   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 4.824\n",
      "(Epoch 379 / 10000) Train_Loss: 46.167; Val_Loss: 449.423   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.562\n",
      "(Epoch 380 / 10000) Train_Loss: 45.765; Val_Loss: 469.479   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 5.058\n",
      "(Epoch 381 / 10000) Train_Loss: 44.408; Val_Loss: 447.676   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.459; Val_NMI: 5.265\n",
      "(Epoch 382 / 10000) Train_Loss: 43.957; Val_Loss: 459.331   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.467; Val_NMI: 5.106\n",
      "(Epoch 383 / 10000) Train_Loss: 44.970; Val_Loss: 457.021   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.473; Val_NMI: 4.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 384 / 10000) Train_Loss: 45.814; Val_Loss: 443.810   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.459; Val_NMI: 5.047\n",
      "(Epoch 385 / 10000) Train_Loss: 45.353; Val_Loss: 459.485   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.349; Val_NMI: 4.469\n",
      "(Epoch 386 / 10000) Train_Loss: 43.694; Val_Loss: 457.357   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.411; Val_NMI: 4.559\n",
      "(Epoch 387 / 10000) Train_Loss: 43.723; Val_Loss: 463.782   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.421; Val_NMI: 4.866\n",
      "(Epoch 388 / 10000) Train_Loss: 44.876; Val_Loss: 449.942   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 4.103\n",
      "(Epoch 389 / 10000) Train_Loss: 43.442; Val_Loss: 456.150   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.990\n",
      "(Epoch 390 / 10000) Train_Loss: 43.756; Val_Loss: 443.855   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.311; Val_NMI: 5.017\n",
      "(Epoch 391 / 10000) Train_Loss: 43.841; Val_Loss: 466.655   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 5.605\n",
      "(Epoch 392 / 10000) Train_Loss: 43.069; Val_Loss: 484.558   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.587\n",
      "(Epoch 393 / 10000) Train_Loss: 42.924; Val_Loss: 434.245   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.417; Val_NMI: 4.993\n",
      "(Epoch 394 / 10000) Train_Loss: 43.090; Val_Loss: 449.240   Train_ACC: 15.280; Val_ACC: 19.259   Train_NMI: 0.446; Val_NMI: 4.809\n",
      "(Epoch 395 / 10000) Train_Loss: 43.556; Val_Loss: 433.366   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.409; Val_NMI: 5.246\n",
      "(Epoch 396 / 10000) Train_Loss: 44.395; Val_Loss: 471.845   Train_ACC: 15.321; Val_ACC: 19.259   Train_NMI: 0.451; Val_NMI: 4.302\n",
      "(Epoch 397 / 10000) Train_Loss: 44.495; Val_Loss: 499.847   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.432; Val_NMI: 3.868\n",
      "(Epoch 398 / 10000) Train_Loss: 44.091; Val_Loss: 461.123   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.426; Val_NMI: 4.664\n",
      "(Epoch 399 / 10000) Train_Loss: 44.556; Val_Loss: 455.213   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 4.402\n",
      "(Epoch 400 / 10000) Train_Loss: 44.715; Val_Loss: 457.464   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.446; Val_NMI: 4.293\n",
      "(Epoch 401 / 10000) Train_Loss: 45.223; Val_Loss: 490.397   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.467; Val_NMI: 4.394\n",
      "(Epoch 402 / 10000) Train_Loss: 43.703; Val_Loss: 489.815   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.412; Val_NMI: 4.437\n",
      "(Epoch 403 / 10000) Train_Loss: 43.340; Val_Loss: 484.093   Train_ACC: 15.321; Val_ACC: 19.630   Train_NMI: 0.438; Val_NMI: 4.476\n",
      "(Epoch 404 / 10000) Train_Loss: 43.935; Val_Loss: 479.047   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 4.666\n",
      "(Epoch 405 / 10000) Train_Loss: 43.258; Val_Loss: 452.479   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.394; Val_NMI: 4.918\n",
      "(Epoch 406 / 10000) Train_Loss: 45.368; Val_Loss: 484.560   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 4.553\n",
      "(Epoch 407 / 10000) Train_Loss: 49.002; Val_Loss: 481.062   Train_ACC: 15.486; Val_ACC: 19.630   Train_NMI: 0.547; Val_NMI: 4.562\n",
      "(Epoch 408 / 10000) Train_Loss: 50.596; Val_Loss: 437.818   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.383; Val_NMI: 4.050\n",
      "(Epoch 409 / 10000) Train_Loss: 49.053; Val_Loss: 479.555   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.409; Val_NMI: 4.161\n",
      "(Epoch 410 / 10000) Train_Loss: 48.048; Val_Loss: 480.915   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.431; Val_NMI: 4.833\n",
      "(Epoch 411 / 10000) Train_Loss: 46.134; Val_Loss: 466.073   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.658\n",
      "(Epoch 412 / 10000) Train_Loss: 45.933; Val_Loss: 460.924   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.959\n",
      "(Epoch 413 / 10000) Train_Loss: 45.318; Val_Loss: 456.196   Train_ACC: 15.321; Val_ACC: 19.259   Train_NMI: 0.446; Val_NMI: 4.681\n",
      "(Epoch 414 / 10000) Train_Loss: 43.954; Val_Loss: 463.537   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.654\n",
      "(Epoch 415 / 10000) Train_Loss: 43.283; Val_Loss: 478.624   Train_ACC: 15.239; Val_ACC: 18.889   Train_NMI: 0.445; Val_NMI: 4.085\n",
      "(Epoch 416 / 10000) Train_Loss: 43.181; Val_Loss: 459.316   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.388; Val_NMI: 4.223\n",
      "(Epoch 417 / 10000) Train_Loss: 41.217; Val_Loss: 482.320   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.418; Val_NMI: 3.930\n",
      "(Epoch 418 / 10000) Train_Loss: 42.035; Val_Loss: 467.133   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.712\n",
      "(Epoch 419 / 10000) Train_Loss: 41.050; Val_Loss: 489.753   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.448; Val_NMI: 4.264\n",
      "(Epoch 420 / 10000) Train_Loss: 40.599; Val_Loss: 476.783   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.797\n",
      "(Epoch 421 / 10000) Train_Loss: 41.957; Val_Loss: 515.648   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.448; Val_NMI: 4.607\n",
      "(Epoch 422 / 10000) Train_Loss: 41.593; Val_Loss: 479.207   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.453; Val_NMI: 4.788\n",
      "(Epoch 423 / 10000) Train_Loss: 42.326; Val_Loss: 492.603   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.721\n",
      "(Epoch 424 / 10000) Train_Loss: 42.295; Val_Loss: 474.727   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.082\n",
      "(Epoch 425 / 10000) Train_Loss: 41.336; Val_Loss: 495.984   Train_ACC: 15.404; Val_ACC: 20.370   Train_NMI: 0.531; Val_NMI: 5.152\n",
      "(Epoch 426 / 10000) Train_Loss: 41.135; Val_Loss: 511.056   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 4.779\n",
      "(Epoch 427 / 10000) Train_Loss: 41.894; Val_Loss: 525.179   Train_ACC: 15.280; Val_ACC: 19.259   Train_NMI: 0.464; Val_NMI: 4.289\n",
      "(Epoch 428 / 10000) Train_Loss: 42.116; Val_Loss: 505.415   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.452; Val_NMI: 4.581\n",
      "(Epoch 429 / 10000) Train_Loss: 43.256; Val_Loss: 499.252   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 4.616\n",
      "(Epoch 430 / 10000) Train_Loss: 42.356; Val_Loss: 477.604   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.118\n",
      "(Epoch 431 / 10000) Train_Loss: 43.163; Val_Loss: 509.512   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 4.820\n",
      "(Epoch 432 / 10000) Train_Loss: 43.219; Val_Loss: 470.639   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.419; Val_NMI: 4.998\n",
      "(Epoch 433 / 10000) Train_Loss: 42.426; Val_Loss: 477.945   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.466; Val_NMI: 5.038\n",
      "(Epoch 434 / 10000) Train_Loss: 42.632; Val_Loss: 482.763   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.455; Val_NMI: 5.224\n",
      "(Epoch 435 / 10000) Train_Loss: 42.395; Val_Loss: 467.599   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.430; Val_NMI: 4.862\n",
      "(Epoch 436 / 10000) Train_Loss: 42.223; Val_Loss: 507.250   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.400; Val_NMI: 5.696\n",
      "(Epoch 437 / 10000) Train_Loss: 42.727; Val_Loss: 472.615   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.408; Val_NMI: 5.149\n",
      "(Epoch 438 / 10000) Train_Loss: 45.622; Val_Loss: 499.225   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.369; Val_NMI: 3.963\n",
      "(Epoch 439 / 10000) Train_Loss: 45.099; Val_Loss: 505.099   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 4.076\n",
      "(Epoch 440 / 10000) Train_Loss: 42.691; Val_Loss: 515.914   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.382; Val_NMI: 4.929\n",
      "(Epoch 441 / 10000) Train_Loss: 46.305; Val_Loss: 505.748   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.393; Val_NMI: 4.221\n",
      "(Epoch 442 / 10000) Train_Loss: 50.738; Val_Loss: 509.313   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.472; Val_NMI: 4.614\n",
      "(Epoch 443 / 10000) Train_Loss: 50.590; Val_Loss: 475.259   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.888\n",
      "(Epoch 444 / 10000) Train_Loss: 45.640; Val_Loss: 484.641   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 5.205\n",
      "(Epoch 445 / 10000) Train_Loss: 42.043; Val_Loss: 508.960   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 5.158\n",
      "(Epoch 446 / 10000) Train_Loss: 41.189; Val_Loss: 490.849   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 5.412\n",
      "(Epoch 447 / 10000) Train_Loss: 40.286; Val_Loss: 483.650   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 5.825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 448 / 10000) Train_Loss: 39.192; Val_Loss: 479.908   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 5.125\n",
      "(Epoch 449 / 10000) Train_Loss: 39.718; Val_Loss: 482.839   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.490\n",
      "(Epoch 450 / 10000) Train_Loss: 39.682; Val_Loss: 510.555   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 5.623\n",
      "(Epoch 451 / 10000) Train_Loss: 39.167; Val_Loss: 482.701   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 4.789\n",
      "(Epoch 452 / 10000) Train_Loss: 39.473; Val_Loss: 520.500   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.391; Val_NMI: 5.778\n",
      "(Epoch 453 / 10000) Train_Loss: 39.911; Val_Loss: 522.559   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.439; Val_NMI: 4.827\n",
      "(Epoch 454 / 10000) Train_Loss: 40.771; Val_Loss: 488.991   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.390; Val_NMI: 4.877\n",
      "(Epoch 455 / 10000) Train_Loss: 41.454; Val_Loss: 505.946   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 5.303\n",
      "(Epoch 456 / 10000) Train_Loss: 41.251; Val_Loss: 530.943   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.429; Val_NMI: 5.476\n",
      "(Epoch 457 / 10000) Train_Loss: 41.727; Val_Loss: 501.327   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 5.026\n",
      "(Epoch 458 / 10000) Train_Loss: 40.864; Val_Loss: 467.657   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 5.146\n",
      "(Epoch 459 / 10000) Train_Loss: 40.074; Val_Loss: 518.385   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.433; Val_NMI: 4.955\n",
      "(Epoch 460 / 10000) Train_Loss: 39.584; Val_Loss: 489.704   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 5.130\n",
      "(Epoch 461 / 10000) Train_Loss: 40.431; Val_Loss: 525.904   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.885\n",
      "(Epoch 462 / 10000) Train_Loss: 40.758; Val_Loss: 531.098   Train_ACC: 15.404; Val_ACC: 20.741   Train_NMI: 0.441; Val_NMI: 5.075\n",
      "(Epoch 463 / 10000) Train_Loss: 39.930; Val_Loss: 482.327   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.586\n",
      "(Epoch 464 / 10000) Train_Loss: 41.111; Val_Loss: 542.868   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 4.814\n",
      "(Epoch 465 / 10000) Train_Loss: 41.287; Val_Loss: 497.579   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.695\n",
      "(Epoch 466 / 10000) Train_Loss: 40.309; Val_Loss: 509.042   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.442; Val_NMI: 4.595\n",
      "(Epoch 467 / 10000) Train_Loss: 40.956; Val_Loss: 512.029   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.853\n",
      "(Epoch 468 / 10000) Train_Loss: 41.004; Val_Loss: 491.545   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.418; Val_NMI: 4.831\n",
      "(Epoch 469 / 10000) Train_Loss: 40.675; Val_Loss: 508.172   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 4.942\n",
      "(Epoch 470 / 10000) Train_Loss: 39.881; Val_Loss: 518.026   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.424; Val_NMI: 5.231\n",
      "(Epoch 471 / 10000) Train_Loss: 39.279; Val_Loss: 538.044   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.432; Val_NMI: 4.934\n",
      "(Epoch 472 / 10000) Train_Loss: 39.364; Val_Loss: 521.417   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.346\n",
      "(Epoch 473 / 10000) Train_Loss: 39.805; Val_Loss: 526.391   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.223\n",
      "(Epoch 474 / 10000) Train_Loss: 40.400; Val_Loss: 550.314   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.543\n",
      "(Epoch 475 / 10000) Train_Loss: 40.308; Val_Loss: 534.044   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.418; Val_NMI: 4.886\n",
      "(Epoch 476 / 10000) Train_Loss: 40.009; Val_Loss: 525.630   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.336\n",
      "(Epoch 477 / 10000) Train_Loss: 40.288; Val_Loss: 528.709   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 6.509\n",
      "(Epoch 478 / 10000) Train_Loss: 42.109; Val_Loss: 545.893   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.469; Val_NMI: 5.435\n",
      "(Epoch 479 / 10000) Train_Loss: 42.563; Val_Loss: 533.579   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.452; Val_NMI: 5.391\n",
      "(Epoch 480 / 10000) Train_Loss: 43.195; Val_Loss: 491.067   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.411; Val_NMI: 5.145\n",
      "(Epoch 481 / 10000) Train_Loss: 42.747; Val_Loss: 508.571   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.459; Val_NMI: 5.037\n",
      "(Epoch 482 / 10000) Train_Loss: 42.103; Val_Loss: 546.187   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.419; Val_NMI: 5.002\n",
      "(Epoch 483 / 10000) Train_Loss: 43.875; Val_Loss: 533.019   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 5.600\n",
      "(Epoch 484 / 10000) Train_Loss: 44.738; Val_Loss: 506.230   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.500; Val_NMI: 4.822\n",
      "(Epoch 485 / 10000) Train_Loss: 41.688; Val_Loss: 501.408   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.827\n",
      "(Epoch 486 / 10000) Train_Loss: 41.783; Val_Loss: 520.111   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.345; Val_NMI: 5.839\n",
      "(Epoch 487 / 10000) Train_Loss: 39.877; Val_Loss: 499.333   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.443; Val_NMI: 4.173\n",
      "(Epoch 488 / 10000) Train_Loss: 39.843; Val_Loss: 506.330   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.491; Val_NMI: 5.009\n",
      "(Epoch 489 / 10000) Train_Loss: 39.956; Val_Loss: 511.862   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 5.107\n",
      "(Epoch 490 / 10000) Train_Loss: 39.569; Val_Loss: 560.599   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.456; Val_NMI: 5.156\n",
      "(Epoch 491 / 10000) Train_Loss: 38.955; Val_Loss: 495.355   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.466; Val_NMI: 4.879\n",
      "(Epoch 492 / 10000) Train_Loss: 39.567; Val_Loss: 547.178   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.440; Val_NMI: 5.338\n",
      "(Epoch 493 / 10000) Train_Loss: 41.596; Val_Loss: 537.936   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.461; Val_NMI: 5.536\n",
      "(Epoch 494 / 10000) Train_Loss: 41.236; Val_Loss: 572.130   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.466; Val_NMI: 4.351\n",
      "(Epoch 495 / 10000) Train_Loss: 41.358; Val_Loss: 529.670   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.611\n",
      "(Epoch 496 / 10000) Train_Loss: 40.196; Val_Loss: 520.247   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.411; Val_NMI: 5.071\n",
      "(Epoch 497 / 10000) Train_Loss: 39.329; Val_Loss: 511.405   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 4.940\n",
      "(Epoch 498 / 10000) Train_Loss: 38.872; Val_Loss: 565.850   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.476; Val_NMI: 4.950\n",
      "(Epoch 499 / 10000) Train_Loss: 38.964; Val_Loss: 572.599   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 4.911\n",
      "(Epoch 500 / 10000) Train_Loss: 38.641; Val_Loss: 546.403   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.722\n",
      "(Epoch 501 / 10000) Train_Loss: 39.399; Val_Loss: 510.996   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.377; Val_NMI: 5.306\n",
      "(Epoch 502 / 10000) Train_Loss: 38.817; Val_Loss: 548.119   Train_ACC: 15.321; Val_ACC: 20.370   Train_NMI: 0.426; Val_NMI: 5.088\n",
      "(Epoch 503 / 10000) Train_Loss: 39.011; Val_Loss: 550.694   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.467; Val_NMI: 4.787\n",
      "(Epoch 504 / 10000) Train_Loss: 39.529; Val_Loss: 565.810   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.434; Val_NMI: 4.690\n",
      "(Epoch 505 / 10000) Train_Loss: 39.316; Val_Loss: 532.326   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.423; Val_NMI: 4.756\n",
      "(Epoch 506 / 10000) Train_Loss: 39.466; Val_Loss: 521.034   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.434; Val_NMI: 4.949\n",
      "(Epoch 507 / 10000) Train_Loss: 39.873; Val_Loss: 555.195   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.424; Val_NMI: 4.784\n",
      "(Epoch 508 / 10000) Train_Loss: 42.268; Val_Loss: 544.920   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.455; Val_NMI: 4.713\n",
      "(Epoch 509 / 10000) Train_Loss: 45.573; Val_Loss: 530.655   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.463; Val_NMI: 4.694\n",
      "(Epoch 510 / 10000) Train_Loss: 48.813; Val_Loss: 556.920   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.420; Val_NMI: 5.210\n",
      "(Epoch 511 / 10000) Train_Loss: 48.379; Val_Loss: 519.846   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.422; Val_NMI: 4.742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 512 / 10000) Train_Loss: 43.770; Val_Loss: 536.394   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.135\n",
      "(Epoch 513 / 10000) Train_Loss: 40.487; Val_Loss: 471.492   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.491; Val_NMI: 4.635\n",
      "(Epoch 514 / 10000) Train_Loss: 38.746; Val_Loss: 538.748   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.425; Val_NMI: 4.929\n",
      "(Epoch 515 / 10000) Train_Loss: 37.905; Val_Loss: 551.176   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.438; Val_NMI: 4.603\n",
      "(Epoch 516 / 10000) Train_Loss: 37.797; Val_Loss: 564.235   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 4.256\n",
      "(Epoch 517 / 10000) Train_Loss: 41.660; Val_Loss: 533.889   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 4.499\n",
      "(Epoch 518 / 10000) Train_Loss: 40.837; Val_Loss: 545.583   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.525\n",
      "(Epoch 519 / 10000) Train_Loss: 40.230; Val_Loss: 544.765   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 4.218\n",
      "(Epoch 520 / 10000) Train_Loss: 38.660; Val_Loss: 541.824   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.778\n",
      "(Epoch 521 / 10000) Train_Loss: 38.990; Val_Loss: 499.680   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 4.966\n",
      "(Epoch 522 / 10000) Train_Loss: 39.300; Val_Loss: 566.434   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 4.840\n",
      "(Epoch 523 / 10000) Train_Loss: 38.757; Val_Loss: 539.342   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.387\n",
      "(Epoch 524 / 10000) Train_Loss: 37.439; Val_Loss: 587.539   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.437; Val_NMI: 4.786\n",
      "(Epoch 525 / 10000) Train_Loss: 37.725; Val_Loss: 554.158   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 5.064\n",
      "(Epoch 526 / 10000) Train_Loss: 36.594; Val_Loss: 586.951   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.382; Val_NMI: 4.728\n",
      "(Epoch 527 / 10000) Train_Loss: 37.633; Val_Loss: 536.624   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 4.865\n",
      "(Epoch 528 / 10000) Train_Loss: 36.668; Val_Loss: 571.819   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.762\n",
      "(Epoch 529 / 10000) Train_Loss: 37.043; Val_Loss: 563.262   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.963\n",
      "(Epoch 530 / 10000) Train_Loss: 37.213; Val_Loss: 593.815   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 4.958\n",
      "(Epoch 531 / 10000) Train_Loss: 37.403; Val_Loss: 548.965   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.436; Val_NMI: 5.233\n",
      "(Epoch 532 / 10000) Train_Loss: 38.676; Val_Loss: 584.634   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 5.045\n",
      "(Epoch 533 / 10000) Train_Loss: 39.000; Val_Loss: 594.279   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.414; Val_NMI: 4.832\n",
      "(Epoch 534 / 10000) Train_Loss: 39.553; Val_Loss: 553.261   Train_ACC: 15.404; Val_ACC: 19.630   Train_NMI: 0.495; Val_NMI: 4.501\n",
      "(Epoch 535 / 10000) Train_Loss: 38.891; Val_Loss: 531.294   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.407; Val_NMI: 4.899\n",
      "(Epoch 536 / 10000) Train_Loss: 38.295; Val_Loss: 568.460   Train_ACC: 15.321; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 4.708\n",
      "(Epoch 537 / 10000) Train_Loss: 38.508; Val_Loss: 547.825   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.484; Val_NMI: 5.138\n",
      "(Epoch 538 / 10000) Train_Loss: 37.858; Val_Loss: 591.640   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.407; Val_NMI: 5.249\n",
      "(Epoch 539 / 10000) Train_Loss: 39.995; Val_Loss: 547.030   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 5.260\n",
      "(Epoch 540 / 10000) Train_Loss: 40.183; Val_Loss: 583.299   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.658\n",
      "(Epoch 541 / 10000) Train_Loss: 40.124; Val_Loss: 583.037   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 4.727\n",
      "(Epoch 542 / 10000) Train_Loss: 38.797; Val_Loss: 589.490   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.421; Val_NMI: 5.340\n",
      "(Epoch 543 / 10000) Train_Loss: 38.815; Val_Loss: 563.940   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 4.735\n",
      "(Epoch 544 / 10000) Train_Loss: 37.443; Val_Loss: 584.154   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 5.159\n",
      "(Epoch 545 / 10000) Train_Loss: 37.043; Val_Loss: 578.628   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.398; Val_NMI: 4.588\n",
      "(Epoch 546 / 10000) Train_Loss: 37.026; Val_Loss: 551.518   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.460; Val_NMI: 5.247\n",
      "(Epoch 547 / 10000) Train_Loss: 37.347; Val_Loss: 547.676   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.436; Val_NMI: 4.406\n",
      "(Epoch 548 / 10000) Train_Loss: 37.468; Val_Loss: 538.388   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.414; Val_NMI: 4.622\n",
      "(Epoch 549 / 10000) Train_Loss: 37.468; Val_Loss: 571.550   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.861\n",
      "(Epoch 550 / 10000) Train_Loss: 37.091; Val_Loss: 570.705   Train_ACC: 15.321; Val_ACC: 19.259   Train_NMI: 0.466; Val_NMI: 4.904\n",
      "(Epoch 551 / 10000) Train_Loss: 39.344; Val_Loss: 597.795   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.832\n",
      "(Epoch 552 / 10000) Train_Loss: 39.076; Val_Loss: 562.907   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.969\n",
      "(Epoch 553 / 10000) Train_Loss: 38.230; Val_Loss: 540.845   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.836\n",
      "(Epoch 554 / 10000) Train_Loss: 38.745; Val_Loss: 536.361   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 5.091\n",
      "(Epoch 555 / 10000) Train_Loss: 38.143; Val_Loss: 558.708   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.668\n",
      "(Epoch 556 / 10000) Train_Loss: 45.893; Val_Loss: 588.458   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.434; Val_NMI: 5.312\n",
      "(Epoch 557 / 10000) Train_Loss: 52.412; Val_Loss: 587.513   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 5.496\n",
      "(Epoch 558 / 10000) Train_Loss: 48.224; Val_Loss: 535.511   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.353; Val_NMI: 4.949\n",
      "(Epoch 559 / 10000) Train_Loss: 41.724; Val_Loss: 559.859   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.371; Val_NMI: 5.121\n",
      "(Epoch 560 / 10000) Train_Loss: 40.318; Val_Loss: 530.222   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.411; Val_NMI: 4.812\n",
      "(Epoch 561 / 10000) Train_Loss: 37.133; Val_Loss: 563.260   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.403; Val_NMI: 4.427\n",
      "(Epoch 562 / 10000) Train_Loss: 36.400; Val_Loss: 549.916   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.399; Val_NMI: 4.775\n",
      "(Epoch 563 / 10000) Train_Loss: 36.376; Val_Loss: 582.679   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.421; Val_NMI: 4.872\n",
      "(Epoch 564 / 10000) Train_Loss: 36.025; Val_Loss: 583.633   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 5.140\n",
      "(Epoch 565 / 10000) Train_Loss: 37.650; Val_Loss: 560.990   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.308; Val_NMI: 5.129\n",
      "(Epoch 566 / 10000) Train_Loss: 38.865; Val_Loss: 540.999   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.344; Val_NMI: 4.838\n",
      "(Epoch 567 / 10000) Train_Loss: 36.549; Val_Loss: 560.237   Train_ACC: 15.115; Val_ACC: 21.111   Train_NMI: 0.374; Val_NMI: 5.636\n",
      "(Epoch 568 / 10000) Train_Loss: 36.324; Val_Loss: 570.460   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.057\n",
      "(Epoch 569 / 10000) Train_Loss: 38.014; Val_Loss: 586.331   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.405; Val_NMI: 5.032\n",
      "(Epoch 570 / 10000) Train_Loss: 35.973; Val_Loss: 568.850   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.444; Val_NMI: 5.118\n",
      "(Epoch 571 / 10000) Train_Loss: 36.569; Val_Loss: 575.229   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.383; Val_NMI: 4.921\n",
      "(Epoch 572 / 10000) Train_Loss: 37.871; Val_Loss: 584.845   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 5.331\n",
      "(Epoch 573 / 10000) Train_Loss: 39.296; Val_Loss: 566.090   Train_ACC: 15.198; Val_ACC: 21.111   Train_NMI: 0.442; Val_NMI: 5.175\n",
      "(Epoch 574 / 10000) Train_Loss: 38.645; Val_Loss: 559.074   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.395; Val_NMI: 5.099\n",
      "(Epoch 575 / 10000) Train_Loss: 38.528; Val_Loss: 609.100   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 576 / 10000) Train_Loss: 38.237; Val_Loss: 588.757   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.470; Val_NMI: 5.016\n",
      "(Epoch 577 / 10000) Train_Loss: 37.986; Val_Loss: 567.740   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 5.127\n",
      "(Epoch 578 / 10000) Train_Loss: 36.369; Val_Loss: 582.193   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 5.085\n",
      "(Epoch 579 / 10000) Train_Loss: 36.998; Val_Loss: 587.234   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.914\n",
      "(Epoch 580 / 10000) Train_Loss: 38.411; Val_Loss: 606.255   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.751\n",
      "(Epoch 581 / 10000) Train_Loss: 38.215; Val_Loss: 574.783   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 5.019\n",
      "(Epoch 582 / 10000) Train_Loss: 36.887; Val_Loss: 554.335   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.835\n",
      "(Epoch 583 / 10000) Train_Loss: 36.293; Val_Loss: 621.974   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 5.422\n",
      "(Epoch 584 / 10000) Train_Loss: 36.403; Val_Loss: 573.649   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.346; Val_NMI: 5.917\n",
      "(Epoch 585 / 10000) Train_Loss: 35.954; Val_Loss: 598.029   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.442; Val_NMI: 5.803\n",
      "(Epoch 586 / 10000) Train_Loss: 36.641; Val_Loss: 584.930   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.363; Val_NMI: 5.398\n",
      "(Epoch 587 / 10000) Train_Loss: 36.243; Val_Loss: 647.557   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 5.789\n",
      "(Epoch 588 / 10000) Train_Loss: 38.081; Val_Loss: 607.666   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.415; Val_NMI: 5.311\n",
      "(Epoch 589 / 10000) Train_Loss: 42.287; Val_Loss: 587.656   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 5.315\n",
      "(Epoch 590 / 10000) Train_Loss: 41.504; Val_Loss: 632.562   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.381; Val_NMI: 5.708\n",
      "(Epoch 591 / 10000) Train_Loss: 39.167; Val_Loss: 609.727   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.336; Val_NMI: 5.041\n",
      "(Epoch 592 / 10000) Train_Loss: 38.216; Val_Loss: 598.705   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.407; Val_NMI: 5.329\n",
      "(Epoch 593 / 10000) Train_Loss: 36.407; Val_Loss: 637.715   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.347; Val_NMI: 5.151\n",
      "(Epoch 594 / 10000) Train_Loss: 36.015; Val_Loss: 581.191   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.393; Val_NMI: 5.475\n",
      "(Epoch 595 / 10000) Train_Loss: 37.580; Val_Loss: 557.676   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.716\n",
      "(Epoch 596 / 10000) Train_Loss: 36.833; Val_Loss: 621.114   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.418; Val_NMI: 5.418\n",
      "(Epoch 597 / 10000) Train_Loss: 37.287; Val_Loss: 603.110   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.394; Val_NMI: 5.672\n",
      "(Epoch 598 / 10000) Train_Loss: 37.118; Val_Loss: 579.096   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.366; Val_NMI: 5.346\n",
      "(Epoch 599 / 10000) Train_Loss: 38.800; Val_Loss: 620.008   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 4.935\n",
      "(Epoch 600 / 10000) Train_Loss: 37.115; Val_Loss: 585.568   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 5.235\n",
      "(Epoch 601 / 10000) Train_Loss: 36.951; Val_Loss: 612.599   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 4.791\n",
      "(Epoch 602 / 10000) Train_Loss: 36.708; Val_Loss: 617.010   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.417; Val_NMI: 5.517\n",
      "(Epoch 603 / 10000) Train_Loss: 38.412; Val_Loss: 580.116   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 5.617\n",
      "(Epoch 604 / 10000) Train_Loss: 38.323; Val_Loss: 567.535   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.401; Val_NMI: 4.702\n",
      "(Epoch 605 / 10000) Train_Loss: 38.067; Val_Loss: 589.103   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.370; Val_NMI: 6.434\n",
      "(Epoch 606 / 10000) Train_Loss: 36.818; Val_Loss: 593.743   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.393; Val_NMI: 5.743\n",
      "(Epoch 607 / 10000) Train_Loss: 36.449; Val_Loss: 594.061   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 5.746\n",
      "(Epoch 608 / 10000) Train_Loss: 37.602; Val_Loss: 607.543   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.585\n",
      "(Epoch 609 / 10000) Train_Loss: 37.029; Val_Loss: 566.779   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.874\n",
      "(Epoch 610 / 10000) Train_Loss: 37.673; Val_Loss: 581.916   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 5.442\n",
      "(Epoch 611 / 10000) Train_Loss: 37.635; Val_Loss: 593.737   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.471; Val_NMI: 5.183\n",
      "(Epoch 612 / 10000) Train_Loss: 36.519; Val_Loss: 598.788   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 5.510\n",
      "(Epoch 613 / 10000) Train_Loss: 36.074; Val_Loss: 596.749   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.338; Val_NMI: 5.134\n",
      "(Epoch 614 / 10000) Train_Loss: 36.781; Val_Loss: 596.772   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 5.094\n",
      "(Epoch 615 / 10000) Train_Loss: 37.016; Val_Loss: 572.915   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.762\n",
      "(Epoch 616 / 10000) Train_Loss: 36.476; Val_Loss: 601.408   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 5.058\n",
      "(Epoch 617 / 10000) Train_Loss: 36.682; Val_Loss: 597.645   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 4.861\n",
      "(Epoch 618 / 10000) Train_Loss: 35.776; Val_Loss: 632.993   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.419; Val_NMI: 5.015\n",
      "(Epoch 619 / 10000) Train_Loss: 35.281; Val_Loss: 584.683   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.408; Val_NMI: 5.319\n",
      "(Epoch 620 / 10000) Train_Loss: 34.804; Val_Loss: 616.259   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.457; Val_NMI: 5.243\n",
      "(Epoch 621 / 10000) Train_Loss: 34.361; Val_Loss: 613.457   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.382; Val_NMI: 5.598\n",
      "(Epoch 622 / 10000) Train_Loss: 36.265; Val_Loss: 637.485   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.395; Val_NMI: 5.281\n",
      "(Epoch 623 / 10000) Train_Loss: 36.279; Val_Loss: 630.013   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.764\n",
      "(Epoch 624 / 10000) Train_Loss: 37.690; Val_Loss: 601.308   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 5.472\n",
      "(Epoch 625 / 10000) Train_Loss: 36.917; Val_Loss: 614.241   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.982\n",
      "(Epoch 626 / 10000) Train_Loss: 36.621; Val_Loss: 605.611   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.433; Val_NMI: 5.654\n",
      "(Epoch 627 / 10000) Train_Loss: 37.490; Val_Loss: 581.175   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 5.177\n",
      "(Epoch 628 / 10000) Train_Loss: 39.680; Val_Loss: 609.852   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.446; Val_NMI: 5.120\n",
      "(Epoch 629 / 10000) Train_Loss: 42.608; Val_Loss: 624.284   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.383\n",
      "(Epoch 630 / 10000) Train_Loss: 43.105; Val_Loss: 615.970   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.339; Val_NMI: 5.555\n",
      "(Epoch 631 / 10000) Train_Loss: 40.403; Val_Loss: 589.507   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 4.994\n",
      "(Epoch 632 / 10000) Train_Loss: 38.793; Val_Loss: 615.188   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.377; Val_NMI: 4.904\n",
      "(Epoch 633 / 10000) Train_Loss: 40.395; Val_Loss: 578.437   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.451; Val_NMI: 5.693\n",
      "(Epoch 634 / 10000) Train_Loss: 37.894; Val_Loss: 599.817   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.433; Val_NMI: 5.353\n",
      "(Epoch 635 / 10000) Train_Loss: 36.656; Val_Loss: 609.359   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.438; Val_NMI: 5.168\n",
      "(Epoch 636 / 10000) Train_Loss: 37.266; Val_Loss: 634.968   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.918\n",
      "(Epoch 637 / 10000) Train_Loss: 36.330; Val_Loss: 637.141   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.442; Val_NMI: 5.389\n",
      "(Epoch 638 / 10000) Train_Loss: 36.458; Val_Loss: 553.437   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.406; Val_NMI: 5.383\n",
      "(Epoch 639 / 10000) Train_Loss: 36.576; Val_Loss: 625.214   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.423; Val_NMI: 4.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 640 / 10000) Train_Loss: 36.350; Val_Loss: 589.760   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.449; Val_NMI: 5.396\n",
      "(Epoch 641 / 10000) Train_Loss: 36.449; Val_Loss: 620.770   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.462; Val_NMI: 4.892\n",
      "(Epoch 642 / 10000) Train_Loss: 35.209; Val_Loss: 589.677   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 5.559\n",
      "(Epoch 643 / 10000) Train_Loss: 36.614; Val_Loss: 591.616   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.747\n",
      "(Epoch 644 / 10000) Train_Loss: 37.111; Val_Loss: 634.388   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.417; Val_NMI: 4.646\n",
      "(Epoch 645 / 10000) Train_Loss: 35.815; Val_Loss: 625.824   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.380; Val_NMI: 5.447\n",
      "(Epoch 646 / 10000) Train_Loss: 36.470; Val_Loss: 602.637   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.414\n",
      "(Epoch 647 / 10000) Train_Loss: 35.801; Val_Loss: 644.317   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.388; Val_NMI: 5.058\n",
      "(Epoch 648 / 10000) Train_Loss: 35.645; Val_Loss: 620.628   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.362; Val_NMI: 5.380\n",
      "(Epoch 649 / 10000) Train_Loss: 35.649; Val_Loss: 608.207   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.342; Val_NMI: 5.223\n",
      "(Epoch 650 / 10000) Train_Loss: 34.804; Val_Loss: 603.297   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.412; Val_NMI: 4.681\n",
      "(Epoch 651 / 10000) Train_Loss: 35.638; Val_Loss: 632.409   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.366; Val_NMI: 5.222\n",
      "(Epoch 652 / 10000) Train_Loss: 37.885; Val_Loss: 631.182   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.522\n",
      "(Epoch 653 / 10000) Train_Loss: 37.495; Val_Loss: 614.511   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 5.504\n",
      "(Epoch 654 / 10000) Train_Loss: 37.037; Val_Loss: 626.764   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 5.249\n",
      "(Epoch 655 / 10000) Train_Loss: 35.643; Val_Loss: 603.381   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 4.485\n",
      "(Epoch 656 / 10000) Train_Loss: 34.987; Val_Loss: 645.428   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.661\n",
      "(Epoch 657 / 10000) Train_Loss: 34.416; Val_Loss: 631.691   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 5.101\n",
      "(Epoch 658 / 10000) Train_Loss: 35.431; Val_Loss: 608.997   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.781\n",
      "(Epoch 659 / 10000) Train_Loss: 35.053; Val_Loss: 612.180   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 5.304\n",
      "(Epoch 660 / 10000) Train_Loss: 42.735; Val_Loss: 615.046   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.363; Val_NMI: 5.369\n",
      "(Epoch 661 / 10000) Train_Loss: 51.113; Val_Loss: 652.597   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.627\n",
      "(Epoch 662 / 10000) Train_Loss: 45.207; Val_Loss: 650.507   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.480; Val_NMI: 5.321\n",
      "(Epoch 663 / 10000) Train_Loss: 41.914; Val_Loss: 603.911   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.427; Val_NMI: 5.295\n",
      "(Epoch 664 / 10000) Train_Loss: 38.703; Val_Loss: 607.818   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.904\n",
      "(Epoch 665 / 10000) Train_Loss: 35.424; Val_Loss: 614.423   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.442; Val_NMI: 4.447\n",
      "(Epoch 666 / 10000) Train_Loss: 36.133; Val_Loss: 580.409   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.829\n",
      "(Epoch 667 / 10000) Train_Loss: 36.420; Val_Loss: 595.700   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.395; Val_NMI: 5.940\n",
      "(Epoch 668 / 10000) Train_Loss: 34.850; Val_Loss: 618.103   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.357; Val_NMI: 4.835\n",
      "(Epoch 669 / 10000) Train_Loss: 34.853; Val_Loss: 618.344   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.389; Val_NMI: 4.996\n",
      "(Epoch 670 / 10000) Train_Loss: 34.122; Val_Loss: 591.189   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 5.734\n",
      "(Epoch 671 / 10000) Train_Loss: 33.569; Val_Loss: 604.038   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.381; Val_NMI: 5.756\n",
      "(Epoch 672 / 10000) Train_Loss: 33.588; Val_Loss: 631.474   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.421; Val_NMI: 5.811\n",
      "(Epoch 673 / 10000) Train_Loss: 34.022; Val_Loss: 604.215   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.374; Val_NMI: 4.756\n",
      "(Epoch 674 / 10000) Train_Loss: 33.974; Val_Loss: 638.445   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 5.884\n",
      "(Epoch 675 / 10000) Train_Loss: 33.947; Val_Loss: 624.196   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.441; Val_NMI: 4.745\n",
      "(Epoch 676 / 10000) Train_Loss: 34.105; Val_Loss: 624.909   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 4.957\n",
      "(Epoch 677 / 10000) Train_Loss: 33.709; Val_Loss: 615.459   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.401; Val_NMI: 5.091\n",
      "(Epoch 678 / 10000) Train_Loss: 33.499; Val_Loss: 627.571   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.441; Val_NMI: 5.358\n",
      "(Epoch 679 / 10000) Train_Loss: 34.824; Val_Loss: 652.402   Train_ACC: 14.539; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 5.109\n",
      "(Epoch 680 / 10000) Train_Loss: 34.421; Val_Loss: 630.130   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.448; Val_NMI: 4.769\n",
      "(Epoch 681 / 10000) Train_Loss: 34.447; Val_Loss: 590.782   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.440; Val_NMI: 5.733\n",
      "(Epoch 682 / 10000) Train_Loss: 34.375; Val_Loss: 617.812   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.362; Val_NMI: 4.802\n",
      "(Epoch 683 / 10000) Train_Loss: 35.002; Val_Loss: 669.150   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.397; Val_NMI: 4.961\n",
      "(Epoch 684 / 10000) Train_Loss: 37.910; Val_Loss: 667.957   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.391\n",
      "(Epoch 685 / 10000) Train_Loss: 40.440; Val_Loss: 652.360   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.419; Val_NMI: 4.856\n",
      "(Epoch 686 / 10000) Train_Loss: 39.358; Val_Loss: 610.777   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.408; Val_NMI: 5.474\n",
      "(Epoch 687 / 10000) Train_Loss: 39.451; Val_Loss: 642.448   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 4.802\n",
      "(Epoch 688 / 10000) Train_Loss: 40.939; Val_Loss: 611.555   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.367; Val_NMI: 4.861\n",
      "(Epoch 689 / 10000) Train_Loss: 37.981; Val_Loss: 643.131   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.406; Val_NMI: 5.605\n",
      "(Epoch 690 / 10000) Train_Loss: 36.663; Val_Loss: 636.760   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 5.144\n",
      "(Epoch 691 / 10000) Train_Loss: 35.444; Val_Loss: 607.176   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.356; Val_NMI: 5.851\n",
      "(Epoch 692 / 10000) Train_Loss: 36.289; Val_Loss: 596.626   Train_ACC: 14.539; Val_ACC: 20.741   Train_NMI: 0.354; Val_NMI: 4.782\n",
      "(Epoch 693 / 10000) Train_Loss: 35.402; Val_Loss: 623.259   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.344; Val_NMI: 5.685\n",
      "(Epoch 694 / 10000) Train_Loss: 34.302; Val_Loss: 630.749   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.400; Val_NMI: 5.667\n",
      "(Epoch 695 / 10000) Train_Loss: 33.903; Val_Loss: 627.014   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 5.119\n",
      "(Epoch 696 / 10000) Train_Loss: 33.816; Val_Loss: 638.161   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.896\n",
      "(Epoch 697 / 10000) Train_Loss: 34.354; Val_Loss: 623.160   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 5.289\n",
      "(Epoch 698 / 10000) Train_Loss: 35.431; Val_Loss: 650.613   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 5.454\n",
      "(Epoch 699 / 10000) Train_Loss: 35.249; Val_Loss: 633.677   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.411; Val_NMI: 5.668\n",
      "(Epoch 700 / 10000) Train_Loss: 35.057; Val_Loss: 640.936   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 5.378\n",
      "(Epoch 701 / 10000) Train_Loss: 36.379; Val_Loss: 627.482   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.361; Val_NMI: 6.126\n",
      "(Epoch 702 / 10000) Train_Loss: 37.902; Val_Loss: 638.964   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.309; Val_NMI: 6.182\n",
      "(Epoch 703 / 10000) Train_Loss: 36.479; Val_Loss: 646.996   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 4.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 704 / 10000) Train_Loss: 34.730; Val_Loss: 641.557   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.393; Val_NMI: 5.456\n",
      "(Epoch 705 / 10000) Train_Loss: 34.650; Val_Loss: 615.843   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.343; Val_NMI: 6.214\n",
      "(Epoch 706 / 10000) Train_Loss: 34.758; Val_Loss: 618.626   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.347; Val_NMI: 5.482\n",
      "(Epoch 707 / 10000) Train_Loss: 35.738; Val_Loss: 643.731   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 5.202\n",
      "(Epoch 708 / 10000) Train_Loss: 34.522; Val_Loss: 597.028   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.339; Val_NMI: 5.731\n",
      "(Epoch 709 / 10000) Train_Loss: 33.961; Val_Loss: 635.531   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.383; Val_NMI: 5.208\n",
      "(Epoch 710 / 10000) Train_Loss: 34.825; Val_Loss: 694.623   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.430; Val_NMI: 5.352\n",
      "(Epoch 711 / 10000) Train_Loss: 35.868; Val_Loss: 676.336   Train_ACC: 15.280; Val_ACC: 20.370   Train_NMI: 0.458; Val_NMI: 5.491\n",
      "(Epoch 712 / 10000) Train_Loss: 36.331; Val_Loss: 628.840   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.359; Val_NMI: 6.089\n",
      "(Epoch 713 / 10000) Train_Loss: 36.568; Val_Loss: 633.577   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.333; Val_NMI: 5.894\n",
      "(Epoch 714 / 10000) Train_Loss: 37.004; Val_Loss: 626.896   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 5.469\n",
      "(Epoch 715 / 10000) Train_Loss: 35.794; Val_Loss: 642.365   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.435; Val_NMI: 6.160\n",
      "(Epoch 716 / 10000) Train_Loss: 36.162; Val_Loss: 673.463   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 5.763\n",
      "(Epoch 717 / 10000) Train_Loss: 37.446; Val_Loss: 645.900   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.466; Val_NMI: 6.110\n",
      "(Epoch 718 / 10000) Train_Loss: 35.718; Val_Loss: 626.402   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.430; Val_NMI: 5.701\n",
      "(Epoch 719 / 10000) Train_Loss: 34.516; Val_Loss: 648.083   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.380; Val_NMI: 6.068\n",
      "(Epoch 720 / 10000) Train_Loss: 34.274; Val_Loss: 621.890   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.365; Val_NMI: 6.184\n",
      "(Epoch 721 / 10000) Train_Loss: 33.929; Val_Loss: 620.081   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 5.388\n",
      "(Epoch 722 / 10000) Train_Loss: 34.227; Val_Loss: 677.497   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 5.807\n",
      "(Epoch 723 / 10000) Train_Loss: 33.657; Val_Loss: 644.977   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.431; Val_NMI: 5.701\n",
      "(Epoch 724 / 10000) Train_Loss: 33.024; Val_Loss: 659.422   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.453; Val_NMI: 5.276\n",
      "(Epoch 725 / 10000) Train_Loss: 33.923; Val_Loss: 678.295   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.387; Val_NMI: 5.151\n",
      "(Epoch 726 / 10000) Train_Loss: 34.286; Val_Loss: 663.932   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.442; Val_NMI: 5.490\n",
      "(Epoch 727 / 10000) Train_Loss: 34.275; Val_Loss: 649.800   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 5.419\n",
      "(Epoch 728 / 10000) Train_Loss: 36.066; Val_Loss: 680.253   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.425; Val_NMI: 5.410\n",
      "(Epoch 729 / 10000) Train_Loss: 35.701; Val_Loss: 640.172   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 5.262\n",
      "(Epoch 730 / 10000) Train_Loss: 34.822; Val_Loss: 671.799   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.395; Val_NMI: 5.113\n",
      "(Epoch 731 / 10000) Train_Loss: 34.690; Val_Loss: 660.352   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 5.209\n",
      "(Epoch 732 / 10000) Train_Loss: 35.367; Val_Loss: 649.832   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.449; Val_NMI: 5.535\n",
      "(Epoch 733 / 10000) Train_Loss: 36.972; Val_Loss: 627.678   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.442\n",
      "(Epoch 734 / 10000) Train_Loss: 39.676; Val_Loss: 619.863   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 4.619\n",
      "(Epoch 735 / 10000) Train_Loss: 37.029; Val_Loss: 619.434   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.388; Val_NMI: 4.851\n",
      "(Epoch 736 / 10000) Train_Loss: 36.864; Val_Loss: 651.931   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.901\n",
      "(Epoch 737 / 10000) Train_Loss: 35.898; Val_Loss: 600.250   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 4.764\n",
      "(Epoch 738 / 10000) Train_Loss: 35.587; Val_Loss: 657.176   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.376; Val_NMI: 4.941\n",
      "(Epoch 739 / 10000) Train_Loss: 36.188; Val_Loss: 644.690   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 5.457\n",
      "(Epoch 740 / 10000) Train_Loss: 36.716; Val_Loss: 641.248   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.462; Val_NMI: 5.843\n",
      "(Epoch 741 / 10000) Train_Loss: 35.201; Val_Loss: 666.480   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.662\n",
      "(Epoch 742 / 10000) Train_Loss: 35.150; Val_Loss: 662.767   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.377; Val_NMI: 5.250\n",
      "(Epoch 743 / 10000) Train_Loss: 35.315; Val_Loss: 662.089   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.401; Val_NMI: 5.539\n",
      "(Epoch 744 / 10000) Train_Loss: 34.964; Val_Loss: 665.984   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.072\n",
      "(Epoch 745 / 10000) Train_Loss: 34.464; Val_Loss: 684.601   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.422; Val_NMI: 5.079\n",
      "(Epoch 746 / 10000) Train_Loss: 35.325; Val_Loss: 673.076   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.387; Val_NMI: 4.832\n",
      "(Epoch 747 / 10000) Train_Loss: 35.849; Val_Loss: 659.777   Train_ACC: 15.404; Val_ACC: 21.481   Train_NMI: 0.498; Val_NMI: 5.846\n",
      "(Epoch 748 / 10000) Train_Loss: 38.159; Val_Loss: 655.075   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.431; Val_NMI: 5.109\n",
      "(Epoch 749 / 10000) Train_Loss: 35.411; Val_Loss: 640.587   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 5.493\n",
      "(Epoch 750 / 10000) Train_Loss: 34.268; Val_Loss: 647.018   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 5.361\n",
      "(Epoch 751 / 10000) Train_Loss: 34.135; Val_Loss: 694.046   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.430; Val_NMI: 5.642\n",
      "(Epoch 752 / 10000) Train_Loss: 35.372; Val_Loss: 669.663   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.945\n",
      "(Epoch 753 / 10000) Train_Loss: 34.234; Val_Loss: 643.855   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.466; Val_NMI: 5.609\n",
      "(Epoch 754 / 10000) Train_Loss: 33.205; Val_Loss: 678.708   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.456\n",
      "(Epoch 755 / 10000) Train_Loss: 33.463; Val_Loss: 677.092   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.432; Val_NMI: 5.578\n",
      "(Epoch 756 / 10000) Train_Loss: 33.577; Val_Loss: 651.419   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.500; Val_NMI: 5.202\n",
      "(Epoch 757 / 10000) Train_Loss: 33.711; Val_Loss: 668.162   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.445; Val_NMI: 4.870\n",
      "(Epoch 758 / 10000) Train_Loss: 34.073; Val_Loss: 633.042   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 5.192\n",
      "(Epoch 759 / 10000) Train_Loss: 33.394; Val_Loss: 672.517   Train_ACC: 14.456; Val_ACC: 20.000   Train_NMI: 0.308; Val_NMI: 5.703\n",
      "(Epoch 760 / 10000) Train_Loss: 33.291; Val_Loss: 684.971   Train_ACC: 14.498; Val_ACC: 20.741   Train_NMI: 0.358; Val_NMI: 5.831\n",
      "(Epoch 761 / 10000) Train_Loss: 33.224; Val_Loss: 637.635   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 5.587\n",
      "(Epoch 762 / 10000) Train_Loss: 33.746; Val_Loss: 681.881   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.427; Val_NMI: 5.539\n",
      "(Epoch 763 / 10000) Train_Loss: 33.890; Val_Loss: 663.600   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 5.203\n",
      "(Epoch 764 / 10000) Train_Loss: 34.823; Val_Loss: 685.259   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.382; Val_NMI: 5.047\n",
      "(Epoch 765 / 10000) Train_Loss: 36.015; Val_Loss: 696.356   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.356; Val_NMI: 4.961\n",
      "(Epoch 766 / 10000) Train_Loss: 36.318; Val_Loss: 659.259   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 5.224\n",
      "(Epoch 767 / 10000) Train_Loss: 36.647; Val_Loss: 661.622   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 768 / 10000) Train_Loss: 35.734; Val_Loss: 673.986   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.866\n",
      "(Epoch 769 / 10000) Train_Loss: 35.936; Val_Loss: 659.613   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 5.500\n",
      "(Epoch 770 / 10000) Train_Loss: 35.689; Val_Loss: 677.814   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 5.276\n",
      "(Epoch 771 / 10000) Train_Loss: 35.260; Val_Loss: 686.287   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 5.627\n",
      "(Epoch 772 / 10000) Train_Loss: 34.499; Val_Loss: 654.906   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 5.278\n",
      "(Epoch 773 / 10000) Train_Loss: 34.279; Val_Loss: 676.237   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.411; Val_NMI: 4.465\n",
      "(Epoch 774 / 10000) Train_Loss: 33.564; Val_Loss: 686.119   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 5.011\n",
      "(Epoch 775 / 10000) Train_Loss: 33.449; Val_Loss: 679.064   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.368; Val_NMI: 5.488\n",
      "(Epoch 776 / 10000) Train_Loss: 33.237; Val_Loss: 672.038   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 5.906\n",
      "(Epoch 777 / 10000) Train_Loss: 33.441; Val_Loss: 661.038   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 5.082\n",
      "(Epoch 778 / 10000) Train_Loss: 34.144; Val_Loss: 699.192   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.405; Val_NMI: 4.797\n",
      "(Epoch 779 / 10000) Train_Loss: 35.583; Val_Loss: 681.461   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.745\n",
      "(Epoch 780 / 10000) Train_Loss: 35.977; Val_Loss: 665.811   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 5.264\n",
      "(Epoch 781 / 10000) Train_Loss: 36.834; Val_Loss: 664.147   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.385; Val_NMI: 5.250\n",
      "(Epoch 782 / 10000) Train_Loss: 34.929; Val_Loss: 693.293   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.349; Val_NMI: 5.279\n",
      "(Epoch 783 / 10000) Train_Loss: 34.834; Val_Loss: 645.261   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.419; Val_NMI: 4.493\n",
      "(Epoch 784 / 10000) Train_Loss: 34.269; Val_Loss: 692.192   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.367; Val_NMI: 4.732\n",
      "(Epoch 785 / 10000) Train_Loss: 33.648; Val_Loss: 680.151   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 5.025\n",
      "(Epoch 786 / 10000) Train_Loss: 35.383; Val_Loss: 681.761   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 5.223\n",
      "(Epoch 787 / 10000) Train_Loss: 35.324; Val_Loss: 710.223   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 5.258\n",
      "(Epoch 788 / 10000) Train_Loss: 33.969; Val_Loss: 617.890   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.780\n",
      "(Epoch 789 / 10000) Train_Loss: 34.879; Val_Loss: 680.941   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 5.349\n",
      "(Epoch 790 / 10000) Train_Loss: 38.448; Val_Loss: 673.831   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.419; Val_NMI: 5.129\n",
      "(Epoch 791 / 10000) Train_Loss: 36.269; Val_Loss: 676.157   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.432; Val_NMI: 5.455\n",
      "(Epoch 792 / 10000) Train_Loss: 34.623; Val_Loss: 657.729   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.418; Val_NMI: 4.660\n",
      "(Epoch 793 / 10000) Train_Loss: 34.753; Val_Loss: 671.881   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.874\n",
      "(Epoch 794 / 10000) Train_Loss: 35.248; Val_Loss: 668.001   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.400; Val_NMI: 5.416\n",
      "(Epoch 795 / 10000) Train_Loss: 42.995; Val_Loss: 681.365   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 4.819\n",
      "(Epoch 796 / 10000) Train_Loss: 41.994; Val_Loss: 679.300   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 5.181\n",
      "(Epoch 797 / 10000) Train_Loss: 42.522; Val_Loss: 668.963   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.431; Val_NMI: 4.696\n",
      "(Epoch 798 / 10000) Train_Loss: 41.494; Val_Loss: 665.406   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 5.411\n",
      "(Epoch 799 / 10000) Train_Loss: 38.281; Val_Loss: 684.473   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 4.940\n",
      "(Epoch 800 / 10000) Train_Loss: 35.143; Val_Loss: 691.392   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 5.962\n",
      "(Epoch 801 / 10000) Train_Loss: 33.717; Val_Loss: 677.084   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 5.459\n",
      "(Epoch 802 / 10000) Train_Loss: 32.910; Val_Loss: 663.228   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 4.610\n",
      "(Epoch 803 / 10000) Train_Loss: 32.915; Val_Loss: 671.477   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 4.705\n",
      "(Epoch 804 / 10000) Train_Loss: 33.365; Val_Loss: 672.217   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 5.465\n",
      "(Epoch 805 / 10000) Train_Loss: 32.469; Val_Loss: 683.770   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 5.544\n",
      "(Epoch 806 / 10000) Train_Loss: 32.578; Val_Loss: 669.674   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.811\n",
      "(Epoch 807 / 10000) Train_Loss: 32.925; Val_Loss: 666.342   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.339; Val_NMI: 5.532\n",
      "(Epoch 808 / 10000) Train_Loss: 32.605; Val_Loss: 674.725   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.359; Val_NMI: 5.176\n",
      "(Epoch 809 / 10000) Train_Loss: 31.668; Val_Loss: 676.175   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 5.088\n",
      "(Epoch 810 / 10000) Train_Loss: 31.940; Val_Loss: 680.219   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.097\n",
      "(Epoch 811 / 10000) Train_Loss: 32.449; Val_Loss: 674.543   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 5.034\n",
      "(Epoch 812 / 10000) Train_Loss: 32.719; Val_Loss: 631.152   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.728\n",
      "(Epoch 813 / 10000) Train_Loss: 32.816; Val_Loss: 697.120   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 5.846\n",
      "(Epoch 814 / 10000) Train_Loss: 32.443; Val_Loss: 704.293   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.207\n",
      "(Epoch 815 / 10000) Train_Loss: 33.628; Val_Loss: 721.050   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 5.713\n",
      "(Epoch 816 / 10000) Train_Loss: 34.013; Val_Loss: 702.637   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.190\n",
      "(Epoch 817 / 10000) Train_Loss: 34.149; Val_Loss: 618.891   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.464; Val_NMI: 5.371\n",
      "(Epoch 818 / 10000) Train_Loss: 33.750; Val_Loss: 708.979   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 5.607\n",
      "(Epoch 819 / 10000) Train_Loss: 35.269; Val_Loss: 705.255   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.403; Val_NMI: 5.228\n",
      "(Epoch 820 / 10000) Train_Loss: 33.925; Val_Loss: 692.018   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 5.257\n",
      "(Epoch 821 / 10000) Train_Loss: 33.754; Val_Loss: 696.863   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 5.085\n",
      "(Epoch 822 / 10000) Train_Loss: 37.247; Val_Loss: 691.082   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.326; Val_NMI: 4.909\n",
      "(Epoch 823 / 10000) Train_Loss: 37.073; Val_Loss: 704.182   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.583\n",
      "(Epoch 824 / 10000) Train_Loss: 35.764; Val_Loss: 668.390   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.367; Val_NMI: 5.382\n",
      "(Epoch 825 / 10000) Train_Loss: 34.329; Val_Loss: 701.249   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 4.892\n",
      "(Epoch 826 / 10000) Train_Loss: 35.758; Val_Loss: 720.285   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.371; Val_NMI: 5.889\n",
      "(Epoch 827 / 10000) Train_Loss: 39.094; Val_Loss: 719.144   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 4.443\n",
      "(Epoch 828 / 10000) Train_Loss: 37.208; Val_Loss: 670.234   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 5.153\n",
      "(Epoch 829 / 10000) Train_Loss: 38.295; Val_Loss: 669.300   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 4.391\n",
      "(Epoch 830 / 10000) Train_Loss: 35.328; Val_Loss: 672.710   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.400; Val_NMI: 4.895\n",
      "(Epoch 831 / 10000) Train_Loss: 33.595; Val_Loss: 691.121   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.363; Val_NMI: 5.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 832 / 10000) Train_Loss: 33.494; Val_Loss: 683.297   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.479\n",
      "(Epoch 833 / 10000) Train_Loss: 32.508; Val_Loss: 707.742   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 5.595\n",
      "(Epoch 834 / 10000) Train_Loss: 32.148; Val_Loss: 675.259   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.340; Val_NMI: 4.930\n",
      "(Epoch 835 / 10000) Train_Loss: 31.922; Val_Loss: 690.953   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.341; Val_NMI: 5.120\n",
      "(Epoch 836 / 10000) Train_Loss: 31.984; Val_Loss: 712.228   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 4.388\n",
      "(Epoch 837 / 10000) Train_Loss: 32.044; Val_Loss: 727.678   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 5.472\n",
      "(Epoch 838 / 10000) Train_Loss: 33.229; Val_Loss: 660.265   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 5.208\n",
      "(Epoch 839 / 10000) Train_Loss: 32.950; Val_Loss: 658.960   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.376; Val_NMI: 5.531\n",
      "(Epoch 840 / 10000) Train_Loss: 37.063; Val_Loss: 662.603   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.423; Val_NMI: 5.469\n",
      "(Epoch 841 / 10000) Train_Loss: 34.616; Val_Loss: 685.567   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.474; Val_NMI: 5.287\n",
      "(Epoch 842 / 10000) Train_Loss: 34.172; Val_Loss: 670.984   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.428; Val_NMI: 5.021\n",
      "(Epoch 843 / 10000) Train_Loss: 35.924; Val_Loss: 673.259   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.521\n",
      "(Epoch 844 / 10000) Train_Loss: 40.088; Val_Loss: 675.624   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.529\n",
      "(Epoch 845 / 10000) Train_Loss: 35.088; Val_Loss: 710.451   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.278\n",
      "(Epoch 846 / 10000) Train_Loss: 33.583; Val_Loss: 734.040   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 4.753\n",
      "(Epoch 847 / 10000) Train_Loss: 33.527; Val_Loss: 684.483   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.622\n",
      "(Epoch 848 / 10000) Train_Loss: 33.552; Val_Loss: 749.041   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 5.008\n",
      "(Epoch 849 / 10000) Train_Loss: 34.195; Val_Loss: 692.570   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.362; Val_NMI: 5.756\n",
      "(Epoch 850 / 10000) Train_Loss: 32.969; Val_Loss: 690.991   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.814\n",
      "(Epoch 851 / 10000) Train_Loss: 32.399; Val_Loss: 695.588   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.586\n",
      "(Epoch 852 / 10000) Train_Loss: 32.805; Val_Loss: 667.733   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.945\n",
      "(Epoch 853 / 10000) Train_Loss: 32.979; Val_Loss: 715.210   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.421; Val_NMI: 4.156\n",
      "(Epoch 854 / 10000) Train_Loss: 32.900; Val_Loss: 685.886   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.622\n",
      "(Epoch 855 / 10000) Train_Loss: 33.057; Val_Loss: 697.416   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 4.751\n",
      "(Epoch 856 / 10000) Train_Loss: 33.449; Val_Loss: 709.489   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 5.211\n",
      "(Epoch 857 / 10000) Train_Loss: 33.492; Val_Loss: 666.805   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.382; Val_NMI: 5.023\n",
      "(Epoch 858 / 10000) Train_Loss: 33.110; Val_Loss: 671.319   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 5.397\n",
      "(Epoch 859 / 10000) Train_Loss: 33.151; Val_Loss: 656.676   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.439; Val_NMI: 5.572\n",
      "(Epoch 860 / 10000) Train_Loss: 33.258; Val_Loss: 701.968   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.922\n",
      "(Epoch 861 / 10000) Train_Loss: 34.645; Val_Loss: 702.815   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.391; Val_NMI: 5.528\n",
      "(Epoch 862 / 10000) Train_Loss: 35.326; Val_Loss: 698.792   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.446\n",
      "(Epoch 863 / 10000) Train_Loss: 33.342; Val_Loss: 724.821   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.336; Val_NMI: 5.379\n",
      "(Epoch 864 / 10000) Train_Loss: 34.137; Val_Loss: 705.088   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.316; Val_NMI: 5.797\n",
      "(Epoch 865 / 10000) Train_Loss: 36.702; Val_Loss: 716.487   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 4.737\n",
      "(Epoch 866 / 10000) Train_Loss: 37.040; Val_Loss: 713.683   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 5.351\n",
      "(Epoch 867 / 10000) Train_Loss: 34.509; Val_Loss: 714.613   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.743\n",
      "(Epoch 868 / 10000) Train_Loss: 35.354; Val_Loss: 708.868   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 5.152\n",
      "(Epoch 869 / 10000) Train_Loss: 34.636; Val_Loss: 731.164   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.370; Val_NMI: 5.397\n",
      "(Epoch 870 / 10000) Train_Loss: 33.193; Val_Loss: 695.215   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 5.812\n",
      "(Epoch 871 / 10000) Train_Loss: 31.827; Val_Loss: 700.536   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 5.593\n",
      "(Epoch 872 / 10000) Train_Loss: 32.322; Val_Loss: 685.330   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.441; Val_NMI: 5.668\n",
      "(Epoch 873 / 10000) Train_Loss: 32.091; Val_Loss: 722.564   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.388; Val_NMI: 5.063\n",
      "(Epoch 874 / 10000) Train_Loss: 33.122; Val_Loss: 732.923   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.397; Val_NMI: 5.310\n",
      "(Epoch 875 / 10000) Train_Loss: 33.539; Val_Loss: 724.689   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 5.000\n",
      "(Epoch 876 / 10000) Train_Loss: 33.507; Val_Loss: 736.633   Train_ACC: 14.415; Val_ACC: 20.741   Train_NMI: 0.294; Val_NMI: 5.577\n",
      "(Epoch 877 / 10000) Train_Loss: 33.428; Val_Loss: 724.801   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 5.444\n",
      "(Epoch 878 / 10000) Train_Loss: 33.797; Val_Loss: 720.911   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 5.434\n",
      "(Epoch 879 / 10000) Train_Loss: 32.433; Val_Loss: 743.426   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 5.192\n",
      "(Epoch 880 / 10000) Train_Loss: 32.739; Val_Loss: 707.587   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 5.360\n",
      "(Epoch 881 / 10000) Train_Loss: 32.939; Val_Loss: 675.147   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.439; Val_NMI: 5.226\n",
      "(Epoch 882 / 10000) Train_Loss: 32.982; Val_Loss: 678.225   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 5.413\n",
      "(Epoch 883 / 10000) Train_Loss: 32.888; Val_Loss: 697.999   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.411; Val_NMI: 5.660\n",
      "(Epoch 884 / 10000) Train_Loss: 32.334; Val_Loss: 697.574   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.378; Val_NMI: 5.474\n",
      "(Epoch 885 / 10000) Train_Loss: 33.011; Val_Loss: 730.522   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.346; Val_NMI: 4.847\n",
      "(Epoch 886 / 10000) Train_Loss: 33.813; Val_Loss: 726.144   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 5.342\n",
      "(Epoch 887 / 10000) Train_Loss: 32.867; Val_Loss: 686.314   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.424; Val_NMI: 5.261\n",
      "(Epoch 888 / 10000) Train_Loss: 33.529; Val_Loss: 712.483   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 5.215\n",
      "(Epoch 889 / 10000) Train_Loss: 33.474; Val_Loss: 707.790   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 5.401\n",
      "(Epoch 890 / 10000) Train_Loss: 38.781; Val_Loss: 686.574   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.582\n",
      "(Epoch 891 / 10000) Train_Loss: 40.259; Val_Loss: 677.865   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.335; Val_NMI: 5.079\n",
      "(Epoch 892 / 10000) Train_Loss: 36.533; Val_Loss: 695.776   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.422; Val_NMI: 4.777\n",
      "(Epoch 893 / 10000) Train_Loss: 36.780; Val_Loss: 677.234   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.289\n",
      "(Epoch 894 / 10000) Train_Loss: 34.712; Val_Loss: 694.543   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.788\n",
      "(Epoch 895 / 10000) Train_Loss: 33.671; Val_Loss: 749.472   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 5.245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 896 / 10000) Train_Loss: 33.274; Val_Loss: 715.289   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.754\n",
      "(Epoch 897 / 10000) Train_Loss: 32.366; Val_Loss: 674.793   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.609\n",
      "(Epoch 898 / 10000) Train_Loss: 32.210; Val_Loss: 683.376   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.966\n",
      "(Epoch 899 / 10000) Train_Loss: 33.583; Val_Loss: 691.879   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.709\n",
      "(Epoch 900 / 10000) Train_Loss: 33.999; Val_Loss: 690.517   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.437; Val_NMI: 5.522\n",
      "(Epoch 901 / 10000) Train_Loss: 33.691; Val_Loss: 701.255   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 5.402\n",
      "(Epoch 902 / 10000) Train_Loss: 36.229; Val_Loss: 706.340   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.406; Val_NMI: 5.061\n",
      "(Epoch 903 / 10000) Train_Loss: 32.903; Val_Loss: 701.852   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.617\n",
      "(Epoch 904 / 10000) Train_Loss: 32.439; Val_Loss: 716.788   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 5.225\n",
      "(Epoch 905 / 10000) Train_Loss: 32.776; Val_Loss: 721.895   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.933\n",
      "(Epoch 906 / 10000) Train_Loss: 35.763; Val_Loss: 741.551   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.412; Val_NMI: 4.994\n",
      "(Epoch 907 / 10000) Train_Loss: 36.058; Val_Loss: 736.628   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 5.376\n",
      "(Epoch 908 / 10000) Train_Loss: 37.320; Val_Loss: 722.048   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.397; Val_NMI: 5.775\n",
      "(Epoch 909 / 10000) Train_Loss: 34.369; Val_Loss: 706.135   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 5.454\n",
      "(Epoch 910 / 10000) Train_Loss: 34.078; Val_Loss: 708.803   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.394; Val_NMI: 3.857\n",
      "(Epoch 911 / 10000) Train_Loss: 36.896; Val_Loss: 696.368   Train_ACC: 15.486; Val_ACC: 19.630   Train_NMI: 0.437; Val_NMI: 4.859\n",
      "(Epoch 912 / 10000) Train_Loss: 34.606; Val_Loss: 702.554   Train_ACC: 15.362; Val_ACC: 20.000   Train_NMI: 0.535; Val_NMI: 5.511\n",
      "(Epoch 913 / 10000) Train_Loss: 34.513; Val_Loss: 680.468   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.417; Val_NMI: 5.452\n",
      "(Epoch 914 / 10000) Train_Loss: 34.921; Val_Loss: 734.044   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.435; Val_NMI: 4.962\n",
      "(Epoch 915 / 10000) Train_Loss: 33.975; Val_Loss: 745.063   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.424; Val_NMI: 5.410\n",
      "(Epoch 916 / 10000) Train_Loss: 32.665; Val_Loss: 680.981   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 5.347\n",
      "(Epoch 917 / 10000) Train_Loss: 33.039; Val_Loss: 722.628   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.444; Val_NMI: 5.188\n",
      "(Epoch 918 / 10000) Train_Loss: 33.540; Val_Loss: 729.393   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 5.425\n",
      "(Epoch 919 / 10000) Train_Loss: 33.632; Val_Loss: 706.949   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.427; Val_NMI: 4.962\n",
      "(Epoch 920 / 10000) Train_Loss: 31.922; Val_Loss: 714.860   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.529\n",
      "(Epoch 921 / 10000) Train_Loss: 32.254; Val_Loss: 752.398   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 5.463\n",
      "(Epoch 922 / 10000) Train_Loss: 32.502; Val_Loss: 720.422   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 5.401\n",
      "(Epoch 923 / 10000) Train_Loss: 32.267; Val_Loss: 700.992   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.388; Val_NMI: 5.265\n",
      "(Epoch 924 / 10000) Train_Loss: 32.377; Val_Loss: 707.402   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 5.012\n",
      "(Epoch 925 / 10000) Train_Loss: 33.112; Val_Loss: 688.285   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 5.207\n",
      "(Epoch 926 / 10000) Train_Loss: 33.211; Val_Loss: 726.020   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.403; Val_NMI: 4.904\n",
      "(Epoch 927 / 10000) Train_Loss: 32.703; Val_Loss: 717.550   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 5.418\n",
      "(Epoch 928 / 10000) Train_Loss: 32.216; Val_Loss: 710.807   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.872\n",
      "(Epoch 929 / 10000) Train_Loss: 31.195; Val_Loss: 733.561   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.413; Val_NMI: 5.550\n",
      "(Epoch 930 / 10000) Train_Loss: 32.047; Val_Loss: 755.653   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.405; Val_NMI: 5.291\n",
      "(Epoch 931 / 10000) Train_Loss: 34.516; Val_Loss: 721.553   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 5.198\n",
      "(Epoch 932 / 10000) Train_Loss: 33.770; Val_Loss: 733.996   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 5.460\n",
      "(Epoch 933 / 10000) Train_Loss: 33.504; Val_Loss: 721.782   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 6.108\n",
      "(Epoch 934 / 10000) Train_Loss: 33.187; Val_Loss: 696.007   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.437; Val_NMI: 5.393\n",
      "(Epoch 935 / 10000) Train_Loss: 32.738; Val_Loss: 670.190   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 5.777\n",
      "(Epoch 936 / 10000) Train_Loss: 33.388; Val_Loss: 699.333   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 5.711\n",
      "(Epoch 937 / 10000) Train_Loss: 36.038; Val_Loss: 760.436   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 5.830\n",
      "(Epoch 938 / 10000) Train_Loss: 36.130; Val_Loss: 716.782   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 5.184\n",
      "(Epoch 939 / 10000) Train_Loss: 35.669; Val_Loss: 707.690   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 5.005\n",
      "(Epoch 940 / 10000) Train_Loss: 35.874; Val_Loss: 747.381   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.438; Val_NMI: 5.355\n",
      "(Epoch 941 / 10000) Train_Loss: 34.472; Val_Loss: 735.684   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.389; Val_NMI: 5.663\n",
      "(Epoch 942 / 10000) Train_Loss: 33.587; Val_Loss: 723.251   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.530\n",
      "(Epoch 943 / 10000) Train_Loss: 34.154; Val_Loss: 775.501   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.383; Val_NMI: 5.490\n",
      "(Epoch 944 / 10000) Train_Loss: 33.745; Val_Loss: 744.200   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.863\n",
      "(Epoch 945 / 10000) Train_Loss: 33.763; Val_Loss: 741.859   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.417; Val_NMI: 5.194\n",
      "(Epoch 946 / 10000) Train_Loss: 33.754; Val_Loss: 719.400   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.388; Val_NMI: 5.140\n",
      "(Epoch 947 / 10000) Train_Loss: 34.483; Val_Loss: 696.910   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.485; Val_NMI: 5.370\n",
      "(Epoch 948 / 10000) Train_Loss: 32.277; Val_Loss: 695.675   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.439; Val_NMI: 5.193\n",
      "(Epoch 949 / 10000) Train_Loss: 32.427; Val_Loss: 742.334   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.465; Val_NMI: 5.407\n",
      "(Epoch 950 / 10000) Train_Loss: 32.120; Val_Loss: 743.144   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.416; Val_NMI: 5.884\n",
      "(Epoch 951 / 10000) Train_Loss: 31.945; Val_Loss: 726.972   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.448; Val_NMI: 5.435\n",
      "(Epoch 952 / 10000) Train_Loss: 31.432; Val_Loss: 744.795   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.414; Val_NMI: 5.448\n",
      "(Epoch 953 / 10000) Train_Loss: 33.717; Val_Loss: 681.476   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 5.508\n",
      "(Epoch 954 / 10000) Train_Loss: 32.761; Val_Loss: 696.244   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 5.759\n",
      "(Epoch 955 / 10000) Train_Loss: 32.731; Val_Loss: 730.744   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 5.182\n",
      "(Epoch 956 / 10000) Train_Loss: 32.712; Val_Loss: 696.390   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 4.866\n",
      "(Epoch 957 / 10000) Train_Loss: 32.910; Val_Loss: 726.180   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.433\n",
      "(Epoch 958 / 10000) Train_Loss: 33.374; Val_Loss: 746.975   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.405; Val_NMI: 5.613\n",
      "(Epoch 959 / 10000) Train_Loss: 31.838; Val_Loss: 730.577   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.404; Val_NMI: 5.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 960 / 10000) Train_Loss: 32.185; Val_Loss: 744.629   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 4.864\n",
      "(Epoch 961 / 10000) Train_Loss: 38.785; Val_Loss: 716.138   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.422; Val_NMI: 4.636\n",
      "(Epoch 962 / 10000) Train_Loss: 38.172; Val_Loss: 734.236   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.446; Val_NMI: 4.544\n",
      "(Epoch 963 / 10000) Train_Loss: 35.074; Val_Loss: 721.873   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.444; Val_NMI: 4.684\n",
      "(Epoch 964 / 10000) Train_Loss: 33.282; Val_Loss: 777.465   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.427; Val_NMI: 4.682\n",
      "(Epoch 965 / 10000) Train_Loss: 34.063; Val_Loss: 720.563   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.474; Val_NMI: 5.415\n",
      "(Epoch 966 / 10000) Train_Loss: 33.435; Val_Loss: 717.967   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 5.254\n",
      "(Epoch 967 / 10000) Train_Loss: 34.667; Val_Loss: 745.929   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 5.264\n",
      "(Epoch 968 / 10000) Train_Loss: 32.762; Val_Loss: 727.460   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.904\n",
      "(Epoch 969 / 10000) Train_Loss: 32.487; Val_Loss: 701.623   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.629\n",
      "(Epoch 970 / 10000) Train_Loss: 33.516; Val_Loss: 754.239   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.433; Val_NMI: 5.440\n",
      "(Epoch 971 / 10000) Train_Loss: 35.631; Val_Loss: 721.219   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.398; Val_NMI: 5.306\n",
      "(Epoch 972 / 10000) Train_Loss: 33.743; Val_Loss: 707.028   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.353\n",
      "(Epoch 973 / 10000) Train_Loss: 32.549; Val_Loss: 714.088   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.423; Val_NMI: 5.485\n",
      "(Epoch 974 / 10000) Train_Loss: 32.483; Val_Loss: 706.438   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.446; Val_NMI: 5.347\n",
      "(Epoch 975 / 10000) Train_Loss: 32.467; Val_Loss: 711.147   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.404; Val_NMI: 5.909\n",
      "(Epoch 976 / 10000) Train_Loss: 31.334; Val_Loss: 731.869   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.464; Val_NMI: 5.754\n",
      "(Epoch 977 / 10000) Train_Loss: 31.741; Val_Loss: 733.391   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.038\n",
      "(Epoch 978 / 10000) Train_Loss: 31.635; Val_Loss: 717.613   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.417; Val_NMI: 5.101\n",
      "(Epoch 979 / 10000) Train_Loss: 33.817; Val_Loss: 727.302   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.420; Val_NMI: 5.193\n",
      "(Epoch 980 / 10000) Train_Loss: 33.162; Val_Loss: 725.448   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.425; Val_NMI: 5.115\n",
      "(Epoch 981 / 10000) Train_Loss: 35.288; Val_Loss: 739.024   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.414; Val_NMI: 5.021\n",
      "(Epoch 982 / 10000) Train_Loss: 32.360; Val_Loss: 742.184   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 5.921\n",
      "(Epoch 983 / 10000) Train_Loss: 32.415; Val_Loss: 694.026   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.429; Val_NMI: 4.866\n",
      "(Epoch 984 / 10000) Train_Loss: 32.040; Val_Loss: 734.499   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.465; Val_NMI: 5.403\n",
      "(Epoch 985 / 10000) Train_Loss: 31.873; Val_Loss: 724.503   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 5.672\n",
      "(Epoch 986 / 10000) Train_Loss: 33.611; Val_Loss: 735.535   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.464; Val_NMI: 5.340\n",
      "(Epoch 987 / 10000) Train_Loss: 35.498; Val_Loss: 751.742   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.416; Val_NMI: 5.435\n",
      "(Epoch 988 / 10000) Train_Loss: 32.909; Val_Loss: 725.167   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.425; Val_NMI: 4.703\n",
      "(Epoch 989 / 10000) Train_Loss: 32.644; Val_Loss: 789.835   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.368; Val_NMI: 5.385\n",
      "(Epoch 990 / 10000) Train_Loss: 33.214; Val_Loss: 756.576   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 5.011\n",
      "(Epoch 991 / 10000) Train_Loss: 33.425; Val_Loss: 747.043   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.391; Val_NMI: 5.138\n",
      "(Epoch 992 / 10000) Train_Loss: 36.079; Val_Loss: 736.835   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 4.948\n",
      "(Epoch 993 / 10000) Train_Loss: 35.081; Val_Loss: 766.220   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.432; Val_NMI: 5.469\n",
      "(Epoch 994 / 10000) Train_Loss: 34.397; Val_Loss: 732.156   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 5.347\n",
      "(Epoch 995 / 10000) Train_Loss: 33.685; Val_Loss: 719.468   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 4.970\n",
      "(Epoch 996 / 10000) Train_Loss: 32.198; Val_Loss: 726.738   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.468; Val_NMI: 5.937\n",
      "(Epoch 997 / 10000) Train_Loss: 33.736; Val_Loss: 727.190   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.419; Val_NMI: 4.967\n",
      "(Epoch 998 / 10000) Train_Loss: 34.434; Val_Loss: 714.589   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 5.197\n",
      "(Epoch 999 / 10000) Train_Loss: 33.522; Val_Loss: 693.958   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 4.953\n",
      "(Epoch 1000 / 10000) Train_Loss: 32.455; Val_Loss: 709.219   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 5.211\n",
      "(Epoch 1001 / 10000) Train_Loss: 32.086; Val_Loss: 784.779   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.466; Val_NMI: 5.256\n",
      "(Epoch 1002 / 10000) Train_Loss: 31.233; Val_Loss: 748.301   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.361; Val_NMI: 5.558\n",
      "(Epoch 1003 / 10000) Train_Loss: 31.694; Val_Loss: 707.029   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.416; Val_NMI: 5.597\n",
      "(Epoch 1004 / 10000) Train_Loss: 31.971; Val_Loss: 750.498   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.380; Val_NMI: 4.842\n",
      "(Epoch 1005 / 10000) Train_Loss: 32.025; Val_Loss: 705.393   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 4.883\n",
      "(Epoch 1006 / 10000) Train_Loss: 31.351; Val_Loss: 760.308   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.419; Val_NMI: 5.811\n",
      "(Epoch 1007 / 10000) Train_Loss: 32.027; Val_Loss: 797.179   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.417; Val_NMI: 5.317\n",
      "(Epoch 1008 / 10000) Train_Loss: 31.186; Val_Loss: 757.518   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.485; Val_NMI: 5.366\n",
      "(Epoch 1009 / 10000) Train_Loss: 31.233; Val_Loss: 750.442   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.445; Val_NMI: 5.131\n",
      "(Epoch 1010 / 10000) Train_Loss: 31.049; Val_Loss: 713.442   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.507; Val_NMI: 4.997\n",
      "(Epoch 1011 / 10000) Train_Loss: 31.386; Val_Loss: 712.515   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.469; Val_NMI: 5.611\n",
      "(Epoch 1012 / 10000) Train_Loss: 30.996; Val_Loss: 705.936   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 5.264\n",
      "(Epoch 1013 / 10000) Train_Loss: 31.863; Val_Loss: 782.798   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.432; Val_NMI: 5.471\n",
      "(Epoch 1014 / 10000) Train_Loss: 33.781; Val_Loss: 745.407   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.395\n",
      "(Epoch 1015 / 10000) Train_Loss: 33.757; Val_Loss: 713.955   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 5.937\n",
      "(Epoch 1016 / 10000) Train_Loss: 32.611; Val_Loss: 723.497   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.436; Val_NMI: 5.376\n",
      "(Epoch 1017 / 10000) Train_Loss: 33.008; Val_Loss: 709.806   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.425; Val_NMI: 5.984\n",
      "(Epoch 1018 / 10000) Train_Loss: 34.980; Val_Loss: 718.352   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 6.336\n",
      "(Epoch 1019 / 10000) Train_Loss: 33.052; Val_Loss: 734.372   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.477; Val_NMI: 5.543\n",
      "(Epoch 1020 / 10000) Train_Loss: 34.231; Val_Loss: 731.955   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 4.727\n",
      "(Epoch 1021 / 10000) Train_Loss: 35.068; Val_Loss: 772.509   Train_ACC: 14.909; Val_ACC: 21.481   Train_NMI: 0.409; Val_NMI: 5.936\n",
      "(Epoch 1022 / 10000) Train_Loss: 35.630; Val_Loss: 769.646   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.335; Val_NMI: 5.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1023 / 10000) Train_Loss: 34.669; Val_Loss: 755.597   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 5.030\n",
      "(Epoch 1024 / 10000) Train_Loss: 31.986; Val_Loss: 737.097   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.426; Val_NMI: 5.332\n",
      "(Epoch 1025 / 10000) Train_Loss: 31.213; Val_Loss: 738.641   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 5.227\n",
      "(Epoch 1026 / 10000) Train_Loss: 30.693; Val_Loss: 752.221   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 4.728\n",
      "(Epoch 1027 / 10000) Train_Loss: 31.168; Val_Loss: 768.098   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.179\n",
      "(Epoch 1028 / 10000) Train_Loss: 30.771; Val_Loss: 754.330   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.400; Val_NMI: 5.765\n",
      "(Epoch 1029 / 10000) Train_Loss: 31.168; Val_Loss: 697.178   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.400; Val_NMI: 5.129\n",
      "(Epoch 1030 / 10000) Train_Loss: 31.354; Val_Loss: 736.190   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.391\n",
      "(Epoch 1031 / 10000) Train_Loss: 31.595; Val_Loss: 723.474   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.408; Val_NMI: 4.515\n",
      "(Epoch 1032 / 10000) Train_Loss: 31.804; Val_Loss: 785.763   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 5.377\n",
      "(Epoch 1033 / 10000) Train_Loss: 31.963; Val_Loss: 751.900   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.421; Val_NMI: 5.414\n",
      "(Epoch 1034 / 10000) Train_Loss: 31.901; Val_Loss: 738.801   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 5.558\n",
      "(Epoch 1035 / 10000) Train_Loss: 35.230; Val_Loss: 732.084   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.548\n",
      "(Epoch 1036 / 10000) Train_Loss: 38.446; Val_Loss: 732.013   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.331; Val_NMI: 4.912\n",
      "(Epoch 1037 / 10000) Train_Loss: 33.714; Val_Loss: 763.867   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 5.217\n",
      "(Epoch 1038 / 10000) Train_Loss: 32.293; Val_Loss: 790.819   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 5.531\n",
      "(Epoch 1039 / 10000) Train_Loss: 32.016; Val_Loss: 745.323   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.446; Val_NMI: 5.427\n",
      "(Epoch 1040 / 10000) Train_Loss: 32.862; Val_Loss: 747.753   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.424; Val_NMI: 5.323\n",
      "(Epoch 1041 / 10000) Train_Loss: 32.601; Val_Loss: 754.012   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 4.680\n",
      "(Epoch 1042 / 10000) Train_Loss: 32.890; Val_Loss: 759.126   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.278\n",
      "(Epoch 1043 / 10000) Train_Loss: 35.464; Val_Loss: 742.338   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.368; Val_NMI: 5.993\n",
      "(Epoch 1044 / 10000) Train_Loss: 36.138; Val_Loss: 734.611   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.274\n",
      "(Epoch 1045 / 10000) Train_Loss: 34.011; Val_Loss: 776.639   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 4.934\n",
      "(Epoch 1046 / 10000) Train_Loss: 36.059; Val_Loss: 750.933   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.413; Val_NMI: 5.440\n",
      "(Epoch 1047 / 10000) Train_Loss: 42.357; Val_Loss: 770.921   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.424; Val_NMI: 5.992\n",
      "(Epoch 1048 / 10000) Train_Loss: 38.909; Val_Loss: 737.189   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 5.538\n",
      "(Epoch 1049 / 10000) Train_Loss: 36.059; Val_Loss: 740.132   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.837\n",
      "(Epoch 1050 / 10000) Train_Loss: 36.494; Val_Loss: 759.631   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 5.084\n",
      "(Epoch 1051 / 10000) Train_Loss: 35.079; Val_Loss: 746.335   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 5.350\n",
      "(Epoch 1052 / 10000) Train_Loss: 32.962; Val_Loss: 749.282   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 5.395\n",
      "(Epoch 1053 / 10000) Train_Loss: 31.316; Val_Loss: 754.832   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 5.646\n",
      "(Epoch 1054 / 10000) Train_Loss: 30.626; Val_Loss: 737.208   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.788\n",
      "(Epoch 1055 / 10000) Train_Loss: 31.267; Val_Loss: 742.208   Train_ACC: 14.662; Val_ACC: 21.111   Train_NMI: 0.410; Val_NMI: 5.160\n",
      "(Epoch 1056 / 10000) Train_Loss: 32.172; Val_Loss: 753.328   Train_ACC: 15.280; Val_ACC: 19.630   Train_NMI: 0.547; Val_NMI: 4.754\n",
      "(Epoch 1057 / 10000) Train_Loss: 31.033; Val_Loss: 703.529   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 5.134\n",
      "(Epoch 1058 / 10000) Train_Loss: 30.840; Val_Loss: 762.855   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 5.180\n",
      "(Epoch 1059 / 10000) Train_Loss: 29.996; Val_Loss: 787.976   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 4.944\n",
      "(Epoch 1060 / 10000) Train_Loss: 30.286; Val_Loss: 748.405   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 5.220\n",
      "(Epoch 1061 / 10000) Train_Loss: 31.568; Val_Loss: 810.383   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 6.045\n",
      "(Epoch 1062 / 10000) Train_Loss: 30.442; Val_Loss: 730.967   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.767\n",
      "(Epoch 1063 / 10000) Train_Loss: 30.640; Val_Loss: 788.533   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.944\n",
      "(Epoch 1064 / 10000) Train_Loss: 31.332; Val_Loss: 728.146   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.469; Val_NMI: 5.166\n",
      "(Epoch 1065 / 10000) Train_Loss: 33.020; Val_Loss: 774.423   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.421; Val_NMI: 5.348\n",
      "(Epoch 1066 / 10000) Train_Loss: 31.985; Val_Loss: 739.188   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.455; Val_NMI: 5.298\n",
      "(Epoch 1067 / 10000) Train_Loss: 31.620; Val_Loss: 766.125   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.401; Val_NMI: 6.015\n",
      "(Epoch 1068 / 10000) Train_Loss: 30.454; Val_Loss: 758.330   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.392; Val_NMI: 6.036\n",
      "(Epoch 1069 / 10000) Train_Loss: 31.685; Val_Loss: 748.631   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.363; Val_NMI: 5.395\n",
      "(Epoch 1070 / 10000) Train_Loss: 31.796; Val_Loss: 719.009   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 5.116\n",
      "(Epoch 1071 / 10000) Train_Loss: 30.817; Val_Loss: 738.204   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.374; Val_NMI: 4.700\n",
      "(Epoch 1072 / 10000) Train_Loss: 30.491; Val_Loss: 737.781   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.716\n",
      "(Epoch 1073 / 10000) Train_Loss: 30.447; Val_Loss: 768.328   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 4.634\n",
      "(Epoch 1074 / 10000) Train_Loss: 31.681; Val_Loss: 760.049   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 5.425\n",
      "(Epoch 1075 / 10000) Train_Loss: 31.335; Val_Loss: 737.653   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 4.719\n",
      "(Epoch 1076 / 10000) Train_Loss: 32.293; Val_Loss: 778.617   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.708\n",
      "(Epoch 1077 / 10000) Train_Loss: 32.118; Val_Loss: 759.049   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.459; Val_NMI: 5.244\n",
      "(Epoch 1078 / 10000) Train_Loss: 33.365; Val_Loss: 778.063   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.398; Val_NMI: 4.869\n",
      "(Epoch 1079 / 10000) Train_Loss: 33.564; Val_Loss: 755.255   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.292\n",
      "(Epoch 1080 / 10000) Train_Loss: 33.749; Val_Loss: 771.734   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.357; Val_NMI: 4.770\n",
      "(Epoch 1081 / 10000) Train_Loss: 32.077; Val_Loss: 749.486   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 5.078\n",
      "(Epoch 1082 / 10000) Train_Loss: 32.087; Val_Loss: 758.149   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 5.215\n",
      "(Epoch 1083 / 10000) Train_Loss: 32.057; Val_Loss: 736.310   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 4.891\n",
      "(Epoch 1084 / 10000) Train_Loss: 31.963; Val_Loss: 759.947   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 5.215\n",
      "(Epoch 1085 / 10000) Train_Loss: 31.811; Val_Loss: 743.676   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1086 / 10000) Train_Loss: 32.770; Val_Loss: 744.389   Train_ACC: 15.115; Val_ACC: 21.481   Train_NMI: 0.441; Val_NMI: 5.906\n",
      "(Epoch 1087 / 10000) Train_Loss: 32.233; Val_Loss: 737.119   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.225\n",
      "(Epoch 1088 / 10000) Train_Loss: 31.822; Val_Loss: 745.847   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.411; Val_NMI: 5.547\n",
      "(Epoch 1089 / 10000) Train_Loss: 32.073; Val_Loss: 798.839   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 5.942\n",
      "(Epoch 1090 / 10000) Train_Loss: 31.589; Val_Loss: 772.479   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 5.377\n",
      "(Epoch 1091 / 10000) Train_Loss: 31.821; Val_Loss: 743.656   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 4.886\n",
      "(Epoch 1092 / 10000) Train_Loss: 32.129; Val_Loss: 763.589   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.395; Val_NMI: 5.213\n",
      "(Epoch 1093 / 10000) Train_Loss: 33.659; Val_Loss: 773.901   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.438; Val_NMI: 4.964\n",
      "(Epoch 1094 / 10000) Train_Loss: 33.646; Val_Loss: 748.519   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 4.977\n",
      "(Epoch 1095 / 10000) Train_Loss: 37.995; Val_Loss: 734.486   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.360; Val_NMI: 6.211\n",
      "(Epoch 1096 / 10000) Train_Loss: 34.806; Val_Loss: 731.080   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.377; Val_NMI: 5.516\n",
      "(Epoch 1097 / 10000) Train_Loss: 34.178; Val_Loss: 790.789   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.419; Val_NMI: 5.210\n",
      "(Epoch 1098 / 10000) Train_Loss: 39.796; Val_Loss: 742.685   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.407; Val_NMI: 5.465\n",
      "(Epoch 1099 / 10000) Train_Loss: 40.169; Val_Loss: 765.979   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.435; Val_NMI: 5.501\n",
      "(Epoch 1100 / 10000) Train_Loss: 35.398; Val_Loss: 727.154   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.446; Val_NMI: 4.937\n",
      "(Epoch 1101 / 10000) Train_Loss: 33.222; Val_Loss: 763.609   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.481; Val_NMI: 4.861\n",
      "(Epoch 1102 / 10000) Train_Loss: 32.056; Val_Loss: 770.102   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.424; Val_NMI: 4.486\n",
      "(Epoch 1103 / 10000) Train_Loss: 34.640; Val_Loss: 751.652   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.475; Val_NMI: 4.764\n",
      "(Epoch 1104 / 10000) Train_Loss: 32.344; Val_Loss: 746.231   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 4.830\n",
      "(Epoch 1105 / 10000) Train_Loss: 31.632; Val_Loss: 713.263   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 5.653\n",
      "(Epoch 1106 / 10000) Train_Loss: 31.493; Val_Loss: 798.851   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.002\n",
      "(Epoch 1107 / 10000) Train_Loss: 30.836; Val_Loss: 801.868   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.396; Val_NMI: 5.133\n",
      "(Epoch 1108 / 10000) Train_Loss: 30.200; Val_Loss: 736.531   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 5.636\n",
      "(Epoch 1109 / 10000) Train_Loss: 30.594; Val_Loss: 760.937   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 5.116\n",
      "(Epoch 1110 / 10000) Train_Loss: 31.371; Val_Loss: 772.383   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.434; Val_NMI: 5.081\n",
      "(Epoch 1111 / 10000) Train_Loss: 31.750; Val_Loss: 751.078   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.445; Val_NMI: 5.276\n",
      "(Epoch 1112 / 10000) Train_Loss: 34.278; Val_Loss: 773.375   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 5.246\n",
      "(Epoch 1113 / 10000) Train_Loss: 32.646; Val_Loss: 775.490   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.421; Val_NMI: 5.119\n",
      "(Epoch 1114 / 10000) Train_Loss: 33.298; Val_Loss: 786.980   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.047\n",
      "(Epoch 1115 / 10000) Train_Loss: 33.593; Val_Loss: 725.950   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.393; Val_NMI: 4.988\n",
      "(Epoch 1116 / 10000) Train_Loss: 31.972; Val_Loss: 801.336   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.635\n",
      "(Epoch 1117 / 10000) Train_Loss: 30.533; Val_Loss: 738.849   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.395; Val_NMI: 4.818\n",
      "(Epoch 1118 / 10000) Train_Loss: 30.844; Val_Loss: 763.280   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 5.322\n",
      "(Epoch 1119 / 10000) Train_Loss: 30.243; Val_Loss: 752.174   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.407; Val_NMI: 5.536\n",
      "(Epoch 1120 / 10000) Train_Loss: 31.411; Val_Loss: 808.857   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.385; Val_NMI: 5.584\n",
      "(Epoch 1121 / 10000) Train_Loss: 31.767; Val_Loss: 727.928   Train_ACC: 14.951; Val_ACC: 21.852   Train_NMI: 0.446; Val_NMI: 6.102\n",
      "(Epoch 1122 / 10000) Train_Loss: 32.296; Val_Loss: 735.113   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.443; Val_NMI: 5.800\n",
      "(Epoch 1123 / 10000) Train_Loss: 31.470; Val_Loss: 790.414   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.431; Val_NMI: 5.196\n",
      "(Epoch 1124 / 10000) Train_Loss: 30.764; Val_Loss: 732.716   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.343; Val_NMI: 5.473\n",
      "(Epoch 1125 / 10000) Train_Loss: 31.508; Val_Loss: 753.052   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.391; Val_NMI: 5.713\n",
      "(Epoch 1126 / 10000) Train_Loss: 33.893; Val_Loss: 750.303   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.341\n",
      "(Epoch 1127 / 10000) Train_Loss: 33.740; Val_Loss: 734.653   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 4.831\n",
      "(Epoch 1128 / 10000) Train_Loss: 33.232; Val_Loss: 754.113   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.457; Val_NMI: 5.167\n",
      "(Epoch 1129 / 10000) Train_Loss: 34.119; Val_Loss: 738.469   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 4.867\n",
      "(Epoch 1130 / 10000) Train_Loss: 32.825; Val_Loss: 749.288   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 4.903\n",
      "(Epoch 1131 / 10000) Train_Loss: 30.966; Val_Loss: 801.740   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.409; Val_NMI: 5.691\n",
      "(Epoch 1132 / 10000) Train_Loss: 30.866; Val_Loss: 764.366   Train_ACC: 14.992; Val_ACC: 21.481   Train_NMI: 0.421; Val_NMI: 5.502\n",
      "(Epoch 1133 / 10000) Train_Loss: 32.257; Val_Loss: 743.210   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.368; Val_NMI: 5.469\n",
      "(Epoch 1134 / 10000) Train_Loss: 35.540; Val_Loss: 784.139   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.400; Val_NMI: 5.897\n",
      "(Epoch 1135 / 10000) Train_Loss: 33.077; Val_Loss: 776.769   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.429; Val_NMI: 5.022\n",
      "(Epoch 1136 / 10000) Train_Loss: 37.051; Val_Loss: 812.952   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.431; Val_NMI: 6.020\n",
      "(Epoch 1137 / 10000) Train_Loss: 39.336; Val_Loss: 792.249   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.377; Val_NMI: 6.047\n",
      "(Epoch 1138 / 10000) Train_Loss: 36.303; Val_Loss: 795.076   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.389; Val_NMI: 5.555\n",
      "(Epoch 1139 / 10000) Train_Loss: 33.086; Val_Loss: 728.569   Train_ACC: 14.580; Val_ACC: 21.481   Train_NMI: 0.319; Val_NMI: 5.341\n",
      "(Epoch 1140 / 10000) Train_Loss: 31.498; Val_Loss: 772.174   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.402; Val_NMI: 5.777\n",
      "(Epoch 1141 / 10000) Train_Loss: 30.545; Val_Loss: 756.486   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.381; Val_NMI: 5.473\n",
      "(Epoch 1142 / 10000) Train_Loss: 30.026; Val_Loss: 737.373   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.321; Val_NMI: 5.640\n",
      "(Epoch 1143 / 10000) Train_Loss: 30.215; Val_Loss: 770.897   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.390; Val_NMI: 5.121\n",
      "(Epoch 1144 / 10000) Train_Loss: 30.538; Val_Loss: 772.164   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.353; Val_NMI: 5.209\n",
      "(Epoch 1145 / 10000) Train_Loss: 30.028; Val_Loss: 755.701   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 5.192\n",
      "(Epoch 1146 / 10000) Train_Loss: 29.903; Val_Loss: 746.795   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.410; Val_NMI: 5.245\n",
      "(Epoch 1147 / 10000) Train_Loss: 31.927; Val_Loss: 763.423   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.854\n",
      "(Epoch 1148 / 10000) Train_Loss: 31.197; Val_Loss: 762.338   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 5.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1149 / 10000) Train_Loss: 31.732; Val_Loss: 809.635   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.419; Val_NMI: 5.749\n",
      "(Epoch 1150 / 10000) Train_Loss: 30.379; Val_Loss: 765.362   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.432; Val_NMI: 5.523\n",
      "(Epoch 1151 / 10000) Train_Loss: 29.988; Val_Loss: 726.924   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 5.404\n",
      "(Epoch 1152 / 10000) Train_Loss: 29.793; Val_Loss: 772.663   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 5.222\n",
      "(Epoch 1153 / 10000) Train_Loss: 31.633; Val_Loss: 779.229   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.354; Val_NMI: 6.285\n",
      "(Epoch 1154 / 10000) Train_Loss: 31.111; Val_Loss: 785.514   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.352; Val_NMI: 5.619\n",
      "(Epoch 1155 / 10000) Train_Loss: 31.834; Val_Loss: 779.690   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.361; Val_NMI: 6.061\n",
      "(Epoch 1156 / 10000) Train_Loss: 32.557; Val_Loss: 819.808   Train_ACC: 14.909; Val_ACC: 21.481   Train_NMI: 0.387; Val_NMI: 6.257\n",
      "(Epoch 1157 / 10000) Train_Loss: 31.950; Val_Loss: 749.549   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 5.074\n",
      "(Epoch 1158 / 10000) Train_Loss: 33.013; Val_Loss: 790.246   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.386; Val_NMI: 5.313\n",
      "(Epoch 1159 / 10000) Train_Loss: 34.548; Val_Loss: 779.198   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 5.294\n",
      "(Epoch 1160 / 10000) Train_Loss: 35.637; Val_Loss: 801.041   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 5.662\n",
      "(Epoch 1161 / 10000) Train_Loss: 33.268; Val_Loss: 806.782   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.305; Val_NMI: 5.082\n",
      "(Epoch 1162 / 10000) Train_Loss: 35.087; Val_Loss: 781.756   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.451; Val_NMI: 5.654\n",
      "(Epoch 1163 / 10000) Train_Loss: 32.671; Val_Loss: 786.472   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.379; Val_NMI: 5.740\n",
      "(Epoch 1164 / 10000) Train_Loss: 32.315; Val_Loss: 732.262   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.349; Val_NMI: 6.057\n",
      "(Epoch 1165 / 10000) Train_Loss: 30.240; Val_Loss: 784.721   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.399; Val_NMI: 5.803\n",
      "(Epoch 1166 / 10000) Train_Loss: 30.509; Val_Loss: 761.007   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 5.756\n",
      "(Epoch 1167 / 10000) Train_Loss: 30.621; Val_Loss: 747.215   Train_ACC: 15.157; Val_ACC: 21.481   Train_NMI: 0.391; Val_NMI: 6.079\n",
      "(Epoch 1168 / 10000) Train_Loss: 29.934; Val_Loss: 808.598   Train_ACC: 15.115; Val_ACC: 21.481   Train_NMI: 0.422; Val_NMI: 5.972\n",
      "(Epoch 1169 / 10000) Train_Loss: 29.823; Val_Loss: 746.316   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.417; Val_NMI: 5.705\n",
      "(Epoch 1170 / 10000) Train_Loss: 30.546; Val_Loss: 736.788   Train_ACC: 14.621; Val_ACC: 21.481   Train_NMI: 0.378; Val_NMI: 5.869\n",
      "(Epoch 1171 / 10000) Train_Loss: 31.036; Val_Loss: 739.731   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.336; Val_NMI: 5.531\n",
      "(Epoch 1172 / 10000) Train_Loss: 30.847; Val_Loss: 782.102   Train_ACC: 14.992; Val_ACC: 21.481   Train_NMI: 0.401; Val_NMI: 5.657\n",
      "(Epoch 1173 / 10000) Train_Loss: 31.380; Val_Loss: 777.245   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.480; Val_NMI: 6.053\n",
      "(Epoch 1174 / 10000) Train_Loss: 30.975; Val_Loss: 789.987   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.400; Val_NMI: 5.529\n",
      "(Epoch 1175 / 10000) Train_Loss: 32.417; Val_Loss: 784.936   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 4.913\n",
      "(Epoch 1176 / 10000) Train_Loss: 33.431; Val_Loss: 779.703   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.406; Val_NMI: 5.746\n",
      "(Epoch 1177 / 10000) Train_Loss: 33.853; Val_Loss: 789.062   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 5.641\n",
      "(Epoch 1178 / 10000) Train_Loss: 32.909; Val_Loss: 761.414   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.320; Val_NMI: 6.132\n",
      "(Epoch 1179 / 10000) Train_Loss: 31.781; Val_Loss: 782.877   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.309; Val_NMI: 5.389\n",
      "(Epoch 1180 / 10000) Train_Loss: 30.406; Val_Loss: 765.254   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 5.249\n",
      "(Epoch 1181 / 10000) Train_Loss: 30.111; Val_Loss: 771.232   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.194\n",
      "(Epoch 1182 / 10000) Train_Loss: 30.121; Val_Loss: 759.821   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 5.584\n",
      "(Epoch 1183 / 10000) Train_Loss: 31.117; Val_Loss: 786.103   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.335; Val_NMI: 5.653\n",
      "(Epoch 1184 / 10000) Train_Loss: 32.809; Val_Loss: 781.883   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.343; Val_NMI: 5.583\n",
      "(Epoch 1185 / 10000) Train_Loss: 34.374; Val_Loss: 729.830   Train_ACC: 14.909; Val_ACC: 21.852   Train_NMI: 0.396; Val_NMI: 6.118\n",
      "(Epoch 1186 / 10000) Train_Loss: 32.909; Val_Loss: 777.913   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 5.008\n",
      "(Epoch 1187 / 10000) Train_Loss: 31.348; Val_Loss: 782.768   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 4.652\n",
      "(Epoch 1188 / 10000) Train_Loss: 31.446; Val_Loss: 811.449   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 4.788\n",
      "(Epoch 1189 / 10000) Train_Loss: 30.901; Val_Loss: 756.949   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.419; Val_NMI: 5.569\n",
      "(Epoch 1190 / 10000) Train_Loss: 32.138; Val_Loss: 746.566   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.578\n",
      "(Epoch 1191 / 10000) Train_Loss: 33.595; Val_Loss: 795.033   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.410; Val_NMI: 5.428\n",
      "(Epoch 1192 / 10000) Train_Loss: 34.790; Val_Loss: 783.090   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.399; Val_NMI: 5.208\n",
      "(Epoch 1193 / 10000) Train_Loss: 37.260; Val_Loss: 822.785   Train_ACC: 14.909; Val_ACC: 21.481   Train_NMI: 0.433; Val_NMI: 5.156\n",
      "(Epoch 1194 / 10000) Train_Loss: 34.041; Val_Loss: 762.279   Train_ACC: 15.198; Val_ACC: 20.741   Train_NMI: 0.443; Val_NMI: 5.615\n",
      "(Epoch 1195 / 10000) Train_Loss: 33.949; Val_Loss: 782.870   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.390; Val_NMI: 5.665\n",
      "(Epoch 1196 / 10000) Train_Loss: 36.348; Val_Loss: 771.584   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.383; Val_NMI: 5.113\n",
      "(Epoch 1197 / 10000) Train_Loss: 41.408; Val_Loss: 825.110   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 5.198\n",
      "(Epoch 1198 / 10000) Train_Loss: 35.610; Val_Loss: 766.038   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.421; Val_NMI: 5.874\n",
      "(Epoch 1199 / 10000) Train_Loss: 33.553; Val_Loss: 742.617   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 5.160\n",
      "(Epoch 1200 / 10000) Train_Loss: 30.968; Val_Loss: 733.188   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.346; Val_NMI: 5.760\n",
      "(Epoch 1201 / 10000) Train_Loss: 29.865; Val_Loss: 739.663   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.382; Val_NMI: 5.936\n",
      "(Epoch 1202 / 10000) Train_Loss: 29.847; Val_Loss: 739.716   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.347; Val_NMI: 6.045\n",
      "(Epoch 1203 / 10000) Train_Loss: 29.160; Val_Loss: 777.150   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.400; Val_NMI: 6.280\n",
      "(Epoch 1204 / 10000) Train_Loss: 29.585; Val_Loss: 740.352   Train_ACC: 14.992; Val_ACC: 22.222   Train_NMI: 0.392; Val_NMI: 6.429\n",
      "(Epoch 1205 / 10000) Train_Loss: 29.625; Val_Loss: 770.912   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 5.383\n",
      "(Epoch 1206 / 10000) Train_Loss: 29.791; Val_Loss: 744.478   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.391; Val_NMI: 4.700\n",
      "(Epoch 1207 / 10000) Train_Loss: 30.715; Val_Loss: 790.531   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 5.114\n",
      "(Epoch 1208 / 10000) Train_Loss: 29.941; Val_Loss: 776.385   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 5.831\n",
      "(Epoch 1209 / 10000) Train_Loss: 30.361; Val_Loss: 782.862   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.407; Val_NMI: 5.266\n",
      "(Epoch 1210 / 10000) Train_Loss: 30.282; Val_Loss: 744.816   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.435; Val_NMI: 5.128\n",
      "(Epoch 1211 / 10000) Train_Loss: 30.473; Val_Loss: 770.898   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.417; Val_NMI: 5.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1212 / 10000) Train_Loss: 30.027; Val_Loss: 815.786   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.409; Val_NMI: 6.028\n",
      "(Epoch 1213 / 10000) Train_Loss: 29.114; Val_Loss: 764.411   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.382; Val_NMI: 4.970\n",
      "(Epoch 1214 / 10000) Train_Loss: 30.153; Val_Loss: 770.504   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 5.459\n",
      "(Epoch 1215 / 10000) Train_Loss: 32.366; Val_Loss: 790.480   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.399; Val_NMI: 5.744\n",
      "(Epoch 1216 / 10000) Train_Loss: 40.038; Val_Loss: 744.172   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 5.435\n",
      "(Epoch 1217 / 10000) Train_Loss: 37.898; Val_Loss: 793.559   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 5.602\n",
      "(Epoch 1218 / 10000) Train_Loss: 35.322; Val_Loss: 809.153   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.375; Val_NMI: 6.254\n",
      "(Epoch 1219 / 10000) Train_Loss: 33.243; Val_Loss: 826.650   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.408; Val_NMI: 5.436\n",
      "(Epoch 1220 / 10000) Train_Loss: 30.912; Val_Loss: 771.170   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.378; Val_NMI: 5.450\n",
      "(Epoch 1221 / 10000) Train_Loss: 30.314; Val_Loss: 782.267   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.385; Val_NMI: 6.080\n",
      "(Epoch 1222 / 10000) Train_Loss: 32.878; Val_Loss: 796.068   Train_ACC: 14.868; Val_ACC: 21.852   Train_NMI: 0.390; Val_NMI: 6.063\n",
      "(Epoch 1223 / 10000) Train_Loss: 33.864; Val_Loss: 807.357   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 5.360\n",
      "(Epoch 1224 / 10000) Train_Loss: 31.377; Val_Loss: 774.321   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 5.520\n",
      "(Epoch 1225 / 10000) Train_Loss: 31.610; Val_Loss: 743.948   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.360; Val_NMI: 5.750\n",
      "(Epoch 1226 / 10000) Train_Loss: 31.751; Val_Loss: 778.585   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.377; Val_NMI: 5.796\n",
      "(Epoch 1227 / 10000) Train_Loss: 30.098; Val_Loss: 784.263   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.419; Val_NMI: 5.499\n",
      "(Epoch 1228 / 10000) Train_Loss: 29.286; Val_Loss: 777.708   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.407; Val_NMI: 6.136\n",
      "(Epoch 1229 / 10000) Train_Loss: 29.232; Val_Loss: 777.629   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.355; Val_NMI: 6.114\n",
      "(Epoch 1230 / 10000) Train_Loss: 31.372; Val_Loss: 816.083   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.398; Val_NMI: 5.955\n",
      "(Epoch 1231 / 10000) Train_Loss: 30.931; Val_Loss: 772.968   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 5.748\n",
      "(Epoch 1232 / 10000) Train_Loss: 32.824; Val_Loss: 812.985   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.400; Val_NMI: 6.328\n",
      "(Epoch 1233 / 10000) Train_Loss: 34.453; Val_Loss: 792.281   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.389; Val_NMI: 5.456\n",
      "(Epoch 1234 / 10000) Train_Loss: 31.604; Val_Loss: 758.647   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.320; Val_NMI: 6.047\n",
      "(Epoch 1235 / 10000) Train_Loss: 30.328; Val_Loss: 820.867   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.350; Val_NMI: 5.660\n",
      "(Epoch 1236 / 10000) Train_Loss: 31.110; Val_Loss: 775.749   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.386; Val_NMI: 5.695\n",
      "(Epoch 1237 / 10000) Train_Loss: 31.022; Val_Loss: 757.829   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.422; Val_NMI: 5.768\n",
      "(Epoch 1238 / 10000) Train_Loss: 29.735; Val_Loss: 755.963   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.365; Val_NMI: 5.424\n",
      "(Epoch 1239 / 10000) Train_Loss: 30.381; Val_Loss: 755.043   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.369; Val_NMI: 5.519\n",
      "(Epoch 1240 / 10000) Train_Loss: 30.655; Val_Loss: 784.579   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.407; Val_NMI: 5.434\n",
      "(Epoch 1241 / 10000) Train_Loss: 31.054; Val_Loss: 776.651   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.355; Val_NMI: 5.398\n",
      "(Epoch 1242 / 10000) Train_Loss: 30.998; Val_Loss: 835.922   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.349; Val_NMI: 5.900\n",
      "(Epoch 1243 / 10000) Train_Loss: 31.159; Val_Loss: 793.167   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.448; Val_NMI: 5.843\n",
      "(Epoch 1244 / 10000) Train_Loss: 32.157; Val_Loss: 744.312   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 4.833\n",
      "(Epoch 1245 / 10000) Train_Loss: 30.830; Val_Loss: 773.567   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.465; Val_NMI: 4.639\n",
      "(Epoch 1246 / 10000) Train_Loss: 30.492; Val_Loss: 784.402   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.368; Val_NMI: 5.203\n",
      "(Epoch 1247 / 10000) Train_Loss: 31.260; Val_Loss: 843.756   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.341; Val_NMI: 5.330\n",
      "(Epoch 1248 / 10000) Train_Loss: 31.705; Val_Loss: 841.115   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.374\n",
      "(Epoch 1249 / 10000) Train_Loss: 30.591; Val_Loss: 793.729   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.372; Val_NMI: 5.338\n",
      "(Epoch 1250 / 10000) Train_Loss: 30.145; Val_Loss: 832.144   Train_ACC: 14.662; Val_ACC: 21.111   Train_NMI: 0.362; Val_NMI: 5.320\n",
      "(Epoch 1251 / 10000) Train_Loss: 31.150; Val_Loss: 798.856   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.925\n",
      "(Epoch 1252 / 10000) Train_Loss: 30.257; Val_Loss: 758.133   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.470\n",
      "(Epoch 1253 / 10000) Train_Loss: 30.834; Val_Loss: 803.632   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 4.817\n",
      "(Epoch 1254 / 10000) Train_Loss: 33.227; Val_Loss: 791.150   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.356; Val_NMI: 5.245\n",
      "(Epoch 1255 / 10000) Train_Loss: 37.641; Val_Loss: 810.092   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.671\n",
      "(Epoch 1256 / 10000) Train_Loss: 36.993; Val_Loss: 822.608   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.329; Val_NMI: 5.552\n",
      "(Epoch 1257 / 10000) Train_Loss: 33.609; Val_Loss: 770.950   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 5.169\n",
      "(Epoch 1258 / 10000) Train_Loss: 33.021; Val_Loss: 793.543   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.426; Val_NMI: 5.568\n",
      "(Epoch 1259 / 10000) Train_Loss: 31.302; Val_Loss: 801.999   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.416; Val_NMI: 4.963\n",
      "(Epoch 1260 / 10000) Train_Loss: 30.920; Val_Loss: 761.388   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 4.845\n",
      "(Epoch 1261 / 10000) Train_Loss: 32.317; Val_Loss: 812.872   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.528\n",
      "(Epoch 1262 / 10000) Train_Loss: 30.798; Val_Loss: 782.422   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 4.974\n",
      "(Epoch 1263 / 10000) Train_Loss: 29.123; Val_Loss: 775.975   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.332; Val_NMI: 5.463\n",
      "(Epoch 1264 / 10000) Train_Loss: 29.222; Val_Loss: 785.640   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.393; Val_NMI: 5.222\n",
      "(Epoch 1265 / 10000) Train_Loss: 29.374; Val_Loss: 791.233   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 5.366\n",
      "(Epoch 1266 / 10000) Train_Loss: 30.143; Val_Loss: 797.648   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.402; Val_NMI: 5.011\n",
      "(Epoch 1267 / 10000) Train_Loss: 35.511; Val_Loss: 835.786   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.451; Val_NMI: 5.137\n",
      "(Epoch 1268 / 10000) Train_Loss: 34.268; Val_Loss: 807.394   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.383\n",
      "(Epoch 1269 / 10000) Train_Loss: 31.225; Val_Loss: 746.104   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.388; Val_NMI: 5.745\n",
      "(Epoch 1270 / 10000) Train_Loss: 31.239; Val_Loss: 828.872   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.439; Val_NMI: 4.903\n",
      "(Epoch 1271 / 10000) Train_Loss: 31.163; Val_Loss: 795.963   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.366; Val_NMI: 5.041\n",
      "(Epoch 1272 / 10000) Train_Loss: 29.858; Val_Loss: 754.515   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.409; Val_NMI: 5.190\n",
      "(Epoch 1273 / 10000) Train_Loss: 29.191; Val_Loss: 799.034   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.406; Val_NMI: 5.482\n",
      "(Epoch 1274 / 10000) Train_Loss: 29.704; Val_Loss: 770.708   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 5.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1275 / 10000) Train_Loss: 29.567; Val_Loss: 792.009   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.443; Val_NMI: 4.687\n",
      "(Epoch 1276 / 10000) Train_Loss: 29.058; Val_Loss: 807.831   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.212\n",
      "(Epoch 1277 / 10000) Train_Loss: 29.768; Val_Loss: 772.740   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.093\n",
      "(Epoch 1278 / 10000) Train_Loss: 30.890; Val_Loss: 779.504   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.458; Val_NMI: 5.545\n",
      "(Epoch 1279 / 10000) Train_Loss: 32.131; Val_Loss: 817.363   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.621\n",
      "(Epoch 1280 / 10000) Train_Loss: 32.151; Val_Loss: 838.715   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.923\n",
      "(Epoch 1281 / 10000) Train_Loss: 33.162; Val_Loss: 817.938   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.391; Val_NMI: 6.138\n",
      "(Epoch 1282 / 10000) Train_Loss: 31.735; Val_Loss: 787.035   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.388; Val_NMI: 4.859\n",
      "(Epoch 1283 / 10000) Train_Loss: 31.057; Val_Loss: 761.057   Train_ACC: 14.539; Val_ACC: 20.741   Train_NMI: 0.340; Val_NMI: 5.824\n",
      "(Epoch 1284 / 10000) Train_Loss: 31.945; Val_Loss: 742.808   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.454; Val_NMI: 4.758\n",
      "(Epoch 1285 / 10000) Train_Loss: 31.745; Val_Loss: 834.491   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 5.654\n",
      "(Epoch 1286 / 10000) Train_Loss: 31.074; Val_Loss: 838.985   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.456; Val_NMI: 5.540\n",
      "(Epoch 1287 / 10000) Train_Loss: 30.880; Val_Loss: 824.487   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 5.244\n",
      "(Epoch 1288 / 10000) Train_Loss: 32.543; Val_Loss: 795.753   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.718\n",
      "(Epoch 1289 / 10000) Train_Loss: 32.678; Val_Loss: 789.780   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.310; Val_NMI: 4.288\n",
      "(Epoch 1290 / 10000) Train_Loss: 32.012; Val_Loss: 789.429   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.492\n",
      "(Epoch 1291 / 10000) Train_Loss: 31.231; Val_Loss: 827.078   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 5.585\n",
      "(Epoch 1292 / 10000) Train_Loss: 33.284; Val_Loss: 799.723   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.401; Val_NMI: 5.188\n",
      "(Epoch 1293 / 10000) Train_Loss: 32.406; Val_Loss: 810.505   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.377; Val_NMI: 4.937\n",
      "(Epoch 1294 / 10000) Train_Loss: 31.450; Val_Loss: 825.435   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.401; Val_NMI: 4.951\n",
      "(Epoch 1295 / 10000) Train_Loss: 29.865; Val_Loss: 772.868   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.665\n",
      "(Epoch 1296 / 10000) Train_Loss: 29.898; Val_Loss: 786.358   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 4.487\n",
      "(Epoch 1297 / 10000) Train_Loss: 29.783; Val_Loss: 777.630   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.342; Val_NMI: 6.099\n",
      "(Epoch 1298 / 10000) Train_Loss: 30.960; Val_Loss: 811.354   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.377; Val_NMI: 5.066\n",
      "(Epoch 1299 / 10000) Train_Loss: 30.371; Val_Loss: 767.099   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 6.300\n",
      "(Epoch 1300 / 10000) Train_Loss: 30.757; Val_Loss: 821.658   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 4.751\n",
      "(Epoch 1301 / 10000) Train_Loss: 31.161; Val_Loss: 817.995   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 5.154\n",
      "(Epoch 1302 / 10000) Train_Loss: 29.986; Val_Loss: 792.567   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 4.460\n",
      "(Epoch 1303 / 10000) Train_Loss: 30.626; Val_Loss: 750.462   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.448; Val_NMI: 4.744\n",
      "(Epoch 1304 / 10000) Train_Loss: 32.251; Val_Loss: 892.392   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.412; Val_NMI: 5.441\n",
      "(Epoch 1305 / 10000) Train_Loss: 32.334; Val_Loss: 800.625   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.397; Val_NMI: 5.198\n",
      "(Epoch 1306 / 10000) Train_Loss: 31.953; Val_Loss: 836.858   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.882\n",
      "(Epoch 1307 / 10000) Train_Loss: 32.603; Val_Loss: 804.418   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.396\n",
      "(Epoch 1308 / 10000) Train_Loss: 31.878; Val_Loss: 808.958   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.439; Val_NMI: 4.917\n",
      "(Epoch 1309 / 10000) Train_Loss: 32.493; Val_Loss: 797.721   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.435; Val_NMI: 5.334\n",
      "(Epoch 1310 / 10000) Train_Loss: 30.855; Val_Loss: 826.053   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 4.924\n",
      "(Epoch 1311 / 10000) Train_Loss: 30.533; Val_Loss: 757.368   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 5.485\n",
      "(Epoch 1312 / 10000) Train_Loss: 31.063; Val_Loss: 810.225   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.211\n",
      "(Epoch 1313 / 10000) Train_Loss: 30.527; Val_Loss: 772.467   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.417; Val_NMI: 5.260\n",
      "(Epoch 1314 / 10000) Train_Loss: 29.631; Val_Loss: 835.850   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.987\n",
      "(Epoch 1315 / 10000) Train_Loss: 31.487; Val_Loss: 761.626   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 5.156\n",
      "(Epoch 1316 / 10000) Train_Loss: 34.112; Val_Loss: 793.090   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 4.765\n",
      "(Epoch 1317 / 10000) Train_Loss: 37.126; Val_Loss: 801.146   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.366; Val_NMI: 5.389\n",
      "(Epoch 1318 / 10000) Train_Loss: 36.026; Val_Loss: 833.496   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.055\n",
      "(Epoch 1319 / 10000) Train_Loss: 33.092; Val_Loss: 838.171   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.795\n",
      "(Epoch 1320 / 10000) Train_Loss: 31.611; Val_Loss: 774.705   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.256\n",
      "(Epoch 1321 / 10000) Train_Loss: 30.570; Val_Loss: 790.125   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.393; Val_NMI: 4.946\n",
      "(Epoch 1322 / 10000) Train_Loss: 30.064; Val_Loss: 818.529   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 4.878\n",
      "(Epoch 1323 / 10000) Train_Loss: 32.025; Val_Loss: 794.472   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 5.610\n",
      "(Epoch 1324 / 10000) Train_Loss: 31.266; Val_Loss: 802.083   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 4.829\n",
      "(Epoch 1325 / 10000) Train_Loss: 31.836; Val_Loss: 758.113   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.172\n",
      "(Epoch 1326 / 10000) Train_Loss: 30.618; Val_Loss: 790.731   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 4.429\n",
      "(Epoch 1327 / 10000) Train_Loss: 30.906; Val_Loss: 780.539   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.487; Val_NMI: 4.893\n",
      "(Epoch 1328 / 10000) Train_Loss: 31.187; Val_Loss: 818.752   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.450\n",
      "(Epoch 1329 / 10000) Train_Loss: 30.486; Val_Loss: 810.984   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.398; Val_NMI: 4.869\n",
      "(Epoch 1330 / 10000) Train_Loss: 29.790; Val_Loss: 821.967   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.407; Val_NMI: 5.013\n",
      "(Epoch 1331 / 10000) Train_Loss: 29.985; Val_Loss: 822.326   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.416; Val_NMI: 4.397\n",
      "(Epoch 1332 / 10000) Train_Loss: 30.375; Val_Loss: 823.377   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.453; Val_NMI: 5.498\n",
      "(Epoch 1333 / 10000) Train_Loss: 30.077; Val_Loss: 790.635   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 4.960\n",
      "(Epoch 1334 / 10000) Train_Loss: 33.080; Val_Loss: 754.954   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 4.536\n",
      "(Epoch 1335 / 10000) Train_Loss: 32.920; Val_Loss: 767.702   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.418; Val_NMI: 4.588\n",
      "(Epoch 1336 / 10000) Train_Loss: 31.332; Val_Loss: 760.834   Train_ACC: 14.992; Val_ACC: 21.481   Train_NMI: 0.421; Val_NMI: 4.831\n",
      "(Epoch 1337 / 10000) Train_Loss: 30.012; Val_Loss: 801.716   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.454; Val_NMI: 5.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1338 / 10000) Train_Loss: 28.914; Val_Loss: 786.941   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 5.167\n",
      "(Epoch 1339 / 10000) Train_Loss: 29.189; Val_Loss: 801.406   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.431; Val_NMI: 5.190\n",
      "(Epoch 1340 / 10000) Train_Loss: 30.322; Val_Loss: 763.050   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.434; Val_NMI: 4.682\n",
      "(Epoch 1341 / 10000) Train_Loss: 29.969; Val_Loss: 850.683   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.477; Val_NMI: 4.974\n",
      "(Epoch 1342 / 10000) Train_Loss: 30.201; Val_Loss: 793.986   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.455; Val_NMI: 5.266\n",
      "(Epoch 1343 / 10000) Train_Loss: 30.558; Val_Loss: 773.410   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.336; Val_NMI: 5.298\n",
      "(Epoch 1344 / 10000) Train_Loss: 29.607; Val_Loss: 818.181   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.345; Val_NMI: 5.366\n",
      "(Epoch 1345 / 10000) Train_Loss: 30.259; Val_Loss: 867.740   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.410; Val_NMI: 5.198\n",
      "(Epoch 1346 / 10000) Train_Loss: 31.621; Val_Loss: 827.225   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.388; Val_NMI: 5.399\n",
      "(Epoch 1347 / 10000) Train_Loss: 34.678; Val_Loss: 778.474   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.467; Val_NMI: 4.857\n",
      "(Epoch 1348 / 10000) Train_Loss: 34.461; Val_Loss: 828.471   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.322; Val_NMI: 4.984\n",
      "(Epoch 1349 / 10000) Train_Loss: 31.126; Val_Loss: 777.763   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.340; Val_NMI: 4.847\n",
      "(Epoch 1350 / 10000) Train_Loss: 30.303; Val_Loss: 832.823   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.406; Val_NMI: 5.374\n",
      "(Epoch 1351 / 10000) Train_Loss: 29.814; Val_Loss: 774.423   Train_ACC: 14.456; Val_ACC: 20.370   Train_NMI: 0.281; Val_NMI: 4.828\n",
      "(Epoch 1352 / 10000) Train_Loss: 29.769; Val_Loss: 770.246   Train_ACC: 15.280; Val_ACC: 20.370   Train_NMI: 0.462; Val_NMI: 5.104\n",
      "(Epoch 1353 / 10000) Train_Loss: 30.345; Val_Loss: 753.557   Train_ACC: 15.321; Val_ACC: 20.741   Train_NMI: 0.450; Val_NMI: 4.711\n",
      "(Epoch 1354 / 10000) Train_Loss: 29.199; Val_Loss: 827.066   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 5.390\n",
      "(Epoch 1355 / 10000) Train_Loss: 28.904; Val_Loss: 795.743   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.387; Val_NMI: 4.953\n",
      "(Epoch 1356 / 10000) Train_Loss: 30.877; Val_Loss: 818.267   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 5.633\n",
      "(Epoch 1357 / 10000) Train_Loss: 31.544; Val_Loss: 826.832   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.466; Val_NMI: 4.975\n",
      "(Epoch 1358 / 10000) Train_Loss: 30.258; Val_Loss: 831.022   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.771\n",
      "(Epoch 1359 / 10000) Train_Loss: 31.238; Val_Loss: 792.746   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.370; Val_NMI: 4.789\n",
      "(Epoch 1360 / 10000) Train_Loss: 29.699; Val_Loss: 801.963   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.369; Val_NMI: 4.966\n",
      "(Epoch 1361 / 10000) Train_Loss: 33.328; Val_Loss: 820.151   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.425; Val_NMI: 4.362\n",
      "(Epoch 1362 / 10000) Train_Loss: 32.756; Val_Loss: 807.536   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.404; Val_NMI: 4.839\n",
      "(Epoch 1363 / 10000) Train_Loss: 32.904; Val_Loss: 808.352   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.424; Val_NMI: 4.854\n",
      "(Epoch 1364 / 10000) Train_Loss: 32.549; Val_Loss: 799.903   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.442; Val_NMI: 4.553\n",
      "(Epoch 1365 / 10000) Train_Loss: 30.575; Val_Loss: 799.305   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.324; Val_NMI: 5.225\n",
      "(Epoch 1366 / 10000) Train_Loss: 30.206; Val_Loss: 773.364   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.807\n",
      "(Epoch 1367 / 10000) Train_Loss: 30.107; Val_Loss: 803.410   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.568\n",
      "(Epoch 1368 / 10000) Train_Loss: 30.208; Val_Loss: 792.718   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.289\n",
      "(Epoch 1369 / 10000) Train_Loss: 29.844; Val_Loss: 796.091   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.398; Val_NMI: 4.843\n",
      "(Epoch 1370 / 10000) Train_Loss: 31.624; Val_Loss: 799.957   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.422; Val_NMI: 4.964\n",
      "(Epoch 1371 / 10000) Train_Loss: 32.537; Val_Loss: 806.973   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 4.535\n",
      "(Epoch 1372 / 10000) Train_Loss: 32.655; Val_Loss: 816.468   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 4.689\n",
      "(Epoch 1373 / 10000) Train_Loss: 32.520; Val_Loss: 819.918   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 4.856\n",
      "(Epoch 1374 / 10000) Train_Loss: 31.310; Val_Loss: 774.770   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 4.717\n",
      "(Epoch 1375 / 10000) Train_Loss: 32.062; Val_Loss: 797.171   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.378; Val_NMI: 5.071\n",
      "(Epoch 1376 / 10000) Train_Loss: 30.764; Val_Loss: 800.064   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 5.446\n",
      "(Epoch 1377 / 10000) Train_Loss: 30.495; Val_Loss: 825.387   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.374; Val_NMI: 5.170\n",
      "(Epoch 1378 / 10000) Train_Loss: 31.216; Val_Loss: 813.128   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 4.601\n",
      "(Epoch 1379 / 10000) Train_Loss: 30.853; Val_Loss: 780.673   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.413; Val_NMI: 4.651\n",
      "(Epoch 1380 / 10000) Train_Loss: 30.104; Val_Loss: 790.532   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.849\n",
      "(Epoch 1381 / 10000) Train_Loss: 29.792; Val_Loss: 810.392   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.423; Val_NMI: 4.625\n",
      "(Epoch 1382 / 10000) Train_Loss: 29.857; Val_Loss: 803.044   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.497; Val_NMI: 4.727\n",
      "(Epoch 1383 / 10000) Train_Loss: 30.599; Val_Loss: 810.761   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.425; Val_NMI: 4.542\n",
      "(Epoch 1384 / 10000) Train_Loss: 33.540; Val_Loss: 831.148   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 4.252\n",
      "(Epoch 1385 / 10000) Train_Loss: 31.452; Val_Loss: 765.989   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 4.373\n",
      "(Epoch 1386 / 10000) Train_Loss: 29.529; Val_Loss: 824.482   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.397; Val_NMI: 4.475\n",
      "(Epoch 1387 / 10000) Train_Loss: 30.835; Val_Loss: 836.445   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.372; Val_NMI: 4.386\n",
      "(Epoch 1388 / 10000) Train_Loss: 32.336; Val_Loss: 819.509   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.389; Val_NMI: 4.499\n",
      "(Epoch 1389 / 10000) Train_Loss: 31.894; Val_Loss: 826.144   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.455; Val_NMI: 4.577\n",
      "(Epoch 1390 / 10000) Train_Loss: 32.895; Val_Loss: 812.625   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.615\n",
      "(Epoch 1391 / 10000) Train_Loss: 32.607; Val_Loss: 818.223   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.459; Val_NMI: 4.511\n",
      "(Epoch 1392 / 10000) Train_Loss: 31.639; Val_Loss: 824.201   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 4.539\n",
      "(Epoch 1393 / 10000) Train_Loss: 31.722; Val_Loss: 843.491   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.379; Val_NMI: 4.774\n",
      "(Epoch 1394 / 10000) Train_Loss: 31.476; Val_Loss: 780.432   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 4.570\n",
      "(Epoch 1395 / 10000) Train_Loss: 30.459; Val_Loss: 802.328   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.288\n",
      "(Epoch 1396 / 10000) Train_Loss: 30.861; Val_Loss: 821.836   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.417; Val_NMI: 4.283\n",
      "(Epoch 1397 / 10000) Train_Loss: 30.835; Val_Loss: 795.021   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.429; Val_NMI: 4.834\n",
      "(Epoch 1398 / 10000) Train_Loss: 30.880; Val_Loss: 839.288   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.349; Val_NMI: 4.606\n",
      "(Epoch 1399 / 10000) Train_Loss: 29.768; Val_Loss: 801.311   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 4.487\n",
      "(Epoch 1400 / 10000) Train_Loss: 29.781; Val_Loss: 815.610   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 5.319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1401 / 10000) Train_Loss: 29.273; Val_Loss: 808.363   Train_ACC: 14.662; Val_ACC: 21.481   Train_NMI: 0.356; Val_NMI: 4.973\n",
      "(Epoch 1402 / 10000) Train_Loss: 29.613; Val_Loss: 819.517   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.397; Val_NMI: 5.215\n",
      "(Epoch 1403 / 10000) Train_Loss: 30.907; Val_Loss: 775.287   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 4.882\n",
      "(Epoch 1404 / 10000) Train_Loss: 31.088; Val_Loss: 800.789   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 4.644\n",
      "(Epoch 1405 / 10000) Train_Loss: 30.584; Val_Loss: 766.880   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.389; Val_NMI: 5.085\n",
      "(Epoch 1406 / 10000) Train_Loss: 30.319; Val_Loss: 845.903   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 4.615\n",
      "(Epoch 1407 / 10000) Train_Loss: 30.599; Val_Loss: 785.834   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 5.144\n",
      "(Epoch 1408 / 10000) Train_Loss: 29.100; Val_Loss: 771.307   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 5.363\n",
      "(Epoch 1409 / 10000) Train_Loss: 29.244; Val_Loss: 798.697   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.281\n",
      "(Epoch 1410 / 10000) Train_Loss: 30.359; Val_Loss: 862.928   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.730\n",
      "(Epoch 1411 / 10000) Train_Loss: 31.890; Val_Loss: 815.375   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.429; Val_NMI: 4.701\n",
      "(Epoch 1412 / 10000) Train_Loss: 32.363; Val_Loss: 796.647   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 4.861\n",
      "(Epoch 1413 / 10000) Train_Loss: 30.418; Val_Loss: 837.351   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.365; Val_NMI: 5.179\n",
      "(Epoch 1414 / 10000) Train_Loss: 29.889; Val_Loss: 822.555   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.408; Val_NMI: 5.157\n",
      "(Epoch 1415 / 10000) Train_Loss: 31.915; Val_Loss: 870.333   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 5.186\n",
      "(Epoch 1416 / 10000) Train_Loss: 32.828; Val_Loss: 845.693   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.409; Val_NMI: 5.567\n",
      "(Epoch 1417 / 10000) Train_Loss: 32.061; Val_Loss: 809.350   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 5.166\n",
      "(Epoch 1418 / 10000) Train_Loss: 30.747; Val_Loss: 804.089   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.882\n",
      "(Epoch 1419 / 10000) Train_Loss: 30.180; Val_Loss: 831.976   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 4.787\n",
      "(Epoch 1420 / 10000) Train_Loss: 31.336; Val_Loss: 824.512   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.440; Val_NMI: 5.069\n",
      "(Epoch 1421 / 10000) Train_Loss: 41.289; Val_Loss: 843.428   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.427; Val_NMI: 4.894\n",
      "(Epoch 1422 / 10000) Train_Loss: 44.855; Val_Loss: 800.925   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.374; Val_NMI: 5.060\n",
      "(Epoch 1423 / 10000) Train_Loss: 40.022; Val_Loss: 833.439   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 4.847\n",
      "(Epoch 1424 / 10000) Train_Loss: 32.886; Val_Loss: 761.911   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 5.072\n",
      "(Epoch 1425 / 10000) Train_Loss: 31.187; Val_Loss: 861.809   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.377; Val_NMI: 4.756\n",
      "(Epoch 1426 / 10000) Train_Loss: 29.901; Val_Loss: 757.112   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.543\n",
      "(Epoch 1427 / 10000) Train_Loss: 29.088; Val_Loss: 810.528   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.357; Val_NMI: 4.740\n",
      "(Epoch 1428 / 10000) Train_Loss: 29.029; Val_Loss: 770.982   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.357; Val_NMI: 5.272\n",
      "(Epoch 1429 / 10000) Train_Loss: 28.424; Val_Loss: 813.144   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.447; Val_NMI: 4.856\n",
      "(Epoch 1430 / 10000) Train_Loss: 28.504; Val_Loss: 767.042   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 4.961\n",
      "(Epoch 1431 / 10000) Train_Loss: 28.238; Val_Loss: 792.452   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.436; Val_NMI: 4.957\n",
      "(Epoch 1432 / 10000) Train_Loss: 28.897; Val_Loss: 779.706   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 4.784\n",
      "(Epoch 1433 / 10000) Train_Loss: 29.348; Val_Loss: 817.713   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 5.044\n",
      "(Epoch 1434 / 10000) Train_Loss: 28.846; Val_Loss: 780.814   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 4.590\n",
      "(Epoch 1435 / 10000) Train_Loss: 28.882; Val_Loss: 817.862   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.483; Val_NMI: 5.360\n",
      "(Epoch 1436 / 10000) Train_Loss: 30.667; Val_Loss: 793.742   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.360; Val_NMI: 4.582\n",
      "(Epoch 1437 / 10000) Train_Loss: 30.130; Val_Loss: 824.556   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.386; Val_NMI: 4.725\n",
      "(Epoch 1438 / 10000) Train_Loss: 29.119; Val_Loss: 799.730   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.466; Val_NMI: 4.195\n",
      "(Epoch 1439 / 10000) Train_Loss: 29.555; Val_Loss: 827.103   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.450; Val_NMI: 5.071\n",
      "(Epoch 1440 / 10000) Train_Loss: 30.235; Val_Loss: 817.271   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.324\n",
      "(Epoch 1441 / 10000) Train_Loss: 29.182; Val_Loss: 820.855   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.359; Val_NMI: 4.209\n",
      "(Epoch 1442 / 10000) Train_Loss: 29.407; Val_Loss: 804.087   Train_ACC: 15.115; Val_ACC: 21.111   Train_NMI: 0.432; Val_NMI: 4.901\n",
      "(Epoch 1443 / 10000) Train_Loss: 29.096; Val_Loss: 776.110   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 4.328\n",
      "(Epoch 1444 / 10000) Train_Loss: 30.145; Val_Loss: 838.784   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 4.974\n",
      "(Epoch 1445 / 10000) Train_Loss: 31.746; Val_Loss: 842.190   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.385; Val_NMI: 5.308\n",
      "(Epoch 1446 / 10000) Train_Loss: 31.982; Val_Loss: 846.624   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.353; Val_NMI: 4.844\n",
      "(Epoch 1447 / 10000) Train_Loss: 31.201; Val_Loss: 865.399   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.329; Val_NMI: 4.901\n",
      "(Epoch 1448 / 10000) Train_Loss: 31.717; Val_Loss: 869.357   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.355; Val_NMI: 4.803\n",
      "(Epoch 1449 / 10000) Train_Loss: 29.407; Val_Loss: 816.758   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.418; Val_NMI: 5.462\n",
      "(Epoch 1450 / 10000) Train_Loss: 30.697; Val_Loss: 863.568   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.376; Val_NMI: 5.473\n",
      "(Epoch 1451 / 10000) Train_Loss: 31.655; Val_Loss: 864.576   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.410; Val_NMI: 5.568\n",
      "(Epoch 1452 / 10000) Train_Loss: 31.708; Val_Loss: 869.139   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.419; Val_NMI: 4.867\n",
      "(Epoch 1453 / 10000) Train_Loss: 31.808; Val_Loss: 851.908   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.409; Val_NMI: 4.675\n",
      "(Epoch 1454 / 10000) Train_Loss: 34.308; Val_Loss: 831.955   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 4.952\n",
      "(Epoch 1455 / 10000) Train_Loss: 34.822; Val_Loss: 841.584   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.403; Val_NMI: 4.746\n",
      "(Epoch 1456 / 10000) Train_Loss: 32.856; Val_Loss: 823.950   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 5.208\n",
      "(Epoch 1457 / 10000) Train_Loss: 33.720; Val_Loss: 838.243   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.921\n",
      "(Epoch 1458 / 10000) Train_Loss: 32.106; Val_Loss: 843.956   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 4.386\n",
      "(Epoch 1459 / 10000) Train_Loss: 30.168; Val_Loss: 809.314   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.394; Val_NMI: 5.027\n",
      "(Epoch 1460 / 10000) Train_Loss: 28.959; Val_Loss: 790.626   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.361; Val_NMI: 5.085\n",
      "(Epoch 1461 / 10000) Train_Loss: 29.825; Val_Loss: 814.238   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 5.294\n",
      "(Epoch 1462 / 10000) Train_Loss: 29.314; Val_Loss: 801.923   Train_ACC: 14.992; Val_ACC: 22.222   Train_NMI: 0.404; Val_NMI: 5.801\n",
      "(Epoch 1463 / 10000) Train_Loss: 29.265; Val_Loss: 797.663   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.334; Val_NMI: 4.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1464 / 10000) Train_Loss: 29.609; Val_Loss: 813.734   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.352; Val_NMI: 5.061\n",
      "(Epoch 1465 / 10000) Train_Loss: 29.817; Val_Loss: 833.707   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.334; Val_NMI: 5.138\n",
      "(Epoch 1466 / 10000) Train_Loss: 29.485; Val_Loss: 813.426   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.395; Val_NMI: 4.531\n",
      "(Epoch 1467 / 10000) Train_Loss: 29.063; Val_Loss: 814.682   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.346; Val_NMI: 4.522\n",
      "(Epoch 1468 / 10000) Train_Loss: 30.193; Val_Loss: 810.089   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 5.270\n",
      "(Epoch 1469 / 10000) Train_Loss: 29.782; Val_Loss: 786.067   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 4.871\n",
      "(Epoch 1470 / 10000) Train_Loss: 32.256; Val_Loss: 812.006   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.407; Val_NMI: 5.176\n",
      "(Epoch 1471 / 10000) Train_Loss: 30.306; Val_Loss: 824.312   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 4.749\n",
      "(Epoch 1472 / 10000) Train_Loss: 31.782; Val_Loss: 845.905   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.310; Val_NMI: 6.038\n",
      "(Epoch 1473 / 10000) Train_Loss: 31.716; Val_Loss: 842.165   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.348; Val_NMI: 5.493\n",
      "(Epoch 1474 / 10000) Train_Loss: 30.016; Val_Loss: 794.011   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.377\n",
      "(Epoch 1475 / 10000) Train_Loss: 28.865; Val_Loss: 785.422   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.365; Val_NMI: 5.333\n",
      "(Epoch 1476 / 10000) Train_Loss: 29.880; Val_Loss: 825.683   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.344; Val_NMI: 4.805\n",
      "(Epoch 1477 / 10000) Train_Loss: 30.151; Val_Loss: 819.867   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.383; Val_NMI: 5.445\n",
      "(Epoch 1478 / 10000) Train_Loss: 31.221; Val_Loss: 805.958   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.351; Val_NMI: 5.546\n",
      "(Epoch 1479 / 10000) Train_Loss: 29.735; Val_Loss: 845.737   Train_ACC: 14.662; Val_ACC: 22.222   Train_NMI: 0.341; Val_NMI: 5.743\n",
      "(Epoch 1480 / 10000) Train_Loss: 29.510; Val_Loss: 793.461   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 4.926\n",
      "(Epoch 1481 / 10000) Train_Loss: 30.731; Val_Loss: 844.124   Train_ACC: 14.621; Val_ACC: 21.481   Train_NMI: 0.363; Val_NMI: 6.147\n",
      "(Epoch 1482 / 10000) Train_Loss: 29.511; Val_Loss: 825.678   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.332; Val_NMI: 5.734\n",
      "(Epoch 1483 / 10000) Train_Loss: 30.197; Val_Loss: 781.618   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 4.866\n",
      "(Epoch 1484 / 10000) Train_Loss: 31.347; Val_Loss: 817.499   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 5.785\n",
      "(Epoch 1485 / 10000) Train_Loss: 38.863; Val_Loss: 812.251   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.305; Val_NMI: 5.555\n",
      "(Epoch 1486 / 10000) Train_Loss: 35.793; Val_Loss: 767.635   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 5.042\n",
      "(Epoch 1487 / 10000) Train_Loss: 33.345; Val_Loss: 822.073   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.429; Val_NMI: 5.126\n",
      "(Epoch 1488 / 10000) Train_Loss: 30.799; Val_Loss: 816.140   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.398; Val_NMI: 5.397\n",
      "(Epoch 1489 / 10000) Train_Loss: 33.486; Val_Loss: 809.883   Train_ACC: 14.539; Val_ACC: 20.741   Train_NMI: 0.364; Val_NMI: 4.990\n",
      "(Epoch 1490 / 10000) Train_Loss: 32.722; Val_Loss: 815.911   Train_ACC: 14.703; Val_ACC: 21.852   Train_NMI: 0.368; Val_NMI: 6.018\n",
      "(Epoch 1491 / 10000) Train_Loss: 30.585; Val_Loss: 797.767   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.340; Val_NMI: 5.772\n",
      "(Epoch 1492 / 10000) Train_Loss: 29.966; Val_Loss: 856.608   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 5.692\n",
      "(Epoch 1493 / 10000) Train_Loss: 30.720; Val_Loss: 807.609   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.435; Val_NMI: 5.926\n",
      "(Epoch 1494 / 10000) Train_Loss: 29.628; Val_Loss: 810.150   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.425; Val_NMI: 5.895\n",
      "(Epoch 1495 / 10000) Train_Loss: 28.568; Val_Loss: 872.462   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 5.445\n",
      "(Epoch 1496 / 10000) Train_Loss: 29.042; Val_Loss: 846.348   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.418; Val_NMI: 5.726\n",
      "(Epoch 1497 / 10000) Train_Loss: 30.404; Val_Loss: 841.649   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.437; Val_NMI: 5.355\n",
      "(Epoch 1498 / 10000) Train_Loss: 29.357; Val_Loss: 830.763   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.352; Val_NMI: 5.700\n",
      "(Epoch 1499 / 10000) Train_Loss: 29.161; Val_Loss: 815.719   Train_ACC: 15.033; Val_ACC: 21.481   Train_NMI: 0.438; Val_NMI: 5.614\n",
      "(Epoch 1500 / 10000) Train_Loss: 30.710; Val_Loss: 858.281   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.306\n",
      "(Epoch 1501 / 10000) Train_Loss: 31.390; Val_Loss: 808.957   Train_ACC: 14.621; Val_ACC: 21.481   Train_NMI: 0.345; Val_NMI: 5.725\n",
      "(Epoch 1502 / 10000) Train_Loss: 30.015; Val_Loss: 834.656   Train_ACC: 14.992; Val_ACC: 22.593   Train_NMI: 0.436; Val_NMI: 6.391\n",
      "(Epoch 1503 / 10000) Train_Loss: 30.262; Val_Loss: 834.926   Train_ACC: 14.703; Val_ACC: 21.852   Train_NMI: 0.380; Val_NMI: 5.748\n",
      "(Epoch 1504 / 10000) Train_Loss: 30.158; Val_Loss: 860.269   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.442; Val_NMI: 5.764\n",
      "(Epoch 1505 / 10000) Train_Loss: 29.435; Val_Loss: 828.969   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.396; Val_NMI: 4.943\n",
      "(Epoch 1506 / 10000) Train_Loss: 30.307; Val_Loss: 877.679   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.409; Val_NMI: 5.036\n",
      "(Epoch 1507 / 10000) Train_Loss: 29.650; Val_Loss: 807.045   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.438; Val_NMI: 5.384\n",
      "(Epoch 1508 / 10000) Train_Loss: 30.365; Val_Loss: 811.570   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.403; Val_NMI: 5.230\n",
      "(Epoch 1509 / 10000) Train_Loss: 31.600; Val_Loss: 832.006   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.455; Val_NMI: 5.576\n",
      "(Epoch 1510 / 10000) Train_Loss: 29.645; Val_Loss: 819.562   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.417; Val_NMI: 5.265\n",
      "(Epoch 1511 / 10000) Train_Loss: 30.119; Val_Loss: 797.397   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.365; Val_NMI: 6.083\n",
      "(Epoch 1512 / 10000) Train_Loss: 29.588; Val_Loss: 810.807   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.456; Val_NMI: 5.116\n",
      "(Epoch 1513 / 10000) Train_Loss: 29.081; Val_Loss: 828.315   Train_ACC: 14.868; Val_ACC: 21.852   Train_NMI: 0.425; Val_NMI: 5.024\n",
      "(Epoch 1514 / 10000) Train_Loss: 29.457; Val_Loss: 826.474   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.490; Val_NMI: 4.887\n",
      "(Epoch 1515 / 10000) Train_Loss: 29.486; Val_Loss: 816.229   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.387; Val_NMI: 5.104\n",
      "(Epoch 1516 / 10000) Train_Loss: 28.879; Val_Loss: 821.623   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.359; Val_NMI: 5.181\n",
      "(Epoch 1517 / 10000) Train_Loss: 32.061; Val_Loss: 824.941   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.477; Val_NMI: 4.723\n",
      "(Epoch 1518 / 10000) Train_Loss: 30.638; Val_Loss: 841.884   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.418; Val_NMI: 5.548\n",
      "(Epoch 1519 / 10000) Train_Loss: 33.046; Val_Loss: 801.953   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.349; Val_NMI: 4.940\n",
      "(Epoch 1520 / 10000) Train_Loss: 34.621; Val_Loss: 803.453   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 4.978\n",
      "(Epoch 1521 / 10000) Train_Loss: 33.231; Val_Loss: 818.103   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.415; Val_NMI: 4.871\n",
      "(Epoch 1522 / 10000) Train_Loss: 30.412; Val_Loss: 835.397   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.406; Val_NMI: 5.407\n",
      "(Epoch 1523 / 10000) Train_Loss: 29.506; Val_Loss: 813.111   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.388; Val_NMI: 5.144\n",
      "(Epoch 1524 / 10000) Train_Loss: 32.389; Val_Loss: 876.925   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.345; Val_NMI: 4.989\n",
      "(Epoch 1525 / 10000) Train_Loss: 38.425; Val_Loss: 848.061   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.396; Val_NMI: 5.053\n",
      "(Epoch 1526 / 10000) Train_Loss: 34.847; Val_Loss: 843.801   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.409; Val_NMI: 4.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1527 / 10000) Train_Loss: 31.578; Val_Loss: 805.087   Train_ACC: 14.662; Val_ACC: 21.481   Train_NMI: 0.392; Val_NMI: 5.640\n",
      "(Epoch 1528 / 10000) Train_Loss: 30.098; Val_Loss: 783.914   Train_ACC: 14.539; Val_ACC: 21.481   Train_NMI: 0.372; Val_NMI: 5.497\n",
      "(Epoch 1529 / 10000) Train_Loss: 30.148; Val_Loss: 862.260   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 5.470\n",
      "(Epoch 1530 / 10000) Train_Loss: 29.427; Val_Loss: 862.296   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.381; Val_NMI: 5.491\n",
      "(Epoch 1531 / 10000) Train_Loss: 31.067; Val_Loss: 863.159   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 4.760\n",
      "(Epoch 1532 / 10000) Train_Loss: 30.051; Val_Loss: 812.468   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.209\n",
      "(Epoch 1533 / 10000) Train_Loss: 30.394; Val_Loss: 796.846   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.397; Val_NMI: 5.114\n",
      "(Epoch 1534 / 10000) Train_Loss: 30.670; Val_Loss: 819.528   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 4.848\n",
      "(Epoch 1535 / 10000) Train_Loss: 30.354; Val_Loss: 786.096   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 4.823\n",
      "(Epoch 1536 / 10000) Train_Loss: 29.854; Val_Loss: 864.769   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 4.836\n",
      "(Epoch 1537 / 10000) Train_Loss: 29.976; Val_Loss: 863.308   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.427; Val_NMI: 5.122\n",
      "(Epoch 1538 / 10000) Train_Loss: 33.084; Val_Loss: 855.596   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.396; Val_NMI: 5.063\n",
      "(Epoch 1539 / 10000) Train_Loss: 33.675; Val_Loss: 826.825   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.482; Val_NMI: 5.113\n",
      "(Epoch 1540 / 10000) Train_Loss: 38.782; Val_Loss: 846.193   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 5.463\n",
      "(Epoch 1541 / 10000) Train_Loss: 36.455; Val_Loss: 799.406   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.362; Val_NMI: 5.375\n",
      "(Epoch 1542 / 10000) Train_Loss: 32.222; Val_Loss: 873.379   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 4.845\n",
      "(Epoch 1543 / 10000) Train_Loss: 32.459; Val_Loss: 801.901   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.430; Val_NMI: 5.037\n",
      "(Epoch 1544 / 10000) Train_Loss: 30.027; Val_Loss: 820.029   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 4.690\n",
      "(Epoch 1545 / 10000) Train_Loss: 29.018; Val_Loss: 837.571   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.403; Val_NMI: 5.522\n",
      "(Epoch 1546 / 10000) Train_Loss: 30.743; Val_Loss: 856.249   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 5.319\n",
      "(Epoch 1547 / 10000) Train_Loss: 32.555; Val_Loss: 821.519   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.473; Val_NMI: 5.302\n",
      "(Epoch 1548 / 10000) Train_Loss: 30.754; Val_Loss: 784.800   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 5.205\n",
      "(Epoch 1549 / 10000) Train_Loss: 28.954; Val_Loss: 835.160   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.315; Val_NMI: 5.797\n",
      "(Epoch 1550 / 10000) Train_Loss: 27.882; Val_Loss: 843.391   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.374; Val_NMI: 5.430\n",
      "(Epoch 1551 / 10000) Train_Loss: 28.658; Val_Loss: 876.167   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.339; Val_NMI: 5.867\n",
      "(Epoch 1552 / 10000) Train_Loss: 29.940; Val_Loss: 802.693   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.338; Val_NMI: 5.602\n",
      "(Epoch 1553 / 10000) Train_Loss: 28.521; Val_Loss: 850.216   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 4.964\n",
      "(Epoch 1554 / 10000) Train_Loss: 27.905; Val_Loss: 843.890   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.065\n",
      "(Epoch 1555 / 10000) Train_Loss: 28.777; Val_Loss: 821.815   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.307; Val_NMI: 5.510\n",
      "(Epoch 1556 / 10000) Train_Loss: 28.931; Val_Loss: 897.324   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.328; Val_NMI: 5.571\n",
      "(Epoch 1557 / 10000) Train_Loss: 29.777; Val_Loss: 801.793   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 5.069\n",
      "(Epoch 1558 / 10000) Train_Loss: 29.323; Val_Loss: 827.030   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 4.995\n",
      "(Epoch 1559 / 10000) Train_Loss: 29.577; Val_Loss: 849.775   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 5.432\n",
      "(Epoch 1560 / 10000) Train_Loss: 29.447; Val_Loss: 844.967   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 5.299\n",
      "(Epoch 1561 / 10000) Train_Loss: 30.972; Val_Loss: 848.253   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.325; Val_NMI: 5.140\n",
      "(Epoch 1562 / 10000) Train_Loss: 30.123; Val_Loss: 883.695   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.356; Val_NMI: 5.136\n",
      "(Epoch 1563 / 10000) Train_Loss: 29.315; Val_Loss: 822.644   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.819\n",
      "(Epoch 1564 / 10000) Train_Loss: 29.919; Val_Loss: 878.320   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.321; Val_NMI: 5.101\n",
      "(Epoch 1565 / 10000) Train_Loss: 30.172; Val_Loss: 871.953   Train_ACC: 14.498; Val_ACC: 20.000   Train_NMI: 0.301; Val_NMI: 5.855\n",
      "(Epoch 1566 / 10000) Train_Loss: 28.927; Val_Loss: 802.913   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.379; Val_NMI: 5.200\n",
      "(Epoch 1567 / 10000) Train_Loss: 30.100; Val_Loss: 789.871   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.353; Val_NMI: 5.506\n",
      "(Epoch 1568 / 10000) Train_Loss: 29.680; Val_Loss: 849.932   Train_ACC: 14.786; Val_ACC: 21.481   Train_NMI: 0.325; Val_NMI: 6.313\n",
      "(Epoch 1569 / 10000) Train_Loss: 29.921; Val_Loss: 859.224   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.359; Val_NMI: 5.610\n",
      "(Epoch 1570 / 10000) Train_Loss: 28.539; Val_Loss: 839.839   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.306; Val_NMI: 5.657\n",
      "(Epoch 1571 / 10000) Train_Loss: 29.386; Val_Loss: 825.441   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 5.188\n",
      "(Epoch 1572 / 10000) Train_Loss: 28.861; Val_Loss: 829.808   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.381; Val_NMI: 5.433\n",
      "(Epoch 1573 / 10000) Train_Loss: 30.156; Val_Loss: 858.387   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 5.284\n",
      "(Epoch 1574 / 10000) Train_Loss: 30.848; Val_Loss: 776.633   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 5.445\n",
      "(Epoch 1575 / 10000) Train_Loss: 29.783; Val_Loss: 841.568   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 5.130\n",
      "(Epoch 1576 / 10000) Train_Loss: 33.531; Val_Loss: 803.664   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 4.966\n",
      "(Epoch 1577 / 10000) Train_Loss: 33.987; Val_Loss: 845.051   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.325; Val_NMI: 5.122\n",
      "(Epoch 1578 / 10000) Train_Loss: 32.486; Val_Loss: 852.680   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.548\n",
      "(Epoch 1579 / 10000) Train_Loss: 30.870; Val_Loss: 814.080   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.443; Val_NMI: 5.534\n",
      "(Epoch 1580 / 10000) Train_Loss: 31.855; Val_Loss: 835.470   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.376; Val_NMI: 4.916\n",
      "(Epoch 1581 / 10000) Train_Loss: 33.543; Val_Loss: 834.824   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.374; Val_NMI: 5.181\n",
      "(Epoch 1582 / 10000) Train_Loss: 32.571; Val_Loss: 818.548   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.344; Val_NMI: 4.875\n",
      "(Epoch 1583 / 10000) Train_Loss: 30.804; Val_Loss: 814.606   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.121\n",
      "(Epoch 1584 / 10000) Train_Loss: 31.855; Val_Loss: 829.144   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 4.781\n",
      "(Epoch 1585 / 10000) Train_Loss: 31.466; Val_Loss: 824.231   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.343; Val_NMI: 5.021\n",
      "(Epoch 1586 / 10000) Train_Loss: 31.210; Val_Loss: 847.440   Train_ACC: 14.580; Val_ACC: 21.481   Train_NMI: 0.356; Val_NMI: 4.970\n",
      "(Epoch 1587 / 10000) Train_Loss: 30.950; Val_Loss: 797.195   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 5.028\n",
      "(Epoch 1588 / 10000) Train_Loss: 30.137; Val_Loss: 809.439   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.960\n",
      "(Epoch 1589 / 10000) Train_Loss: 29.270; Val_Loss: 835.388   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 5.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1590 / 10000) Train_Loss: 28.716; Val_Loss: 817.648   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.390; Val_NMI: 5.730\n",
      "(Epoch 1591 / 10000) Train_Loss: 29.186; Val_Loss: 797.805   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.947\n",
      "(Epoch 1592 / 10000) Train_Loss: 30.341; Val_Loss: 805.631   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 5.539\n",
      "(Epoch 1593 / 10000) Train_Loss: 30.283; Val_Loss: 832.944   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 4.988\n",
      "(Epoch 1594 / 10000) Train_Loss: 29.652; Val_Loss: 855.596   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.894\n",
      "(Epoch 1595 / 10000) Train_Loss: 29.553; Val_Loss: 826.988   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.402; Val_NMI: 5.576\n",
      "(Epoch 1596 / 10000) Train_Loss: 28.686; Val_Loss: 819.373   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 5.106\n",
      "(Epoch 1597 / 10000) Train_Loss: 29.469; Val_Loss: 851.325   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.387; Val_NMI: 5.332\n",
      "(Epoch 1598 / 10000) Train_Loss: 30.178; Val_Loss: 827.918   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.464\n",
      "(Epoch 1599 / 10000) Train_Loss: 29.888; Val_Loss: 857.055   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 5.215\n",
      "(Epoch 1600 / 10000) Train_Loss: 31.481; Val_Loss: 817.849   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.358; Val_NMI: 4.839\n",
      "(Epoch 1601 / 10000) Train_Loss: 33.014; Val_Loss: 875.565   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.775\n",
      "(Epoch 1602 / 10000) Train_Loss: 31.511; Val_Loss: 834.921   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.337; Val_NMI: 5.316\n",
      "(Epoch 1603 / 10000) Train_Loss: 31.010; Val_Loss: 852.117   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.426; Val_NMI: 5.153\n",
      "(Epoch 1604 / 10000) Train_Loss: 30.567; Val_Loss: 812.549   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.433; Val_NMI: 5.198\n",
      "(Epoch 1605 / 10000) Train_Loss: 31.646; Val_Loss: 836.623   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 5.413\n",
      "(Epoch 1606 / 10000) Train_Loss: 31.088; Val_Loss: 818.182   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.421; Val_NMI: 5.103\n",
      "(Epoch 1607 / 10000) Train_Loss: 29.463; Val_Loss: 845.332   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.441; Val_NMI: 5.471\n",
      "(Epoch 1608 / 10000) Train_Loss: 28.878; Val_Loss: 788.120   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 5.223\n",
      "(Epoch 1609 / 10000) Train_Loss: 29.792; Val_Loss: 834.270   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 5.030\n",
      "(Epoch 1610 / 10000) Train_Loss: 29.305; Val_Loss: 857.218   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 5.141\n",
      "(Epoch 1611 / 10000) Train_Loss: 30.045; Val_Loss: 837.630   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.401; Val_NMI: 5.072\n",
      "(Epoch 1612 / 10000) Train_Loss: 29.032; Val_Loss: 825.932   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.370; Val_NMI: 5.453\n",
      "(Epoch 1613 / 10000) Train_Loss: 28.444; Val_Loss: 830.148   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 6.034\n",
      "(Epoch 1614 / 10000) Train_Loss: 30.418; Val_Loss: 838.384   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.449; Val_NMI: 4.957\n",
      "(Epoch 1615 / 10000) Train_Loss: 29.565; Val_Loss: 827.968   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.399; Val_NMI: 4.933\n",
      "(Epoch 1616 / 10000) Train_Loss: 30.228; Val_Loss: 845.062   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.431\n",
      "(Epoch 1617 / 10000) Train_Loss: 28.932; Val_Loss: 845.430   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.360; Val_NMI: 5.310\n",
      "(Epoch 1618 / 10000) Train_Loss: 29.913; Val_Loss: 857.627   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.337; Val_NMI: 5.452\n",
      "(Epoch 1619 / 10000) Train_Loss: 30.216; Val_Loss: 821.125   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 5.141\n",
      "(Epoch 1620 / 10000) Train_Loss: 30.157; Val_Loss: 809.736   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 4.774\n",
      "(Epoch 1621 / 10000) Train_Loss: 30.867; Val_Loss: 846.138   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.333; Val_NMI: 5.270\n",
      "(Epoch 1622 / 10000) Train_Loss: 29.834; Val_Loss: 841.208   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.937\n",
      "(Epoch 1623 / 10000) Train_Loss: 30.759; Val_Loss: 850.939   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 4.863\n",
      "(Epoch 1624 / 10000) Train_Loss: 30.041; Val_Loss: 824.098   Train_ACC: 14.374; Val_ACC: 20.000   Train_NMI: 0.279; Val_NMI: 5.562\n",
      "(Epoch 1625 / 10000) Train_Loss: 29.999; Val_Loss: 837.659   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.291; Val_NMI: 4.638\n",
      "(Epoch 1626 / 10000) Train_Loss: 29.809; Val_Loss: 823.894   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 5.201\n",
      "(Epoch 1627 / 10000) Train_Loss: 29.748; Val_Loss: 840.123   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 5.198\n",
      "(Epoch 1628 / 10000) Train_Loss: 32.914; Val_Loss: 807.447   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.361; Val_NMI: 5.025\n",
      "(Epoch 1629 / 10000) Train_Loss: 31.473; Val_Loss: 837.530   Train_ACC: 15.404; Val_ACC: 19.630   Train_NMI: 0.493; Val_NMI: 4.706\n",
      "(Epoch 1630 / 10000) Train_Loss: 29.570; Val_Loss: 860.271   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.121\n",
      "(Epoch 1631 / 10000) Train_Loss: 30.643; Val_Loss: 807.872   Train_ACC: 14.951; Val_ACC: 21.481   Train_NMI: 0.378; Val_NMI: 5.236\n",
      "(Epoch 1632 / 10000) Train_Loss: 32.020; Val_Loss: 853.695   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.331; Val_NMI: 4.900\n",
      "(Epoch 1633 / 10000) Train_Loss: 31.392; Val_Loss: 898.055   Train_ACC: 15.074; Val_ACC: 20.741   Train_NMI: 0.432; Val_NMI: 4.809\n",
      "(Epoch 1634 / 10000) Train_Loss: 31.784; Val_Loss: 843.593   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.384; Val_NMI: 5.153\n",
      "(Epoch 1635 / 10000) Train_Loss: 29.151; Val_Loss: 834.736   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.387; Val_NMI: 4.960\n",
      "(Epoch 1636 / 10000) Train_Loss: 28.359; Val_Loss: 870.979   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 4.840\n",
      "(Epoch 1637 / 10000) Train_Loss: 30.366; Val_Loss: 853.958   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.445; Val_NMI: 4.773\n",
      "(Epoch 1638 / 10000) Train_Loss: 31.147; Val_Loss: 852.639   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.433; Val_NMI: 5.102\n",
      "(Epoch 1639 / 10000) Train_Loss: 31.735; Val_Loss: 861.283   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.823\n",
      "(Epoch 1640 / 10000) Train_Loss: 35.651; Val_Loss: 857.793   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.451; Val_NMI: 5.209\n",
      "(Epoch 1641 / 10000) Train_Loss: 55.017; Val_Loss: 807.357   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 4.583\n",
      "(Epoch 1642 / 10000) Train_Loss: 44.737; Val_Loss: 822.165   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.429; Val_NMI: 5.893\n",
      "(Epoch 1643 / 10000) Train_Loss: 34.230; Val_Loss: 846.432   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 4.771\n",
      "(Epoch 1644 / 10000) Train_Loss: 30.341; Val_Loss: 854.519   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.370; Val_NMI: 5.442\n",
      "(Epoch 1645 / 10000) Train_Loss: 28.996; Val_Loss: 871.644   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 4.510\n",
      "(Epoch 1646 / 10000) Train_Loss: 28.670; Val_Loss: 816.637   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.320; Val_NMI: 5.389\n",
      "(Epoch 1647 / 10000) Train_Loss: 29.745; Val_Loss: 876.277   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 4.602\n",
      "(Epoch 1648 / 10000) Train_Loss: 30.549; Val_Loss: 921.396   Train_ACC: 14.415; Val_ACC: 20.000   Train_NMI: 0.312; Val_NMI: 4.546\n",
      "(Epoch 1649 / 10000) Train_Loss: 28.642; Val_Loss: 844.573   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.373; Val_NMI: 5.452\n",
      "(Epoch 1650 / 10000) Train_Loss: 27.931; Val_Loss: 843.328   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 4.949\n",
      "(Epoch 1651 / 10000) Train_Loss: 28.367; Val_Loss: 829.606   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.588\n",
      "(Epoch 1652 / 10000) Train_Loss: 28.452; Val_Loss: 843.732   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 4.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1653 / 10000) Train_Loss: 27.901; Val_Loss: 836.960   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.399; Val_NMI: 4.924\n",
      "(Epoch 1654 / 10000) Train_Loss: 27.489; Val_Loss: 845.677   Train_ACC: 14.498; Val_ACC: 20.000   Train_NMI: 0.314; Val_NMI: 5.043\n",
      "(Epoch 1655 / 10000) Train_Loss: 27.503; Val_Loss: 859.345   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 4.723\n",
      "(Epoch 1656 / 10000) Train_Loss: 28.872; Val_Loss: 821.958   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.353; Val_NMI: 4.895\n",
      "(Epoch 1657 / 10000) Train_Loss: 28.511; Val_Loss: 825.076   Train_ACC: 14.498; Val_ACC: 20.741   Train_NMI: 0.311; Val_NMI: 5.071\n",
      "(Epoch 1658 / 10000) Train_Loss: 27.747; Val_Loss: 849.733   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.759\n",
      "(Epoch 1659 / 10000) Train_Loss: 28.121; Val_Loss: 853.165   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 5.395\n",
      "(Epoch 1660 / 10000) Train_Loss: 28.489; Val_Loss: 852.931   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.179\n",
      "(Epoch 1661 / 10000) Train_Loss: 27.866; Val_Loss: 810.358   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.359; Val_NMI: 4.835\n",
      "(Epoch 1662 / 10000) Train_Loss: 28.943; Val_Loss: 838.333   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 4.782\n",
      "(Epoch 1663 / 10000) Train_Loss: 30.048; Val_Loss: 852.200   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.407; Val_NMI: 4.773\n",
      "(Epoch 1664 / 10000) Train_Loss: 27.898; Val_Loss: 879.542   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.747\n",
      "(Epoch 1665 / 10000) Train_Loss: 28.848; Val_Loss: 824.198   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.643\n",
      "(Epoch 1666 / 10000) Train_Loss: 30.409; Val_Loss: 851.382   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.844\n",
      "(Epoch 1667 / 10000) Train_Loss: 30.888; Val_Loss: 846.235   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.920\n",
      "(Epoch 1668 / 10000) Train_Loss: 29.389; Val_Loss: 816.470   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.302; Val_NMI: 5.440\n",
      "(Epoch 1669 / 10000) Train_Loss: 28.847; Val_Loss: 826.563   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 5.189\n",
      "(Epoch 1670 / 10000) Train_Loss: 29.111; Val_Loss: 844.939   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.317; Val_NMI: 4.953\n",
      "(Epoch 1671 / 10000) Train_Loss: 29.988; Val_Loss: 838.004   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.389; Val_NMI: 5.511\n",
      "(Epoch 1672 / 10000) Train_Loss: 30.417; Val_Loss: 846.345   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.951\n",
      "(Epoch 1673 / 10000) Train_Loss: 28.811; Val_Loss: 822.777   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.401; Val_NMI: 5.206\n",
      "(Epoch 1674 / 10000) Train_Loss: 28.477; Val_Loss: 843.006   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.390; Val_NMI: 5.280\n",
      "(Epoch 1675 / 10000) Train_Loss: 29.618; Val_Loss: 873.693   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.548\n",
      "(Epoch 1676 / 10000) Train_Loss: 29.475; Val_Loss: 905.012   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.639\n",
      "(Epoch 1677 / 10000) Train_Loss: 29.906; Val_Loss: 858.973   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.922\n",
      "(Epoch 1678 / 10000) Train_Loss: 29.700; Val_Loss: 846.864   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.421; Val_NMI: 4.685\n",
      "(Epoch 1679 / 10000) Train_Loss: 36.084; Val_Loss: 850.843   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.414; Val_NMI: 5.209\n",
      "(Epoch 1680 / 10000) Train_Loss: 34.754; Val_Loss: 826.456   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.370; Val_NMI: 5.049\n",
      "(Epoch 1681 / 10000) Train_Loss: 31.483; Val_Loss: 881.065   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 4.404\n",
      "(Epoch 1682 / 10000) Train_Loss: 30.303; Val_Loss: 876.751   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.414; Val_NMI: 5.096\n",
      "(Epoch 1683 / 10000) Train_Loss: 29.188; Val_Loss: 860.852   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.400; Val_NMI: 5.037\n",
      "(Epoch 1684 / 10000) Train_Loss: 28.898; Val_Loss: 846.482   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.379; Val_NMI: 4.875\n",
      "(Epoch 1685 / 10000) Train_Loss: 28.921; Val_Loss: 849.823   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 4.828\n",
      "(Epoch 1686 / 10000) Train_Loss: 29.215; Val_Loss: 811.351   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.322; Val_NMI: 4.925\n",
      "(Epoch 1687 / 10000) Train_Loss: 30.254; Val_Loss: 854.630   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.383; Val_NMI: 5.001\n",
      "(Epoch 1688 / 10000) Train_Loss: 30.272; Val_Loss: 853.714   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 5.312\n",
      "(Epoch 1689 / 10000) Train_Loss: 28.942; Val_Loss: 817.391   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.385; Val_NMI: 5.708\n",
      "(Epoch 1690 / 10000) Train_Loss: 29.181; Val_Loss: 835.465   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.354; Val_NMI: 5.115\n",
      "(Epoch 1691 / 10000) Train_Loss: 29.629; Val_Loss: 891.532   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 4.700\n",
      "(Epoch 1692 / 10000) Train_Loss: 33.011; Val_Loss: 880.854   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.382; Val_NMI: 4.690\n",
      "(Epoch 1693 / 10000) Train_Loss: 31.851; Val_Loss: 851.694   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.359; Val_NMI: 4.852\n",
      "(Epoch 1694 / 10000) Train_Loss: 29.412; Val_Loss: 855.499   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.345; Val_NMI: 4.756\n",
      "(Epoch 1695 / 10000) Train_Loss: 29.613; Val_Loss: 802.291   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.393; Val_NMI: 5.479\n",
      "(Epoch 1696 / 10000) Train_Loss: 31.722; Val_Loss: 832.564   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.305; Val_NMI: 5.195\n",
      "(Epoch 1697 / 10000) Train_Loss: 31.417; Val_Loss: 844.790   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.493\n",
      "(Epoch 1698 / 10000) Train_Loss: 30.173; Val_Loss: 860.047   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.367; Val_NMI: 5.253\n",
      "(Epoch 1699 / 10000) Train_Loss: 31.417; Val_Loss: 919.102   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 5.773\n",
      "(Epoch 1700 / 10000) Train_Loss: 29.668; Val_Loss: 828.056   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.376; Val_NMI: 5.197\n",
      "(Epoch 1701 / 10000) Train_Loss: 29.375; Val_Loss: 831.544   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 5.495\n",
      "(Epoch 1702 / 10000) Train_Loss: 29.423; Val_Loss: 807.175   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.397; Val_NMI: 5.322\n",
      "(Epoch 1703 / 10000) Train_Loss: 29.456; Val_Loss: 861.655   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.412; Val_NMI: 4.973\n",
      "(Epoch 1704 / 10000) Train_Loss: 29.735; Val_Loss: 850.011   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 5.198\n",
      "(Epoch 1705 / 10000) Train_Loss: 29.475; Val_Loss: 907.384   Train_ACC: 14.456; Val_ACC: 20.370   Train_NMI: 0.340; Val_NMI: 5.604\n",
      "(Epoch 1706 / 10000) Train_Loss: 28.556; Val_Loss: 884.158   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.361; Val_NMI: 4.810\n",
      "(Epoch 1707 / 10000) Train_Loss: 30.426; Val_Loss: 833.417   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.411; Val_NMI: 5.743\n",
      "(Epoch 1708 / 10000) Train_Loss: 28.968; Val_Loss: 859.173   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.370; Val_NMI: 5.249\n",
      "(Epoch 1709 / 10000) Train_Loss: 29.904; Val_Loss: 806.899   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.344; Val_NMI: 5.582\n",
      "(Epoch 1710 / 10000) Train_Loss: 28.868; Val_Loss: 835.352   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 4.966\n",
      "(Epoch 1711 / 10000) Train_Loss: 30.034; Val_Loss: 831.885   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 4.925\n",
      "(Epoch 1712 / 10000) Train_Loss: 29.776; Val_Loss: 828.097   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.390; Val_NMI: 4.970\n",
      "(Epoch 1713 / 10000) Train_Loss: 30.842; Val_Loss: 839.034   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.427; Val_NMI: 5.218\n",
      "(Epoch 1714 / 10000) Train_Loss: 29.924; Val_Loss: 862.987   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 5.238\n",
      "(Epoch 1715 / 10000) Train_Loss: 29.587; Val_Loss: 845.767   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 5.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1716 / 10000) Train_Loss: 28.945; Val_Loss: 893.274   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 4.601\n",
      "(Epoch 1717 / 10000) Train_Loss: 28.628; Val_Loss: 863.886   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.397; Val_NMI: 4.722\n",
      "(Epoch 1718 / 10000) Train_Loss: 29.285; Val_Loss: 822.921   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 4.819\n",
      "(Epoch 1719 / 10000) Train_Loss: 29.903; Val_Loss: 890.166   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.460\n",
      "(Epoch 1720 / 10000) Train_Loss: 29.876; Val_Loss: 843.686   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 5.305\n",
      "(Epoch 1721 / 10000) Train_Loss: 30.510; Val_Loss: 816.928   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.329; Val_NMI: 5.463\n",
      "(Epoch 1722 / 10000) Train_Loss: 29.752; Val_Loss: 889.272   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.355; Val_NMI: 5.354\n",
      "(Epoch 1723 / 10000) Train_Loss: 28.850; Val_Loss: 823.604   Train_ACC: 14.539; Val_ACC: 20.741   Train_NMI: 0.303; Val_NMI: 5.107\n",
      "(Epoch 1724 / 10000) Train_Loss: 28.801; Val_Loss: 875.140   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.431; Val_NMI: 5.113\n",
      "(Epoch 1725 / 10000) Train_Loss: 29.235; Val_Loss: 853.929   Train_ACC: 14.662; Val_ACC: 21.852   Train_NMI: 0.360; Val_NMI: 5.664\n",
      "(Epoch 1726 / 10000) Train_Loss: 29.178; Val_Loss: 832.991   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.396; Val_NMI: 5.189\n",
      "(Epoch 1727 / 10000) Train_Loss: 27.987; Val_Loss: 849.136   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.343; Val_NMI: 5.153\n",
      "(Epoch 1728 / 10000) Train_Loss: 29.419; Val_Loss: 877.377   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.373; Val_NMI: 5.735\n",
      "(Epoch 1729 / 10000) Train_Loss: 29.294; Val_Loss: 896.066   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.472; Val_NMI: 5.712\n",
      "(Epoch 1730 / 10000) Train_Loss: 28.919; Val_Loss: 814.207   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 5.113\n",
      "(Epoch 1731 / 10000) Train_Loss: 30.373; Val_Loss: 872.113   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.207\n",
      "(Epoch 1732 / 10000) Train_Loss: 33.070; Val_Loss: 871.063   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 4.436\n",
      "(Epoch 1733 / 10000) Train_Loss: 33.383; Val_Loss: 869.031   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 4.769\n",
      "(Epoch 1734 / 10000) Train_Loss: 33.726; Val_Loss: 896.587   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.414; Val_NMI: 4.684\n",
      "(Epoch 1735 / 10000) Train_Loss: 32.492; Val_Loss: 900.734   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 5.098\n",
      "(Epoch 1736 / 10000) Train_Loss: 31.631; Val_Loss: 901.990   Train_ACC: 15.198; Val_ACC: 20.741   Train_NMI: 0.444; Val_NMI: 4.783\n",
      "(Epoch 1737 / 10000) Train_Loss: 29.144; Val_Loss: 880.602   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.380; Val_NMI: 5.256\n",
      "(Epoch 1738 / 10000) Train_Loss: 29.423; Val_Loss: 813.594   Train_ACC: 15.074; Val_ACC: 21.481   Train_NMI: 0.412; Val_NMI: 5.715\n",
      "(Epoch 1739 / 10000) Train_Loss: 28.839; Val_Loss: 848.965   Train_ACC: 14.621; Val_ACC: 21.481   Train_NMI: 0.347; Val_NMI: 5.947\n",
      "(Epoch 1740 / 10000) Train_Loss: 28.369; Val_Loss: 880.797   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.464; Val_NMI: 5.490\n",
      "(Epoch 1741 / 10000) Train_Loss: 27.937; Val_Loss: 812.573   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.401; Val_NMI: 5.976\n",
      "(Epoch 1742 / 10000) Train_Loss: 28.117; Val_Loss: 840.270   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.430; Val_NMI: 5.079\n",
      "(Epoch 1743 / 10000) Train_Loss: 30.770; Val_Loss: 821.007   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.356; Val_NMI: 5.411\n",
      "(Epoch 1744 / 10000) Train_Loss: 31.142; Val_Loss: 843.264   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.408; Val_NMI: 5.553\n",
      "(Epoch 1745 / 10000) Train_Loss: 29.402; Val_Loss: 889.704   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.408; Val_NMI: 5.175\n",
      "(Epoch 1746 / 10000) Train_Loss: 29.917; Val_Loss: 928.693   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.337; Val_NMI: 5.446\n",
      "(Epoch 1747 / 10000) Train_Loss: 29.236; Val_Loss: 873.400   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.341; Val_NMI: 5.286\n",
      "(Epoch 1748 / 10000) Train_Loss: 28.858; Val_Loss: 822.911   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 5.409\n",
      "(Epoch 1749 / 10000) Train_Loss: 29.356; Val_Loss: 876.642   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 5.278\n",
      "(Epoch 1750 / 10000) Train_Loss: 28.835; Val_Loss: 844.293   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 5.238\n",
      "(Epoch 1751 / 10000) Train_Loss: 28.444; Val_Loss: 826.724   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 5.687\n",
      "(Epoch 1752 / 10000) Train_Loss: 29.573; Val_Loss: 832.883   Train_ACC: 14.868; Val_ACC: 21.852   Train_NMI: 0.416; Val_NMI: 5.690\n",
      "(Epoch 1753 / 10000) Train_Loss: 29.853; Val_Loss: 890.376   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.369; Val_NMI: 5.827\n",
      "(Epoch 1754 / 10000) Train_Loss: 31.461; Val_Loss: 844.086   Train_ACC: 15.033; Val_ACC: 21.481   Train_NMI: 0.385; Val_NMI: 5.742\n",
      "(Epoch 1755 / 10000) Train_Loss: 32.337; Val_Loss: 832.826   Train_ACC: 14.868; Val_ACC: 21.852   Train_NMI: 0.361; Val_NMI: 5.870\n",
      "(Epoch 1756 / 10000) Train_Loss: 30.720; Val_Loss: 844.325   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.391; Val_NMI: 6.236\n",
      "(Epoch 1757 / 10000) Train_Loss: 30.456; Val_Loss: 851.833   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.431; Val_NMI: 5.438\n",
      "(Epoch 1758 / 10000) Train_Loss: 30.633; Val_Loss: 913.855   Train_ACC: 14.662; Val_ACC: 21.111   Train_NMI: 0.380; Val_NMI: 5.522\n",
      "(Epoch 1759 / 10000) Train_Loss: 34.192; Val_Loss: 820.237   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.371; Val_NMI: 5.697\n",
      "(Epoch 1760 / 10000) Train_Loss: 33.168; Val_Loss: 864.447   Train_ACC: 14.868; Val_ACC: 21.852   Train_NMI: 0.431; Val_NMI: 6.070\n",
      "(Epoch 1761 / 10000) Train_Loss: 34.124; Val_Loss: 895.184   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.422; Val_NMI: 5.834\n",
      "(Epoch 1762 / 10000) Train_Loss: 31.120; Val_Loss: 857.040   Train_ACC: 14.951; Val_ACC: 21.481   Train_NMI: 0.419; Val_NMI: 5.608\n",
      "(Epoch 1763 / 10000) Train_Loss: 31.269; Val_Loss: 824.059   Train_ACC: 15.033; Val_ACC: 21.852   Train_NMI: 0.424; Val_NMI: 5.899\n",
      "(Epoch 1764 / 10000) Train_Loss: 30.177; Val_Loss: 881.539   Train_ACC: 14.745; Val_ACC: 21.852   Train_NMI: 0.370; Val_NMI: 6.271\n",
      "(Epoch 1765 / 10000) Train_Loss: 29.796; Val_Loss: 860.662   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.402; Val_NMI: 5.841\n",
      "(Epoch 1766 / 10000) Train_Loss: 30.810; Val_Loss: 874.396   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 5.509\n",
      "(Epoch 1767 / 10000) Train_Loss: 31.357; Val_Loss: 827.526   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.374; Val_NMI: 5.856\n",
      "(Epoch 1768 / 10000) Train_Loss: 30.596; Val_Loss: 845.457   Train_ACC: 14.662; Val_ACC: 21.111   Train_NMI: 0.359; Val_NMI: 5.631\n",
      "(Epoch 1769 / 10000) Train_Loss: 30.905; Val_Loss: 836.833   Train_ACC: 15.074; Val_ACC: 21.481   Train_NMI: 0.397; Val_NMI: 5.982\n",
      "(Epoch 1770 / 10000) Train_Loss: 35.567; Val_Loss: 875.247   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.426; Val_NMI: 5.741\n",
      "(Epoch 1771 / 10000) Train_Loss: 33.743; Val_Loss: 864.701   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.364; Val_NMI: 5.210\n",
      "(Epoch 1772 / 10000) Train_Loss: 31.618; Val_Loss: 888.171   Train_ACC: 15.115; Val_ACC: 21.852   Train_NMI: 0.429; Val_NMI: 5.712\n",
      "(Epoch 1773 / 10000) Train_Loss: 29.467; Val_Loss: 869.458   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.431; Val_NMI: 5.312\n",
      "(Epoch 1774 / 10000) Train_Loss: 28.695; Val_Loss: 815.041   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.401; Val_NMI: 5.884\n",
      "(Epoch 1775 / 10000) Train_Loss: 28.684; Val_Loss: 864.870   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.388; Val_NMI: 5.552\n",
      "(Epoch 1776 / 10000) Train_Loss: 28.589; Val_Loss: 901.974   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.399; Val_NMI: 5.650\n",
      "(Epoch 1777 / 10000) Train_Loss: 28.744; Val_Loss: 907.380   Train_ACC: 14.745; Val_ACC: 21.481   Train_NMI: 0.334; Val_NMI: 5.890\n",
      "(Epoch 1778 / 10000) Train_Loss: 28.314; Val_Loss: 898.446   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.400; Val_NMI: 5.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1779 / 10000) Train_Loss: 28.209; Val_Loss: 818.093   Train_ACC: 14.827; Val_ACC: 21.852   Train_NMI: 0.389; Val_NMI: 5.918\n",
      "(Epoch 1780 / 10000) Train_Loss: 28.868; Val_Loss: 843.863   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.330; Val_NMI: 5.200\n",
      "(Epoch 1781 / 10000) Train_Loss: 29.289; Val_Loss: 855.541   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.400; Val_NMI: 5.454\n",
      "(Epoch 1782 / 10000) Train_Loss: 29.325; Val_Loss: 871.453   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.381; Val_NMI: 5.163\n",
      "(Epoch 1783 / 10000) Train_Loss: 28.482; Val_Loss: 883.140   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.420; Val_NMI: 5.172\n",
      "(Epoch 1784 / 10000) Train_Loss: 28.624; Val_Loss: 855.501   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.426; Val_NMI: 5.888\n",
      "(Epoch 1785 / 10000) Train_Loss: 29.149; Val_Loss: 845.432   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 5.514\n",
      "(Epoch 1786 / 10000) Train_Loss: 29.453; Val_Loss: 853.440   Train_ACC: 15.074; Val_ACC: 21.111   Train_NMI: 0.426; Val_NMI: 5.840\n",
      "(Epoch 1787 / 10000) Train_Loss: 32.284; Val_Loss: 818.102   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 5.099\n",
      "(Epoch 1788 / 10000) Train_Loss: 30.416; Val_Loss: 881.105   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.445; Val_NMI: 5.395\n",
      "(Epoch 1789 / 10000) Train_Loss: 29.202; Val_Loss: 889.243   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 4.945\n",
      "(Epoch 1790 / 10000) Train_Loss: 29.999; Val_Loss: 865.375   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.452; Val_NMI: 4.931\n",
      "(Epoch 1791 / 10000) Train_Loss: 30.183; Val_Loss: 911.489   Train_ACC: 14.992; Val_ACC: 21.852   Train_NMI: 0.421; Val_NMI: 5.483\n",
      "(Epoch 1792 / 10000) Train_Loss: 29.333; Val_Loss: 879.018   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 5.409\n",
      "(Epoch 1793 / 10000) Train_Loss: 29.156; Val_Loss: 847.124   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.384; Val_NMI: 5.512\n",
      "(Epoch 1794 / 10000) Train_Loss: 29.733; Val_Loss: 874.057   Train_ACC: 14.992; Val_ACC: 21.481   Train_NMI: 0.395; Val_NMI: 5.160\n",
      "(Epoch 1795 / 10000) Train_Loss: 28.436; Val_Loss: 890.865   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.357; Val_NMI: 5.178\n",
      "(Epoch 1796 / 10000) Train_Loss: 30.437; Val_Loss: 871.084   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.389; Val_NMI: 5.401\n",
      "(Epoch 1797 / 10000) Train_Loss: 28.804; Val_Loss: 899.093   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.346; Val_NMI: 5.157\n",
      "(Epoch 1798 / 10000) Train_Loss: 29.365; Val_Loss: 867.856   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.373; Val_NMI: 5.111\n",
      "(Epoch 1799 / 10000) Train_Loss: 30.019; Val_Loss: 867.527   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 5.070\n",
      "(Epoch 1800 / 10000) Train_Loss: 29.056; Val_Loss: 872.167   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 5.352\n",
      "(Epoch 1801 / 10000) Train_Loss: 28.678; Val_Loss: 905.689   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 5.495\n",
      "(Epoch 1802 / 10000) Train_Loss: 40.122; Val_Loss: 882.412   Train_ACC: 14.580; Val_ACC: 21.111   Train_NMI: 0.355; Val_NMI: 5.193\n",
      "(Epoch 1803 / 10000) Train_Loss: 42.938; Val_Loss: 844.237   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.395; Val_NMI: 5.327\n",
      "(Epoch 1804 / 10000) Train_Loss: 33.262; Val_Loss: 836.930   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 5.602\n",
      "(Epoch 1805 / 10000) Train_Loss: 29.940; Val_Loss: 929.416   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.316; Val_NMI: 5.049\n",
      "(Epoch 1806 / 10000) Train_Loss: 28.994; Val_Loss: 842.393   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.377; Val_NMI: 5.496\n",
      "(Epoch 1807 / 10000) Train_Loss: 28.433; Val_Loss: 863.256   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.426; Val_NMI: 5.696\n",
      "(Epoch 1808 / 10000) Train_Loss: 28.102; Val_Loss: 839.066   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 5.171\n",
      "(Epoch 1809 / 10000) Train_Loss: 31.457; Val_Loss: 855.096   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.405; Val_NMI: 5.206\n",
      "(Epoch 1810 / 10000) Train_Loss: 35.250; Val_Loss: 834.829   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.402; Val_NMI: 5.549\n",
      "(Epoch 1811 / 10000) Train_Loss: 32.226; Val_Loss: 826.817   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.320; Val_NMI: 5.314\n",
      "(Epoch 1812 / 10000) Train_Loss: 29.850; Val_Loss: 850.450   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 4.970\n",
      "(Epoch 1813 / 10000) Train_Loss: 28.548; Val_Loss: 896.751   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.399; Val_NMI: 5.530\n",
      "(Epoch 1814 / 10000) Train_Loss: 29.428; Val_Loss: 853.477   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.327; Val_NMI: 5.459\n",
      "(Epoch 1815 / 10000) Train_Loss: 28.777; Val_Loss: 854.897   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.359; Val_NMI: 5.635\n",
      "(Epoch 1816 / 10000) Train_Loss: 28.528; Val_Loss: 845.096   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.395; Val_NMI: 5.880\n",
      "(Epoch 1817 / 10000) Train_Loss: 28.343; Val_Loss: 869.449   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.443\n",
      "(Epoch 1818 / 10000) Train_Loss: 28.866; Val_Loss: 878.580   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 5.534\n",
      "(Epoch 1819 / 10000) Train_Loss: 28.225; Val_Loss: 867.752   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.356; Val_NMI: 5.712\n",
      "(Epoch 1820 / 10000) Train_Loss: 28.522; Val_Loss: 887.822   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.462; Val_NMI: 5.651\n",
      "(Epoch 1821 / 10000) Train_Loss: 28.258; Val_Loss: 862.921   Train_ACC: 15.074; Val_ACC: 21.481   Train_NMI: 0.458; Val_NMI: 6.190\n",
      "(Epoch 1822 / 10000) Train_Loss: 28.468; Val_Loss: 831.389   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.324; Val_NMI: 5.551\n",
      "(Epoch 1823 / 10000) Train_Loss: 29.182; Val_Loss: 867.565   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 5.277\n",
      "(Epoch 1824 / 10000) Train_Loss: 31.260; Val_Loss: 892.905   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.092\n",
      "(Epoch 1825 / 10000) Train_Loss: 39.085; Val_Loss: 818.034   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.336; Val_NMI: 5.163\n",
      "(Epoch 1826 / 10000) Train_Loss: 37.517; Val_Loss: 849.268   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.350; Val_NMI: 5.446\n",
      "(Epoch 1827 / 10000) Train_Loss: 30.938; Val_Loss: 858.920   Train_ACC: 14.621; Val_ACC: 21.481   Train_NMI: 0.331; Val_NMI: 6.326\n",
      "(Epoch 1828 / 10000) Train_Loss: 28.925; Val_Loss: 828.665   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.370; Val_NMI: 5.087\n",
      "(Epoch 1829 / 10000) Train_Loss: 29.329; Val_Loss: 861.980   Train_ACC: 14.498; Val_ACC: 21.481   Train_NMI: 0.339; Val_NMI: 5.413\n",
      "(Epoch 1830 / 10000) Train_Loss: 29.267; Val_Loss: 878.779   Train_ACC: 14.498; Val_ACC: 21.111   Train_NMI: 0.343; Val_NMI: 5.558\n",
      "(Epoch 1831 / 10000) Train_Loss: 28.706; Val_Loss: 831.605   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.338; Val_NMI: 5.550\n",
      "(Epoch 1832 / 10000) Train_Loss: 28.348; Val_Loss: 886.917   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.366; Val_NMI: 5.649\n",
      "(Epoch 1833 / 10000) Train_Loss: 29.291; Val_Loss: 807.479   Train_ACC: 14.580; Val_ACC: 21.111   Train_NMI: 0.335; Val_NMI: 6.032\n",
      "(Epoch 1834 / 10000) Train_Loss: 28.431; Val_Loss: 837.858   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.348; Val_NMI: 5.713\n",
      "(Epoch 1835 / 10000) Train_Loss: 28.756; Val_Loss: 829.204   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.413; Val_NMI: 5.831\n",
      "(Epoch 1836 / 10000) Train_Loss: 28.585; Val_Loss: 866.486   Train_ACC: 14.662; Val_ACC: 21.481   Train_NMI: 0.341; Val_NMI: 5.856\n",
      "(Epoch 1837 / 10000) Train_Loss: 27.674; Val_Loss: 838.958   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.325; Val_NMI: 5.518\n",
      "(Epoch 1838 / 10000) Train_Loss: 30.196; Val_Loss: 889.655   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.398; Val_NMI: 5.634\n",
      "(Epoch 1839 / 10000) Train_Loss: 29.223; Val_Loss: 858.983   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.334; Val_NMI: 6.159\n",
      "(Epoch 1840 / 10000) Train_Loss: 27.876; Val_Loss: 880.389   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.364; Val_NMI: 5.899\n",
      "(Epoch 1841 / 10000) Train_Loss: 27.712; Val_Loss: 885.318   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 5.576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1842 / 10000) Train_Loss: 28.185; Val_Loss: 852.563   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.406; Val_NMI: 5.455\n",
      "(Epoch 1843 / 10000) Train_Loss: 27.965; Val_Loss: 854.294   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.343; Val_NMI: 5.642\n",
      "(Epoch 1844 / 10000) Train_Loss: 28.103; Val_Loss: 880.288   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.365; Val_NMI: 5.826\n",
      "(Epoch 1845 / 10000) Train_Loss: 28.920; Val_Loss: 846.612   Train_ACC: 14.415; Val_ACC: 19.630   Train_NMI: 0.283; Val_NMI: 5.092\n",
      "(Epoch 1846 / 10000) Train_Loss: 29.757; Val_Loss: 875.477   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 5.124\n",
      "(Epoch 1847 / 10000) Train_Loss: 29.324; Val_Loss: 874.322   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.346; Val_NMI: 5.260\n",
      "(Epoch 1848 / 10000) Train_Loss: 28.811; Val_Loss: 909.525   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.399; Val_NMI: 5.323\n",
      "(Epoch 1849 / 10000) Train_Loss: 28.073; Val_Loss: 889.472   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 4.628\n",
      "(Epoch 1850 / 10000) Train_Loss: 30.561; Val_Loss: 841.817   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.412; Val_NMI: 5.533\n",
      "(Epoch 1851 / 10000) Train_Loss: 30.367; Val_Loss: 856.536   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.360; Val_NMI: 5.515\n",
      "(Epoch 1852 / 10000) Train_Loss: 31.429; Val_Loss: 842.047   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.327; Val_NMI: 5.274\n",
      "(Epoch 1853 / 10000) Train_Loss: 30.095; Val_Loss: 873.306   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.339; Val_NMI: 5.254\n",
      "(Epoch 1854 / 10000) Train_Loss: 29.958; Val_Loss: 861.996   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.344; Val_NMI: 5.359\n",
      "(Epoch 1855 / 10000) Train_Loss: 29.762; Val_Loss: 893.816   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.344; Val_NMI: 5.183\n",
      "(Epoch 1856 / 10000) Train_Loss: 28.296; Val_Loss: 850.851   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 5.471\n",
      "(Epoch 1857 / 10000) Train_Loss: 28.336; Val_Loss: 826.012   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.343; Val_NMI: 5.514\n",
      "(Epoch 1858 / 10000) Train_Loss: 30.691; Val_Loss: 846.590   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 5.214\n",
      "(Epoch 1859 / 10000) Train_Loss: 31.174; Val_Loss: 896.370   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.379; Val_NMI: 5.197\n",
      "(Epoch 1860 / 10000) Train_Loss: 29.182; Val_Loss: 851.870   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.364; Val_NMI: 4.977\n",
      "(Epoch 1861 / 10000) Train_Loss: 30.645; Val_Loss: 902.603   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.376; Val_NMI: 5.395\n",
      "(Epoch 1862 / 10000) Train_Loss: 28.905; Val_Loss: 868.977   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.426; Val_NMI: 5.039\n",
      "(Epoch 1863 / 10000) Train_Loss: 28.036; Val_Loss: 849.636   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.895\n",
      "(Epoch 1864 / 10000) Train_Loss: 29.489; Val_Loss: 897.850   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.043\n",
      "(Epoch 1865 / 10000) Train_Loss: 30.327; Val_Loss: 984.556   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.304; Val_NMI: 4.813\n",
      "(Epoch 1866 / 10000) Train_Loss: 31.353; Val_Loss: 860.446   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.359; Val_NMI: 4.362\n",
      "(Epoch 1867 / 10000) Train_Loss: 33.780; Val_Loss: 895.885   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.422; Val_NMI: 5.565\n",
      "(Epoch 1868 / 10000) Train_Loss: 31.021; Val_Loss: 841.899   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.436; Val_NMI: 5.389\n",
      "(Epoch 1869 / 10000) Train_Loss: 31.667; Val_Loss: 858.746   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.937\n",
      "(Epoch 1870 / 10000) Train_Loss: 31.945; Val_Loss: 881.955   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.435; Val_NMI: 5.430\n",
      "(Epoch 1871 / 10000) Train_Loss: 29.971; Val_Loss: 910.443   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.409; Val_NMI: 5.159\n",
      "(Epoch 1872 / 10000) Train_Loss: 29.828; Val_Loss: 907.111   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.418; Val_NMI: 4.968\n",
      "(Epoch 1873 / 10000) Train_Loss: 30.530; Val_Loss: 891.203   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.381; Val_NMI: 5.197\n",
      "(Epoch 1874 / 10000) Train_Loss: 30.830; Val_Loss: 863.384   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.373; Val_NMI: 5.090\n",
      "(Epoch 1875 / 10000) Train_Loss: 29.194; Val_Loss: 883.076   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.805\n",
      "(Epoch 1876 / 10000) Train_Loss: 28.573; Val_Loss: 818.917   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.447; Val_NMI: 5.335\n",
      "(Epoch 1877 / 10000) Train_Loss: 28.280; Val_Loss: 856.998   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 5.163\n",
      "(Epoch 1878 / 10000) Train_Loss: 27.588; Val_Loss: 903.506   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.386; Val_NMI: 5.159\n",
      "(Epoch 1879 / 10000) Train_Loss: 28.164; Val_Loss: 887.478   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.358; Val_NMI: 5.367\n",
      "(Epoch 1880 / 10000) Train_Loss: 27.591; Val_Loss: 875.488   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.420; Val_NMI: 5.391\n",
      "(Epoch 1881 / 10000) Train_Loss: 28.698; Val_Loss: 902.706   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 5.138\n",
      "(Epoch 1882 / 10000) Train_Loss: 29.535; Val_Loss: 833.208   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.341; Val_NMI: 5.323\n",
      "(Epoch 1883 / 10000) Train_Loss: 29.556; Val_Loss: 920.622   Train_ACC: 14.539; Val_ACC: 21.481   Train_NMI: 0.348; Val_NMI: 5.275\n",
      "(Epoch 1884 / 10000) Train_Loss: 28.976; Val_Loss: 879.147   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.390; Val_NMI: 5.763\n",
      "(Epoch 1885 / 10000) Train_Loss: 28.852; Val_Loss: 910.768   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.352; Val_NMI: 5.549\n",
      "(Epoch 1886 / 10000) Train_Loss: 29.724; Val_Loss: 853.986   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 5.334\n",
      "(Epoch 1887 / 10000) Train_Loss: 28.818; Val_Loss: 823.602   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.408; Val_NMI: 6.137\n",
      "(Epoch 1888 / 10000) Train_Loss: 28.914; Val_Loss: 852.171   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.396; Val_NMI: 5.260\n",
      "(Epoch 1889 / 10000) Train_Loss: 29.112; Val_Loss: 852.046   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.440; Val_NMI: 6.063\n",
      "(Epoch 1890 / 10000) Train_Loss: 29.642; Val_Loss: 881.337   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.390; Val_NMI: 5.645\n",
      "(Epoch 1891 / 10000) Train_Loss: 29.513; Val_Loss: 834.652   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.427; Val_NMI: 5.729\n",
      "(Epoch 1892 / 10000) Train_Loss: 28.761; Val_Loss: 885.174   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.357; Val_NMI: 5.748\n",
      "(Epoch 1893 / 10000) Train_Loss: 28.006; Val_Loss: 874.568   Train_ACC: 14.539; Val_ACC: 21.111   Train_NMI: 0.333; Val_NMI: 5.340\n",
      "(Epoch 1894 / 10000) Train_Loss: 30.944; Val_Loss: 901.542   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.339; Val_NMI: 5.548\n",
      "(Epoch 1895 / 10000) Train_Loss: 31.081; Val_Loss: 863.906   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 5.299\n",
      "(Epoch 1896 / 10000) Train_Loss: 30.869; Val_Loss: 845.338   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 5.309\n",
      "(Epoch 1897 / 10000) Train_Loss: 30.270; Val_Loss: 836.854   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.406; Val_NMI: 5.451\n",
      "(Epoch 1898 / 10000) Train_Loss: 30.273; Val_Loss: 886.437   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 5.154\n",
      "(Epoch 1899 / 10000) Train_Loss: 29.754; Val_Loss: 861.843   Train_ACC: 14.580; Val_ACC: 21.111   Train_NMI: 0.378; Val_NMI: 5.063\n",
      "(Epoch 1900 / 10000) Train_Loss: 29.616; Val_Loss: 896.581   Train_ACC: 14.580; Val_ACC: 21.111   Train_NMI: 0.338; Val_NMI: 5.593\n",
      "(Epoch 1901 / 10000) Train_Loss: 29.235; Val_Loss: 940.552   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.360; Val_NMI: 5.553\n",
      "(Epoch 1902 / 10000) Train_Loss: 27.977; Val_Loss: 866.109   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.381; Val_NMI: 5.375\n",
      "(Epoch 1903 / 10000) Train_Loss: 27.804; Val_Loss: 883.164   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.358; Val_NMI: 5.668\n",
      "(Epoch 1904 / 10000) Train_Loss: 27.989; Val_Loss: 842.339   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.328; Val_NMI: 6.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1905 / 10000) Train_Loss: 28.313; Val_Loss: 888.656   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.399; Val_NMI: 5.939\n",
      "(Epoch 1906 / 10000) Train_Loss: 28.313; Val_Loss: 847.055   Train_ACC: 14.621; Val_ACC: 21.111   Train_NMI: 0.359; Val_NMI: 5.644\n",
      "(Epoch 1907 / 10000) Train_Loss: 30.048; Val_Loss: 854.285   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.367; Val_NMI: 6.105\n",
      "(Epoch 1908 / 10000) Train_Loss: 30.096; Val_Loss: 855.547   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.355; Val_NMI: 5.435\n",
      "(Epoch 1909 / 10000) Train_Loss: 29.760; Val_Loss: 858.389   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 6.196\n",
      "(Epoch 1910 / 10000) Train_Loss: 32.112; Val_Loss: 906.725   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.846\n",
      "(Epoch 1911 / 10000) Train_Loss: 29.768; Val_Loss: 879.837   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 5.352\n",
      "(Epoch 1912 / 10000) Train_Loss: 28.422; Val_Loss: 877.875   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.394; Val_NMI: 5.418\n",
      "(Epoch 1913 / 10000) Train_Loss: 28.744; Val_Loss: 908.810   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 5.248\n",
      "(Epoch 1914 / 10000) Train_Loss: 28.190; Val_Loss: 866.697   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.421; Val_NMI: 5.014\n",
      "(Epoch 1915 / 10000) Train_Loss: 28.897; Val_Loss: 896.639   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 5.544\n",
      "(Epoch 1916 / 10000) Train_Loss: 28.172; Val_Loss: 854.735   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.172\n",
      "(Epoch 1917 / 10000) Train_Loss: 28.259; Val_Loss: 921.105   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.326; Val_NMI: 5.185\n",
      "(Epoch 1918 / 10000) Train_Loss: 28.541; Val_Loss: 883.274   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 5.403\n",
      "(Epoch 1919 / 10000) Train_Loss: 30.423; Val_Loss: 819.664   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.359; Val_NMI: 5.293\n",
      "(Epoch 1920 / 10000) Train_Loss: 29.095; Val_Loss: 906.486   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.287\n",
      "(Epoch 1921 / 10000) Train_Loss: 27.942; Val_Loss: 882.341   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.380; Val_NMI: 5.640\n",
      "(Epoch 1922 / 10000) Train_Loss: 28.797; Val_Loss: 874.160   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 5.576\n",
      "(Epoch 1923 / 10000) Train_Loss: 29.642; Val_Loss: 902.609   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.388; Val_NMI: 4.835\n",
      "(Epoch 1924 / 10000) Train_Loss: 29.526; Val_Loss: 913.768   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.422; Val_NMI: 5.786\n",
      "(Epoch 1925 / 10000) Train_Loss: 28.264; Val_Loss: 882.651   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.832\n",
      "(Epoch 1926 / 10000) Train_Loss: 29.100; Val_Loss: 856.528   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.348; Val_NMI: 5.432\n",
      "(Epoch 1927 / 10000) Train_Loss: 30.373; Val_Loss: 863.490   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 6.000\n",
      "(Epoch 1928 / 10000) Train_Loss: 32.533; Val_Loss: 887.609   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.280; Val_NMI: 5.279\n",
      "(Epoch 1929 / 10000) Train_Loss: 31.340; Val_Loss: 851.519   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 5.133\n",
      "(Epoch 1930 / 10000) Train_Loss: 35.160; Val_Loss: 864.175   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 5.263\n",
      "(Epoch 1931 / 10000) Train_Loss: 38.769; Val_Loss: 856.621   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 4.917\n",
      "(Epoch 1932 / 10000) Train_Loss: 33.419; Val_Loss: 874.085   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 5.617\n",
      "(Epoch 1933 / 10000) Train_Loss: 30.830; Val_Loss: 864.622   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.427; Val_NMI: 5.120\n",
      "(Epoch 1934 / 10000) Train_Loss: 29.253; Val_Loss: 899.759   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.430; Val_NMI: 4.962\n",
      "(Epoch 1935 / 10000) Train_Loss: 28.243; Val_Loss: 870.521   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.480; Val_NMI: 5.169\n",
      "(Epoch 1936 / 10000) Train_Loss: 27.320; Val_Loss: 895.677   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 5.271\n",
      "(Epoch 1937 / 10000) Train_Loss: 28.041; Val_Loss: 826.311   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 5.390\n",
      "(Epoch 1938 / 10000) Train_Loss: 28.424; Val_Loss: 839.744   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 5.559\n",
      "(Epoch 1939 / 10000) Train_Loss: 28.749; Val_Loss: 883.664   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.416; Val_NMI: 4.775\n",
      "(Epoch 1940 / 10000) Train_Loss: 29.046; Val_Loss: 913.401   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.416; Val_NMI: 5.177\n",
      "(Epoch 1941 / 10000) Train_Loss: 28.457; Val_Loss: 855.496   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.366; Val_NMI: 5.459\n",
      "(Epoch 1942 / 10000) Train_Loss: 28.861; Val_Loss: 865.167   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.417; Val_NMI: 5.430\n",
      "(Epoch 1943 / 10000) Train_Loss: 30.259; Val_Loss: 876.533   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.473; Val_NMI: 5.039\n",
      "(Epoch 1944 / 10000) Train_Loss: 29.265; Val_Loss: 903.683   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.410; Val_NMI: 5.733\n",
      "(Epoch 1945 / 10000) Train_Loss: 28.635; Val_Loss: 901.561   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 5.254\n",
      "(Epoch 1946 / 10000) Train_Loss: 27.558; Val_Loss: 921.310   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.339; Val_NMI: 5.832\n",
      "(Epoch 1947 / 10000) Train_Loss: 27.959; Val_Loss: 860.358   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.362; Val_NMI: 5.107\n",
      "(Epoch 1948 / 10000) Train_Loss: 31.274; Val_Loss: 861.727   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.437; Val_NMI: 5.344\n",
      "(Epoch 1949 / 10000) Train_Loss: 30.046; Val_Loss: 871.897   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.383; Val_NMI: 5.199\n",
      "(Epoch 1950 / 10000) Train_Loss: 30.367; Val_Loss: 880.961   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.401; Val_NMI: 4.971\n",
      "(Epoch 1951 / 10000) Train_Loss: 29.622; Val_Loss: 890.308   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.340; Val_NMI: 5.116\n",
      "(Epoch 1952 / 10000) Train_Loss: 28.678; Val_Loss: 888.561   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.359; Val_NMI: 5.238\n",
      "(Epoch 1953 / 10000) Train_Loss: 29.716; Val_Loss: 944.223   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 5.265\n",
      "(Epoch 1954 / 10000) Train_Loss: 28.622; Val_Loss: 926.368   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 5.231\n",
      "(Epoch 1955 / 10000) Train_Loss: 29.035; Val_Loss: 858.694   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.352; Val_NMI: 5.558\n",
      "(Epoch 1956 / 10000) Train_Loss: 32.481; Val_Loss: 891.455   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.437; Val_NMI: 5.528\n",
      "(Epoch 1957 / 10000) Train_Loss: 33.274; Val_Loss: 901.872   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.358; Val_NMI: 5.414\n",
      "(Epoch 1958 / 10000) Train_Loss: 30.715; Val_Loss: 903.514   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.397; Val_NMI: 5.540\n",
      "(Epoch 1959 / 10000) Train_Loss: 31.305; Val_Loss: 931.194   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.428; Val_NMI: 5.686\n",
      "(Epoch 1960 / 10000) Train_Loss: 30.198; Val_Loss: 845.513   Train_ACC: 14.827; Val_ACC: 21.852   Train_NMI: 0.377; Val_NMI: 5.297\n",
      "(Epoch 1961 / 10000) Train_Loss: 29.465; Val_Loss: 846.780   Train_ACC: 14.662; Val_ACC: 21.481   Train_NMI: 0.365; Val_NMI: 6.200\n",
      "(Epoch 1962 / 10000) Train_Loss: 30.603; Val_Loss: 875.410   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.350; Val_NMI: 4.978\n",
      "(Epoch 1963 / 10000) Train_Loss: 29.055; Val_Loss: 889.667   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.337; Val_NMI: 5.193\n",
      "(Epoch 1964 / 10000) Train_Loss: 29.764; Val_Loss: 917.421   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 4.895\n",
      "(Epoch 1965 / 10000) Train_Loss: 28.888; Val_Loss: 912.169   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.408; Val_NMI: 4.502\n",
      "(Epoch 1966 / 10000) Train_Loss: 28.655; Val_Loss: 901.292   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.391; Val_NMI: 4.884\n",
      "(Epoch 1967 / 10000) Train_Loss: 31.154; Val_Loss: 852.426   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 5.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1968 / 10000) Train_Loss: 31.890; Val_Loss: 894.051   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.359; Val_NMI: 4.771\n",
      "(Epoch 1969 / 10000) Train_Loss: 30.592; Val_Loss: 873.548   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.363; Val_NMI: 5.185\n",
      "(Epoch 1970 / 10000) Train_Loss: 28.948; Val_Loss: 870.120   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.343; Val_NMI: 5.429\n",
      "(Epoch 1971 / 10000) Train_Loss: 28.376; Val_Loss: 847.141   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.405; Val_NMI: 5.356\n",
      "(Epoch 1972 / 10000) Train_Loss: 27.073; Val_Loss: 850.071   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.394; Val_NMI: 4.789\n",
      "(Epoch 1973 / 10000) Train_Loss: 27.494; Val_Loss: 818.106   Train_ACC: 14.827; Val_ACC: 21.481   Train_NMI: 0.356; Val_NMI: 5.798\n",
      "(Epoch 1974 / 10000) Train_Loss: 28.257; Val_Loss: 890.237   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 5.192\n",
      "(Epoch 1975 / 10000) Train_Loss: 28.274; Val_Loss: 902.501   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.388; Val_NMI: 4.646\n",
      "(Epoch 1976 / 10000) Train_Loss: 30.170; Val_Loss: 890.221   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 4.890\n",
      "(Epoch 1977 / 10000) Train_Loss: 28.744; Val_Loss: 852.620   Train_ACC: 14.703; Val_ACC: 21.481   Train_NMI: 0.402; Val_NMI: 5.544\n",
      "(Epoch 1978 / 10000) Train_Loss: 29.285; Val_Loss: 924.128   Train_ACC: 14.786; Val_ACC: 21.852   Train_NMI: 0.394; Val_NMI: 5.623\n",
      "(Epoch 1979 / 10000) Train_Loss: 30.725; Val_Loss: 881.768   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.371; Val_NMI: 5.167\n",
      "(Epoch 1980 / 10000) Train_Loss: 29.420; Val_Loss: 917.312   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 5.260\n",
      "(Epoch 1981 / 10000) Train_Loss: 28.978; Val_Loss: 844.914   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.422; Val_NMI: 5.041\n",
      "(Epoch 1982 / 10000) Train_Loss: 31.063; Val_Loss: 838.201   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.437; Val_NMI: 5.158\n",
      "(Epoch 1983 / 10000) Train_Loss: 31.565; Val_Loss: 864.301   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 5.129\n",
      "(Epoch 1984 / 10000) Train_Loss: 28.909; Val_Loss: 891.912   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.417; Val_NMI: 5.087\n",
      "(Epoch 1985 / 10000) Train_Loss: 29.090; Val_Loss: 898.985   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 5.450\n",
      "(Epoch 1986 / 10000) Train_Loss: 28.673; Val_Loss: 832.183   Train_ACC: 14.868; Val_ACC: 21.481   Train_NMI: 0.380; Val_NMI: 5.386\n",
      "(Epoch 1987 / 10000) Train_Loss: 28.173; Val_Loss: 901.157   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.418; Val_NMI: 4.564\n",
      "(Epoch 1988 / 10000) Train_Loss: 28.070; Val_Loss: 860.758   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.443; Val_NMI: 5.095\n",
      "(Epoch 1989 / 10000) Train_Loss: 29.349; Val_Loss: 908.499   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.511\n",
      "(Epoch 1990 / 10000) Train_Loss: 30.356; Val_Loss: 901.171   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 5.501\n",
      "(Epoch 1991 / 10000) Train_Loss: 29.467; Val_Loss: 928.462   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.443; Val_NMI: 5.087\n",
      "(Epoch 1992 / 10000) Train_Loss: 28.697; Val_Loss: 869.882   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.461; Val_NMI: 4.989\n",
      "(Epoch 1993 / 10000) Train_Loss: 29.175; Val_Loss: 859.815   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 5.279\n",
      "(Epoch 1994 / 10000) Train_Loss: 30.356; Val_Loss: 830.158   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 5.239\n",
      "(Epoch 1995 / 10000) Train_Loss: 30.739; Val_Loss: 898.406   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.369; Val_NMI: 4.841\n",
      "(Epoch 1996 / 10000) Train_Loss: 30.006; Val_Loss: 888.635   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.056\n",
      "(Epoch 1997 / 10000) Train_Loss: 28.798; Val_Loss: 888.856   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.335; Val_NMI: 5.002\n",
      "(Epoch 1998 / 10000) Train_Loss: 28.201; Val_Loss: 909.656   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.763\n",
      "(Epoch 1999 / 10000) Train_Loss: 29.304; Val_Loss: 947.665   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.014\n",
      "(Epoch 2000 / 10000) Train_Loss: 29.221; Val_Loss: 859.452   Train_ACC: 15.033; Val_ACC: 21.481   Train_NMI: 0.460; Val_NMI: 5.091\n",
      "(Epoch 2001 / 10000) Train_Loss: 29.440; Val_Loss: 844.803   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.350; Val_NMI: 4.543\n",
      "(Epoch 2002 / 10000) Train_Loss: 29.130; Val_Loss: 882.018   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.420; Val_NMI: 5.330\n",
      "(Epoch 2003 / 10000) Train_Loss: 28.274; Val_Loss: 896.113   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.437; Val_NMI: 4.657\n",
      "(Epoch 2004 / 10000) Train_Loss: 28.281; Val_Loss: 835.790   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.338; Val_NMI: 4.921\n",
      "(Epoch 2005 / 10000) Train_Loss: 29.827; Val_Loss: 924.166   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.432; Val_NMI: 5.051\n",
      "(Epoch 2006 / 10000) Train_Loss: 30.603; Val_Loss: 857.168   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.406; Val_NMI: 4.911\n",
      "(Epoch 2007 / 10000) Train_Loss: 31.718; Val_Loss: 884.195   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.365; Val_NMI: 4.659\n",
      "(Epoch 2008 / 10000) Train_Loss: 31.284; Val_Loss: 890.896   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.998\n",
      "(Epoch 2009 / 10000) Train_Loss: 28.909; Val_Loss: 871.294   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 4.675\n",
      "(Epoch 2010 / 10000) Train_Loss: 29.147; Val_Loss: 903.133   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.403; Val_NMI: 5.051\n",
      "(Epoch 2011 / 10000) Train_Loss: 27.888; Val_Loss: 952.612   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.389; Val_NMI: 4.443\n",
      "(Epoch 2012 / 10000) Train_Loss: 28.335; Val_Loss: 935.447   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.341; Val_NMI: 4.832\n",
      "(Epoch 2013 / 10000) Train_Loss: 29.232; Val_Loss: 876.114   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 4.925\n",
      "(Epoch 2014 / 10000) Train_Loss: 29.244; Val_Loss: 902.322   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.330; Val_NMI: 4.894\n",
      "(Epoch 2015 / 10000) Train_Loss: 29.338; Val_Loss: 882.343   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.356; Val_NMI: 5.067\n",
      "(Epoch 2016 / 10000) Train_Loss: 28.196; Val_Loss: 943.971   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 4.820\n",
      "(Epoch 2017 / 10000) Train_Loss: 29.192; Val_Loss: 892.315   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.353; Val_NMI: 4.924\n",
      "(Epoch 2018 / 10000) Train_Loss: 33.881; Val_Loss: 887.192   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 4.893\n",
      "(Epoch 2019 / 10000) Train_Loss: 33.459; Val_Loss: 878.640   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.390; Val_NMI: 4.805\n",
      "(Epoch 2020 / 10000) Train_Loss: 32.243; Val_Loss: 883.607   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.419; Val_NMI: 4.756\n",
      "(Epoch 2021 / 10000) Train_Loss: 31.446; Val_Loss: 833.875   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.408; Val_NMI: 5.160\n",
      "(Epoch 2022 / 10000) Train_Loss: 28.888; Val_Loss: 901.702   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.387; Val_NMI: 5.219\n",
      "(Epoch 2023 / 10000) Train_Loss: 27.877; Val_Loss: 921.002   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.397; Val_NMI: 4.612\n",
      "(Epoch 2024 / 10000) Train_Loss: 28.187; Val_Loss: 870.244   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 5.077\n",
      "(Epoch 2025 / 10000) Train_Loss: 27.868; Val_Loss: 837.279   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 5.121\n",
      "(Epoch 2026 / 10000) Train_Loss: 30.542; Val_Loss: 932.037   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.377; Val_NMI: 4.809\n",
      "(Epoch 2027 / 10000) Train_Loss: 31.186; Val_Loss: 895.592   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.465\n",
      "(Epoch 2028 / 10000) Train_Loss: 28.576; Val_Loss: 842.416   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.391; Val_NMI: 5.113\n",
      "(Epoch 2029 / 10000) Train_Loss: 28.206; Val_Loss: 882.496   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.392; Val_NMI: 5.403\n",
      "(Epoch 2030 / 10000) Train_Loss: 28.330; Val_Loss: 902.886   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.391; Val_NMI: 5.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2031 / 10000) Train_Loss: 29.993; Val_Loss: 876.490   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.366; Val_NMI: 5.207\n",
      "(Epoch 2032 / 10000) Train_Loss: 29.034; Val_Loss: 894.954   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.340; Val_NMI: 4.845\n",
      "(Epoch 2033 / 10000) Train_Loss: 28.707; Val_Loss: 816.429   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.401; Val_NMI: 4.996\n",
      "(Epoch 2034 / 10000) Train_Loss: 29.015; Val_Loss: 877.564   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.389; Val_NMI: 4.702\n",
      "(Epoch 2035 / 10000) Train_Loss: 29.332; Val_Loss: 840.785   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.404; Val_NMI: 5.199\n",
      "(Epoch 2036 / 10000) Train_Loss: 29.164; Val_Loss: 893.334   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.396; Val_NMI: 4.645\n",
      "(Epoch 2037 / 10000) Train_Loss: 28.865; Val_Loss: 837.561   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 4.673\n",
      "(Epoch 2038 / 10000) Train_Loss: 28.513; Val_Loss: 869.220   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.318; Val_NMI: 4.834\n",
      "(Epoch 2039 / 10000) Train_Loss: 29.004; Val_Loss: 903.238   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.410; Val_NMI: 4.343\n",
      "(Epoch 2040 / 10000) Train_Loss: 28.586; Val_Loss: 846.766   Train_ACC: 15.074; Val_ACC: 21.852   Train_NMI: 0.427; Val_NMI: 5.276\n",
      "(Epoch 2041 / 10000) Train_Loss: 29.517; Val_Loss: 945.121   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.397; Val_NMI: 4.664\n",
      "(Epoch 2042 / 10000) Train_Loss: 28.275; Val_Loss: 910.560   Train_ACC: 14.827; Val_ACC: 21.111   Train_NMI: 0.392; Val_NMI: 5.005\n",
      "(Epoch 2043 / 10000) Train_Loss: 28.614; Val_Loss: 901.600   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 5.017\n",
      "(Epoch 2044 / 10000) Train_Loss: 28.680; Val_Loss: 914.858   Train_ACC: 14.909; Val_ACC: 21.852   Train_NMI: 0.399; Val_NMI: 6.064\n",
      "(Epoch 2045 / 10000) Train_Loss: 28.287; Val_Loss: 858.531   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 4.650\n",
      "(Epoch 2046 / 10000) Train_Loss: 29.592; Val_Loss: 896.100   Train_ACC: 14.909; Val_ACC: 21.481   Train_NMI: 0.425; Val_NMI: 5.303\n",
      "(Epoch 2047 / 10000) Train_Loss: 30.729; Val_Loss: 895.087   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.377; Val_NMI: 5.039\n",
      "(Epoch 2048 / 10000) Train_Loss: 28.566; Val_Loss: 874.243   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.327; Val_NMI: 4.745\n",
      "(Epoch 2049 / 10000) Train_Loss: 30.195; Val_Loss: 905.497   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 5.204\n",
      "(Epoch 2050 / 10000) Train_Loss: 31.255; Val_Loss: 865.754   Train_ACC: 15.033; Val_ACC: 21.111   Train_NMI: 0.416; Val_NMI: 5.327\n",
      "(Epoch 2051 / 10000) Train_Loss: 29.584; Val_Loss: 897.365   Train_ACC: 14.580; Val_ACC: 20.741   Train_NMI: 0.350; Val_NMI: 5.849\n",
      "(Epoch 2052 / 10000) Train_Loss: 28.161; Val_Loss: 840.180   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.389; Val_NMI: 4.728\n",
      "(Epoch 2053 / 10000) Train_Loss: 28.337; Val_Loss: 884.857   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.377; Val_NMI: 5.501\n",
      "(Epoch 2054 / 10000) Train_Loss: 29.017; Val_Loss: 890.467   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.336; Val_NMI: 5.288\n",
      "(Epoch 2055 / 10000) Train_Loss: 29.178; Val_Loss: 916.759   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.438; Val_NMI: 5.143\n",
      "(Epoch 2056 / 10000) Train_Loss: 29.295; Val_Loss: 887.214   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 4.971\n",
      "(Epoch 2057 / 10000) Train_Loss: 28.220; Val_Loss: 913.591   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 4.986\n",
      "(Epoch 2058 / 10000) Train_Loss: 28.240; Val_Loss: 870.636   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.358; Val_NMI: 5.151\n",
      "(Epoch 2059 / 10000) Train_Loss: 30.710; Val_Loss: 911.887   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.358; Val_NMI: 4.619\n",
      "(Epoch 2060 / 10000) Train_Loss: 30.589; Val_Loss: 920.150   Train_ACC: 14.909; Val_ACC: 21.111   Train_NMI: 0.409; Val_NMI: 5.032\n",
      "(Epoch 2061 / 10000) Train_Loss: 29.704; Val_Loss: 968.127   Train_ACC: 15.157; Val_ACC: 20.741   Train_NMI: 0.443; Val_NMI: 5.269\n",
      "(Epoch 2062 / 10000) Train_Loss: 30.524; Val_Loss: 945.519   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.426; Val_NMI: 5.335\n",
      "(Epoch 2063 / 10000) Train_Loss: 29.368; Val_Loss: 901.887   Train_ACC: 15.157; Val_ACC: 21.852   Train_NMI: 0.414; Val_NMI: 5.267\n",
      "(Epoch 2064 / 10000) Train_Loss: 29.707; Val_Loss: 853.236   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.402; Val_NMI: 4.920\n",
      "(Epoch 2065 / 10000) Train_Loss: 33.512; Val_Loss: 896.743   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.357; Val_NMI: 5.024\n",
      "(Epoch 2066 / 10000) Train_Loss: 33.576; Val_Loss: 842.468   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.365; Val_NMI: 5.497\n",
      "(Epoch 2067 / 10000) Train_Loss: 33.525; Val_Loss: 913.987   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.418; Val_NMI: 4.818\n",
      "(Epoch 2068 / 10000) Train_Loss: 30.885; Val_Loss: 880.392   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.451; Val_NMI: 4.510\n",
      "(Epoch 2069 / 10000) Train_Loss: 28.913; Val_Loss: 852.055   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.859\n",
      "(Epoch 2070 / 10000) Train_Loss: 29.126; Val_Loss: 860.183   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.427; Val_NMI: 4.736\n",
      "(Epoch 2071 / 10000) Train_Loss: 28.656; Val_Loss: 915.021   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.450; Val_NMI: 4.798\n",
      "(Epoch 2072 / 10000) Train_Loss: 28.807; Val_Loss: 816.034   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.427; Val_NMI: 4.497\n",
      "(Epoch 2073 / 10000) Train_Loss: 27.780; Val_Loss: 856.937   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 5.156\n",
      "(Epoch 2074 / 10000) Train_Loss: 28.097; Val_Loss: 855.071   Train_ACC: 14.868; Val_ACC: 21.111   Train_NMI: 0.381; Val_NMI: 4.918\n",
      "(Epoch 2075 / 10000) Train_Loss: 29.549; Val_Loss: 887.350   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 4.539\n",
      "(Epoch 2076 / 10000) Train_Loss: 30.461; Val_Loss: 876.860   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.423\n",
      "(Epoch 2077 / 10000) Train_Loss: 29.545; Val_Loss: 877.422   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.372; Val_NMI: 4.800\n",
      "(Epoch 2078 / 10000) Train_Loss: 28.433; Val_Loss: 922.766   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 4.672\n",
      "(Epoch 2079 / 10000) Train_Loss: 28.073; Val_Loss: 939.082   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.398; Val_NMI: 5.312\n",
      "(Epoch 2080 / 10000) Train_Loss: 29.403; Val_Loss: 894.266   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.376; Val_NMI: 4.697\n",
      "(Epoch 2081 / 10000) Train_Loss: 29.199; Val_Loss: 888.907   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.344; Val_NMI: 4.878\n",
      "(Epoch 2082 / 10000) Train_Loss: 28.210; Val_Loss: 955.506   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.352; Val_NMI: 4.764\n",
      "(Epoch 2083 / 10000) Train_Loss: 27.723; Val_Loss: 899.327   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.392; Val_NMI: 4.615\n",
      "(Epoch 2084 / 10000) Train_Loss: 28.119; Val_Loss: 850.380   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.402; Val_NMI: 4.875\n",
      "(Epoch 2085 / 10000) Train_Loss: 27.316; Val_Loss: 868.958   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.534\n",
      "(Epoch 2086 / 10000) Train_Loss: 28.342; Val_Loss: 864.339   Train_ACC: 14.662; Val_ACC: 21.111   Train_NMI: 0.347; Val_NMI: 5.021\n",
      "(Epoch 2087 / 10000) Train_Loss: 28.990; Val_Loss: 902.432   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 4.446\n",
      "(Epoch 2088 / 10000) Train_Loss: 28.186; Val_Loss: 905.427   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.472\n",
      "(Epoch 2089 / 10000) Train_Loss: 28.158; Val_Loss: 954.375   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 4.751\n",
      "(Epoch 2090 / 10000) Train_Loss: 30.032; Val_Loss: 853.714   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.324; Val_NMI: 4.205\n",
      "(Epoch 2091 / 10000) Train_Loss: 31.063; Val_Loss: 874.205   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 4.554\n",
      "(Epoch 2092 / 10000) Train_Loss: 28.747; Val_Loss: 863.779   Train_ACC: 14.662; Val_ACC: 20.741   Train_NMI: 0.381; Val_NMI: 4.966\n",
      "(Epoch 2093 / 10000) Train_Loss: 28.197; Val_Loss: 840.457   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.377; Val_NMI: 5.352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2094 / 10000) Train_Loss: 28.165; Val_Loss: 914.446   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.703\n",
      "(Epoch 2095 / 10000) Train_Loss: 28.179; Val_Loss: 851.446   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.409; Val_NMI: 4.716\n",
      "(Epoch 2096 / 10000) Train_Loss: 32.427; Val_Loss: 895.738   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.368; Val_NMI: 5.617\n",
      "(Epoch 2097 / 10000) Train_Loss: 30.924; Val_Loss: 872.031   Train_ACC: 15.115; Val_ACC: 21.111   Train_NMI: 0.412; Val_NMI: 5.240\n",
      "(Epoch 2098 / 10000) Train_Loss: 28.575; Val_Loss: 899.999   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.423; Val_NMI: 4.909\n",
      "(Epoch 2099 / 10000) Train_Loss: 28.723; Val_Loss: 913.234   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.440; Val_NMI: 4.975\n",
      "(Epoch 2100 / 10000) Train_Loss: 28.619; Val_Loss: 918.362   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 5.385\n",
      "(Epoch 2101 / 10000) Train_Loss: 29.316; Val_Loss: 913.285   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.385; Val_NMI: 5.036\n",
      "(Epoch 2102 / 10000) Train_Loss: 28.287; Val_Loss: 878.937   Train_ACC: 14.992; Val_ACC: 20.741   Train_NMI: 0.430; Val_NMI: 4.930\n",
      "(Epoch 2103 / 10000) Train_Loss: 28.652; Val_Loss: 891.963   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.325; Val_NMI: 4.800\n",
      "(Epoch 2104 / 10000) Train_Loss: 28.491; Val_Loss: 920.054   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.388; Val_NMI: 5.035\n",
      "(Epoch 2105 / 10000) Train_Loss: 29.471; Val_Loss: 904.108   Train_ACC: 15.115; Val_ACC: 21.111   Train_NMI: 0.397; Val_NMI: 5.695\n",
      "(Epoch 2106 / 10000) Train_Loss: 29.103; Val_Loss: 920.534   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.694\n",
      "(Epoch 2107 / 10000) Train_Loss: 30.454; Val_Loss: 902.450   Train_ACC: 14.992; Val_ACC: 21.111   Train_NMI: 0.411; Val_NMI: 5.238\n",
      "(Epoch 2108 / 10000) Train_Loss: 31.864; Val_Loss: 935.848   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.378; Val_NMI: 4.301\n",
      "(Epoch 2109 / 10000) Train_Loss: 29.661; Val_Loss: 958.188   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 5.097\n",
      "(Epoch 2110 / 10000) Train_Loss: 31.394; Val_Loss: 900.623   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.873\n",
      "(Epoch 2111 / 10000) Train_Loss: 29.451; Val_Loss: 871.856   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 4.920\n",
      "(Epoch 2112 / 10000) Train_Loss: 28.836; Val_Loss: 872.557   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.432; Val_NMI: 5.142\n",
      "(Epoch 2113 / 10000) Train_Loss: 29.267; Val_Loss: 908.551   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.701\n",
      "(Epoch 2114 / 10000) Train_Loss: 29.563; Val_Loss: 892.175   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.393; Val_NMI: 4.372\n",
      "(Epoch 2115 / 10000) Train_Loss: 28.715; Val_Loss: 884.847   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.447; Val_NMI: 4.833\n",
      "(Epoch 2116 / 10000) Train_Loss: 28.165; Val_Loss: 903.718   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.397; Val_NMI: 4.805\n",
      "(Epoch 2117 / 10000) Train_Loss: 28.988; Val_Loss: 920.322   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.422; Val_NMI: 4.551\n",
      "(Epoch 2118 / 10000) Train_Loss: 31.992; Val_Loss: 894.473   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.440; Val_NMI: 3.996\n",
      "(Epoch 2119 / 10000) Train_Loss: 30.342; Val_Loss: 894.018   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.718\n",
      "(Epoch 2120 / 10000) Train_Loss: 28.392; Val_Loss: 918.511   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.348; Val_NMI: 5.185\n",
      "(Epoch 2121 / 10000) Train_Loss: 28.693; Val_Loss: 888.926   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.386\n",
      "(Epoch 2122 / 10000) Train_Loss: 28.153; Val_Loss: 848.676   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.364\n",
      "(Epoch 2123 / 10000) Train_Loss: 28.213; Val_Loss: 842.332   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.315; Val_NMI: 4.053\n",
      "(Epoch 2124 / 10000) Train_Loss: 28.248; Val_Loss: 924.312   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.387; Val_NMI: 4.926\n",
      "(Epoch 2125 / 10000) Train_Loss: 30.580; Val_Loss: 890.595   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.342; Val_NMI: 4.630\n",
      "(Epoch 2126 / 10000) Train_Loss: 29.802; Val_Loss: 901.071   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 4.517\n",
      "(Epoch 2127 / 10000) Train_Loss: 30.006; Val_Loss: 904.159   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 4.697\n",
      "(Epoch 2128 / 10000) Train_Loss: 29.357; Val_Loss: 911.016   Train_ACC: 14.745; Val_ACC: 21.111   Train_NMI: 0.355; Val_NMI: 4.973\n",
      "(Epoch 2129 / 10000) Train_Loss: 30.306; Val_Loss: 897.350   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.402; Val_NMI: 5.034\n",
      "(Epoch 2130 / 10000) Train_Loss: 29.914; Val_Loss: 924.560   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.379; Val_NMI: 5.680\n",
      "(Epoch 2131 / 10000) Train_Loss: 31.252; Val_Loss: 881.148   Train_ACC: 14.662; Val_ACC: 21.481   Train_NMI: 0.357; Val_NMI: 5.570\n",
      "(Epoch 2132 / 10000) Train_Loss: 29.620; Val_Loss: 899.483   Train_ACC: 14.786; Val_ACC: 21.111   Train_NMI: 0.327; Val_NMI: 4.710\n",
      "(Epoch 2133 / 10000) Train_Loss: 28.331; Val_Loss: 845.593   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.369; Val_NMI: 4.567\n",
      "(Epoch 2134 / 10000) Train_Loss: 27.177; Val_Loss: 922.459   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.548\n",
      "(Epoch 2135 / 10000) Train_Loss: 27.745; Val_Loss: 903.738   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.449; Val_NMI: 4.144\n",
      "(Epoch 2136 / 10000) Train_Loss: 29.569; Val_Loss: 884.961   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.438; Val_NMI: 4.679\n",
      "(Epoch 2137 / 10000) Train_Loss: 28.544; Val_Loss: 934.835   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.420; Val_NMI: 4.592\n",
      "(Epoch 2138 / 10000) Train_Loss: 29.649; Val_Loss: 896.474   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.369; Val_NMI: 4.243\n",
      "(Epoch 2139 / 10000) Train_Loss: 28.273; Val_Loss: 870.099   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.410; Val_NMI: 4.654\n",
      "(Epoch 2140 / 10000) Train_Loss: 28.993; Val_Loss: 894.749   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 4.889\n",
      "(Epoch 2141 / 10000) Train_Loss: 28.805; Val_Loss: 907.232   Train_ACC: 14.868; Val_ACC: 20.741   Train_NMI: 0.449; Val_NMI: 4.409\n",
      "(Epoch 2142 / 10000) Train_Loss: 29.006; Val_Loss: 940.444   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.348; Val_NMI: 4.427\n",
      "(Epoch 2143 / 10000) Train_Loss: 30.174; Val_Loss: 885.196   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 3.878\n",
      "(Epoch 2144 / 10000) Train_Loss: 28.818; Val_Loss: 877.480   Train_ACC: 14.580; Val_ACC: 21.111   Train_NMI: 0.294; Val_NMI: 5.801\n",
      "(Epoch 2145 / 10000) Train_Loss: 27.541; Val_Loss: 934.193   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.421; Val_NMI: 4.595\n",
      "(Epoch 2146 / 10000) Train_Loss: 28.402; Val_Loss: 905.877   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.374; Val_NMI: 4.231\n",
      "(Epoch 2147 / 10000) Train_Loss: 28.606; Val_Loss: 888.657   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 4.561\n",
      "(Epoch 2148 / 10000) Train_Loss: 30.433; Val_Loss: 953.438   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.517\n",
      "(Epoch 2149 / 10000) Train_Loss: 29.119; Val_Loss: 906.905   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.335; Val_NMI: 4.348\n",
      "(Epoch 2150 / 10000) Train_Loss: 28.603; Val_Loss: 885.326   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.365; Val_NMI: 4.333\n",
      "(Epoch 2151 / 10000) Train_Loss: 28.888; Val_Loss: 892.704   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 4.687\n",
      "(Epoch 2152 / 10000) Train_Loss: 29.286; Val_Loss: 893.855   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 4.702\n",
      "(Epoch 2153 / 10000) Train_Loss: 29.403; Val_Loss: 896.880   Train_ACC: 14.909; Val_ACC: 21.481   Train_NMI: 0.418; Val_NMI: 5.138\n",
      "(Epoch 2154 / 10000) Train_Loss: 28.728; Val_Loss: 934.697   Train_ACC: 14.662; Val_ACC: 22.593   Train_NMI: 0.334; Val_NMI: 5.391\n",
      "(Epoch 2155 / 10000) Train_Loss: 28.314; Val_Loss: 889.758   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.059\n",
      "(Epoch 2156 / 10000) Train_Loss: 27.999; Val_Loss: 874.053   Train_ACC: 14.951; Val_ACC: 21.111   Train_NMI: 0.418; Val_NMI: 5.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2157 / 10000) Train_Loss: 29.547; Val_Loss: 872.235   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.399; Val_NMI: 5.288\n",
      "(Epoch 2158 / 10000) Train_Loss: 29.783; Val_Loss: 939.215   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.634\n",
      "(Epoch 2159 / 10000) Train_Loss: 28.658; Val_Loss: 915.207   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.644\n",
      "(Epoch 2160 / 10000) Train_Loss: 29.114; Val_Loss: 946.165   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.347; Val_NMI: 4.379\n",
      "(Epoch 2161 / 10000) Train_Loss: 30.272; Val_Loss: 857.823   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.858\n",
      "(Epoch 2162 / 10000) Train_Loss: 35.213; Val_Loss: 910.036   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 3.231\n",
      "(Epoch 2163 / 10000) Train_Loss: 35.143; Val_Loss: 875.136   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.402; Val_NMI: 4.016\n",
      "(Epoch 2164 / 10000) Train_Loss: 36.421; Val_Loss: 856.200   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 4.031\n",
      "(Epoch 2165 / 10000) Train_Loss: 34.652; Val_Loss: 937.618   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.420; Val_NMI: 3.287\n",
      "(Epoch 2166 / 10000) Train_Loss: 35.749; Val_Loss: 908.748   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 3.600\n",
      "(Epoch 2167 / 10000) Train_Loss: 33.989; Val_Loss: 910.425   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.373; Val_NMI: 3.067\n",
      "(Epoch 2168 / 10000) Train_Loss: 32.713; Val_Loss: 844.693   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 3.954\n",
      "(Epoch 2169 / 10000) Train_Loss: 29.532; Val_Loss: 861.505   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.432; Val_NMI: 3.828\n",
      "(Epoch 2170 / 10000) Train_Loss: 29.315; Val_Loss: 848.391   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.410; Val_NMI: 3.356\n",
      "(Epoch 2171 / 10000) Train_Loss: 28.555; Val_Loss: 899.193   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.485; Val_NMI: 3.745\n",
      "(Epoch 2172 / 10000) Train_Loss: 28.933; Val_Loss: 886.596   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.440; Val_NMI: 3.559\n",
      "(Epoch 2173 / 10000) Train_Loss: 28.647; Val_Loss: 875.893   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.468; Val_NMI: 3.264\n",
      "(Epoch 2174 / 10000) Train_Loss: 29.925; Val_Loss: 914.259   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.417; Val_NMI: 3.363\n",
      "(Epoch 2175 / 10000) Train_Loss: 28.467; Val_Loss: 913.016   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.406; Val_NMI: 3.010\n",
      "(Epoch 2176 / 10000) Train_Loss: 28.622; Val_Loss: 875.524   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.395; Val_NMI: 3.110\n",
      "(Epoch 2177 / 10000) Train_Loss: 28.709; Val_Loss: 856.174   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.406; Val_NMI: 4.119\n",
      "(Epoch 2178 / 10000) Train_Loss: 29.407; Val_Loss: 919.986   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 3.868\n",
      "(Epoch 2179 / 10000) Train_Loss: 29.191; Val_Loss: 889.226   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.463; Val_NMI: 3.479\n",
      "(Epoch 2180 / 10000) Train_Loss: 30.564; Val_Loss: 914.366   Train_ACC: 14.909; Val_ACC: 17.778   Train_NMI: 0.403; Val_NMI: 2.963\n",
      "(Epoch 2181 / 10000) Train_Loss: 30.032; Val_Loss: 853.397   Train_ACC: 15.321; Val_ACC: 18.889   Train_NMI: 0.440; Val_NMI: 3.842\n",
      "(Epoch 2182 / 10000) Train_Loss: 28.042; Val_Loss: 887.733   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.451; Val_NMI: 3.950\n",
      "(Epoch 2183 / 10000) Train_Loss: 30.081; Val_Loss: 891.270   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.227\n",
      "(Epoch 2184 / 10000) Train_Loss: 29.632; Val_Loss: 863.424   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 3.795\n",
      "(Epoch 2185 / 10000) Train_Loss: 30.028; Val_Loss: 844.434   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.422; Val_NMI: 3.700\n",
      "(Epoch 2186 / 10000) Train_Loss: 28.923; Val_Loss: 860.428   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 3.241\n",
      "(Epoch 2187 / 10000) Train_Loss: 28.964; Val_Loss: 899.737   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.429; Val_NMI: 3.931\n",
      "(Epoch 2188 / 10000) Train_Loss: 29.042; Val_Loss: 939.805   Train_ACC: 15.321; Val_ACC: 19.259   Train_NMI: 0.425; Val_NMI: 4.392\n",
      "(Epoch 2189 / 10000) Train_Loss: 28.601; Val_Loss: 911.056   Train_ACC: 15.280; Val_ACC: 19.259   Train_NMI: 0.426; Val_NMI: 3.192\n",
      "(Epoch 2190 / 10000) Train_Loss: 28.137; Val_Loss: 883.406   Train_ACC: 15.404; Val_ACC: 19.259   Train_NMI: 0.432; Val_NMI: 4.311\n",
      "(Epoch 2191 / 10000) Train_Loss: 28.659; Val_Loss: 893.081   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.442; Val_NMI: 3.980\n",
      "(Epoch 2192 / 10000) Train_Loss: 28.759; Val_Loss: 900.759   Train_ACC: 15.280; Val_ACC: 20.000   Train_NMI: 0.459; Val_NMI: 3.969\n",
      "(Epoch 2193 / 10000) Train_Loss: 28.821; Val_Loss: 905.069   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.400; Val_NMI: 4.017\n",
      "(Epoch 2194 / 10000) Train_Loss: 32.013; Val_Loss: 892.076   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.313; Val_NMI: 3.722\n",
      "(Epoch 2195 / 10000) Train_Loss: 32.528; Val_Loss: 879.847   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 3.977\n",
      "(Epoch 2196 / 10000) Train_Loss: 30.926; Val_Loss: 942.582   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.341\n",
      "(Epoch 2197 / 10000) Train_Loss: 29.184; Val_Loss: 838.156   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.768\n",
      "(Epoch 2198 / 10000) Train_Loss: 28.453; Val_Loss: 847.809   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.277\n",
      "(Epoch 2199 / 10000) Train_Loss: 29.258; Val_Loss: 919.251   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.335; Val_NMI: 4.243\n",
      "(Epoch 2200 / 10000) Train_Loss: 28.309; Val_Loss: 916.253   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.193\n",
      "(Epoch 2201 / 10000) Train_Loss: 28.545; Val_Loss: 920.688   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.325\n",
      "(Epoch 2202 / 10000) Train_Loss: 30.040; Val_Loss: 866.346   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.422; Val_NMI: 3.798\n",
      "(Epoch 2203 / 10000) Train_Loss: 28.501; Val_Loss: 861.667   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.085\n",
      "(Epoch 2204 / 10000) Train_Loss: 29.142; Val_Loss: 923.919   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 4.305\n",
      "(Epoch 2205 / 10000) Train_Loss: 31.048; Val_Loss: 853.220   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.218\n",
      "(Epoch 2206 / 10000) Train_Loss: 28.918; Val_Loss: 895.731   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 4.323\n",
      "(Epoch 2207 / 10000) Train_Loss: 28.809; Val_Loss: 853.072   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.872\n",
      "(Epoch 2208 / 10000) Train_Loss: 28.816; Val_Loss: 887.556   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.173\n",
      "(Epoch 2209 / 10000) Train_Loss: 28.122; Val_Loss: 878.882   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.347; Val_NMI: 3.861\n",
      "(Epoch 2210 / 10000) Train_Loss: 28.632; Val_Loss: 862.319   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.311; Val_NMI: 4.029\n",
      "(Epoch 2211 / 10000) Train_Loss: 28.380; Val_Loss: 898.533   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.339; Val_NMI: 4.513\n",
      "(Epoch 2212 / 10000) Train_Loss: 28.416; Val_Loss: 901.960   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.283; Val_NMI: 4.324\n",
      "(Epoch 2213 / 10000) Train_Loss: 29.372; Val_Loss: 922.206   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.349\n",
      "(Epoch 2214 / 10000) Train_Loss: 29.085; Val_Loss: 914.252   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.306; Val_NMI: 4.521\n",
      "(Epoch 2215 / 10000) Train_Loss: 30.579; Val_Loss: 868.909   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.275\n",
      "(Epoch 2216 / 10000) Train_Loss: 28.935; Val_Loss: 820.426   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.348; Val_NMI: 4.822\n",
      "(Epoch 2217 / 10000) Train_Loss: 29.188; Val_Loss: 949.089   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.425; Val_NMI: 3.786\n",
      "(Epoch 2218 / 10000) Train_Loss: 29.570; Val_Loss: 884.081   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.027\n",
      "(Epoch 2219 / 10000) Train_Loss: 28.961; Val_Loss: 860.921   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 4.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2220 / 10000) Train_Loss: 29.169; Val_Loss: 864.741   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.025\n",
      "(Epoch 2221 / 10000) Train_Loss: 28.874; Val_Loss: 888.213   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.171\n",
      "(Epoch 2222 / 10000) Train_Loss: 28.575; Val_Loss: 865.575   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 3.858\n",
      "(Epoch 2223 / 10000) Train_Loss: 29.860; Val_Loss: 857.693   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.376; Val_NMI: 3.818\n",
      "(Epoch 2224 / 10000) Train_Loss: 29.519; Val_Loss: 903.901   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.155\n",
      "(Epoch 2225 / 10000) Train_Loss: 31.928; Val_Loss: 889.305   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.081\n",
      "(Epoch 2226 / 10000) Train_Loss: 30.892; Val_Loss: 900.330   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.987\n",
      "(Epoch 2227 / 10000) Train_Loss: 31.511; Val_Loss: 937.472   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.148\n",
      "(Epoch 2228 / 10000) Train_Loss: 33.816; Val_Loss: 881.061   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.338; Val_NMI: 4.194\n",
      "(Epoch 2229 / 10000) Train_Loss: 31.601; Val_Loss: 902.513   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.974\n",
      "(Epoch 2230 / 10000) Train_Loss: 29.293; Val_Loss: 848.575   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.393; Val_NMI: 4.484\n",
      "(Epoch 2231 / 10000) Train_Loss: 29.965; Val_Loss: 882.358   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.411; Val_NMI: 4.141\n",
      "(Epoch 2232 / 10000) Train_Loss: 28.027; Val_Loss: 910.261   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.373\n",
      "(Epoch 2233 / 10000) Train_Loss: 28.018; Val_Loss: 891.910   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.526\n",
      "(Epoch 2234 / 10000) Train_Loss: 28.835; Val_Loss: 843.914   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 3.460\n",
      "(Epoch 2235 / 10000) Train_Loss: 28.937; Val_Loss: 902.746   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 3.910\n",
      "(Epoch 2236 / 10000) Train_Loss: 27.963; Val_Loss: 875.988   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.396; Val_NMI: 4.621\n",
      "(Epoch 2237 / 10000) Train_Loss: 28.324; Val_Loss: 885.506   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.314; Val_NMI: 4.100\n",
      "(Epoch 2238 / 10000) Train_Loss: 28.186; Val_Loss: 893.531   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.135\n",
      "(Epoch 2239 / 10000) Train_Loss: 28.035; Val_Loss: 887.737   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.428; Val_NMI: 4.673\n",
      "(Epoch 2240 / 10000) Train_Loss: 28.532; Val_Loss: 868.592   Train_ACC: 14.498; Val_ACC: 20.000   Train_NMI: 0.316; Val_NMI: 4.382\n",
      "(Epoch 2241 / 10000) Train_Loss: 27.882; Val_Loss: 874.729   Train_ACC: 14.456; Val_ACC: 19.259   Train_NMI: 0.286; Val_NMI: 4.079\n",
      "(Epoch 2242 / 10000) Train_Loss: 28.711; Val_Loss: 900.818   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.301; Val_NMI: 3.963\n",
      "(Epoch 2243 / 10000) Train_Loss: 28.125; Val_Loss: 922.962   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 3.549\n",
      "(Epoch 2244 / 10000) Train_Loss: 29.470; Val_Loss: 904.376   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.398; Val_NMI: 4.216\n",
      "(Epoch 2245 / 10000) Train_Loss: 29.360; Val_Loss: 924.358   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 3.806\n",
      "(Epoch 2246 / 10000) Train_Loss: 28.608; Val_Loss: 915.480   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.532\n",
      "(Epoch 2247 / 10000) Train_Loss: 28.383; Val_Loss: 927.624   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.291; Val_NMI: 3.785\n",
      "(Epoch 2248 / 10000) Train_Loss: 29.994; Val_Loss: 913.322   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.299; Val_NMI: 4.195\n",
      "(Epoch 2249 / 10000) Train_Loss: 28.666; Val_Loss: 872.695   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.356\n",
      "(Epoch 2250 / 10000) Train_Loss: 29.680; Val_Loss: 883.240   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.302; Val_NMI: 4.206\n",
      "(Epoch 2251 / 10000) Train_Loss: 28.154; Val_Loss: 915.636   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.314; Val_NMI: 4.011\n",
      "(Epoch 2252 / 10000) Train_Loss: 29.291; Val_Loss: 881.295   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.313; Val_NMI: 4.611\n",
      "(Epoch 2253 / 10000) Train_Loss: 30.014; Val_Loss: 920.353   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.290; Val_NMI: 4.172\n",
      "(Epoch 2254 / 10000) Train_Loss: 28.405; Val_Loss: 902.566   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.302; Val_NMI: 4.606\n",
      "(Epoch 2255 / 10000) Train_Loss: 28.152; Val_Loss: 938.260   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 4.768\n",
      "(Epoch 2256 / 10000) Train_Loss: 28.998; Val_Loss: 903.288   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 3.594\n",
      "(Epoch 2257 / 10000) Train_Loss: 28.672; Val_Loss: 893.392   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 4.402\n",
      "(Epoch 2258 / 10000) Train_Loss: 28.641; Val_Loss: 847.149   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 4.311\n",
      "(Epoch 2259 / 10000) Train_Loss: 28.595; Val_Loss: 882.267   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.267\n",
      "(Epoch 2260 / 10000) Train_Loss: 28.455; Val_Loss: 927.707   Train_ACC: 14.292; Val_ACC: 19.259   Train_NMI: 0.270; Val_NMI: 4.347\n",
      "(Epoch 2261 / 10000) Train_Loss: 29.966; Val_Loss: 863.568   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 4.072\n",
      "(Epoch 2262 / 10000) Train_Loss: 30.528; Val_Loss: 915.286   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.403\n",
      "(Epoch 2263 / 10000) Train_Loss: 31.150; Val_Loss: 907.207   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 4.773\n",
      "(Epoch 2264 / 10000) Train_Loss: 31.528; Val_Loss: 905.850   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.333; Val_NMI: 4.412\n",
      "(Epoch 2265 / 10000) Train_Loss: 33.454; Val_Loss: 879.714   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 4.500\n",
      "(Epoch 2266 / 10000) Train_Loss: 36.574; Val_Loss: 887.112   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.618\n",
      "(Epoch 2267 / 10000) Train_Loss: 36.799; Val_Loss: 874.540   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.403; Val_NMI: 3.533\n",
      "(Epoch 2268 / 10000) Train_Loss: 31.347; Val_Loss: 923.249   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.374; Val_NMI: 3.750\n",
      "(Epoch 2269 / 10000) Train_Loss: 28.962; Val_Loss: 947.387   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 3.953\n",
      "(Epoch 2270 / 10000) Train_Loss: 28.080; Val_Loss: 924.721   Train_ACC: 15.033; Val_ACC: 18.519   Train_NMI: 0.407; Val_NMI: 3.407\n",
      "(Epoch 2271 / 10000) Train_Loss: 27.949; Val_Loss: 867.063   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.186\n",
      "(Epoch 2272 / 10000) Train_Loss: 28.970; Val_Loss: 868.480   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.354; Val_NMI: 3.675\n",
      "(Epoch 2273 / 10000) Train_Loss: 31.526; Val_Loss: 944.261   Train_ACC: 14.786; Val_ACC: 18.148   Train_NMI: 0.374; Val_NMI: 3.759\n",
      "(Epoch 2274 / 10000) Train_Loss: 30.735; Val_Loss: 900.423   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.301; Val_NMI: 4.065\n",
      "(Epoch 2275 / 10000) Train_Loss: 29.765; Val_Loss: 888.742   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.297; Val_NMI: 4.142\n",
      "(Epoch 2276 / 10000) Train_Loss: 28.079; Val_Loss: 862.379   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.106\n",
      "(Epoch 2277 / 10000) Train_Loss: 27.876; Val_Loss: 895.748   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.009\n",
      "(Epoch 2278 / 10000) Train_Loss: 28.354; Val_Loss: 864.569   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 4.563\n",
      "(Epoch 2279 / 10000) Train_Loss: 27.962; Val_Loss: 928.104   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.179\n",
      "(Epoch 2280 / 10000) Train_Loss: 29.204; Val_Loss: 909.571   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 3.506\n",
      "(Epoch 2281 / 10000) Train_Loss: 28.226; Val_Loss: 879.488   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.137\n",
      "(Epoch 2282 / 10000) Train_Loss: 27.742; Val_Loss: 927.682   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2283 / 10000) Train_Loss: 27.600; Val_Loss: 876.733   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.473\n",
      "(Epoch 2284 / 10000) Train_Loss: 27.770; Val_Loss: 893.386   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.307; Val_NMI: 4.649\n",
      "(Epoch 2285 / 10000) Train_Loss: 28.451; Val_Loss: 938.608   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.155\n",
      "(Epoch 2286 / 10000) Train_Loss: 28.060; Val_Loss: 918.937   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 4.412\n",
      "(Epoch 2287 / 10000) Train_Loss: 28.068; Val_Loss: 954.696   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.406; Val_NMI: 3.870\n",
      "(Epoch 2288 / 10000) Train_Loss: 28.998; Val_Loss: 869.833   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 4.748\n",
      "(Epoch 2289 / 10000) Train_Loss: 30.265; Val_Loss: 911.567   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.508\n",
      "(Epoch 2290 / 10000) Train_Loss: 28.707; Val_Loss: 958.579   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 3.965\n",
      "(Epoch 2291 / 10000) Train_Loss: 28.455; Val_Loss: 852.311   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.423; Val_NMI: 4.348\n",
      "(Epoch 2292 / 10000) Train_Loss: 29.380; Val_Loss: 916.815   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.186\n",
      "(Epoch 2293 / 10000) Train_Loss: 29.346; Val_Loss: 891.904   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.733\n",
      "(Epoch 2294 / 10000) Train_Loss: 28.002; Val_Loss: 885.249   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.887\n",
      "(Epoch 2295 / 10000) Train_Loss: 30.130; Val_Loss: 1000.035   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.174\n",
      "(Epoch 2296 / 10000) Train_Loss: 28.900; Val_Loss: 901.262   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 4.097\n",
      "(Epoch 2297 / 10000) Train_Loss: 29.713; Val_Loss: 882.400   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.316; Val_NMI: 5.279\n",
      "(Epoch 2298 / 10000) Train_Loss: 30.357; Val_Loss: 915.988   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 5.417\n",
      "(Epoch 2299 / 10000) Train_Loss: 31.060; Val_Loss: 880.816   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.324; Val_NMI: 4.544\n",
      "(Epoch 2300 / 10000) Train_Loss: 34.086; Val_Loss: 928.971   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.467\n",
      "(Epoch 2301 / 10000) Train_Loss: 31.571; Val_Loss: 917.191   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.071\n",
      "(Epoch 2302 / 10000) Train_Loss: 29.511; Val_Loss: 889.448   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.287\n",
      "(Epoch 2303 / 10000) Train_Loss: 28.934; Val_Loss: 909.667   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.600\n",
      "(Epoch 2304 / 10000) Train_Loss: 29.718; Val_Loss: 890.114   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.123\n",
      "(Epoch 2305 / 10000) Train_Loss: 28.475; Val_Loss: 921.904   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.205\n",
      "(Epoch 2306 / 10000) Train_Loss: 29.184; Val_Loss: 923.104   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.273; Val_NMI: 4.866\n",
      "(Epoch 2307 / 10000) Train_Loss: 30.232; Val_Loss: 879.297   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.305; Val_NMI: 3.699\n",
      "(Epoch 2308 / 10000) Train_Loss: 30.175; Val_Loss: 879.717   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 3.964\n",
      "(Epoch 2309 / 10000) Train_Loss: 30.020; Val_Loss: 1012.151   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 3.579\n",
      "(Epoch 2310 / 10000) Train_Loss: 29.126; Val_Loss: 881.643   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 3.797\n",
      "(Epoch 2311 / 10000) Train_Loss: 28.925; Val_Loss: 933.758   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.010\n",
      "(Epoch 2312 / 10000) Train_Loss: 29.330; Val_Loss: 911.722   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.309; Val_NMI: 4.163\n",
      "(Epoch 2313 / 10000) Train_Loss: 28.204; Val_Loss: 911.275   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.314; Val_NMI: 4.215\n",
      "(Epoch 2314 / 10000) Train_Loss: 27.456; Val_Loss: 876.308   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 3.807\n",
      "(Epoch 2315 / 10000) Train_Loss: 28.905; Val_Loss: 914.442   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.266\n",
      "(Epoch 2316 / 10000) Train_Loss: 29.294; Val_Loss: 892.930   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.275\n",
      "(Epoch 2317 / 10000) Train_Loss: 28.469; Val_Loss: 936.740   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 4.662\n",
      "(Epoch 2318 / 10000) Train_Loss: 27.168; Val_Loss: 838.559   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.175\n",
      "(Epoch 2319 / 10000) Train_Loss: 28.528; Val_Loss: 860.571   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 4.044\n",
      "(Epoch 2320 / 10000) Train_Loss: 28.307; Val_Loss: 932.313   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.536\n",
      "(Epoch 2321 / 10000) Train_Loss: 28.501; Val_Loss: 879.047   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 4.382\n",
      "(Epoch 2322 / 10000) Train_Loss: 28.896; Val_Loss: 869.105   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.412; Val_NMI: 4.598\n",
      "(Epoch 2323 / 10000) Train_Loss: 29.160; Val_Loss: 926.562   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.273\n",
      "(Epoch 2324 / 10000) Train_Loss: 28.716; Val_Loss: 942.363   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.308; Val_NMI: 4.384\n",
      "(Epoch 2325 / 10000) Train_Loss: 28.333; Val_Loss: 930.751   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.719\n",
      "(Epoch 2326 / 10000) Train_Loss: 27.805; Val_Loss: 941.722   Train_ACC: 14.827; Val_ACC: 20.741   Train_NMI: 0.359; Val_NMI: 4.682\n",
      "(Epoch 2327 / 10000) Train_Loss: 28.987; Val_Loss: 885.111   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.384\n",
      "(Epoch 2328 / 10000) Train_Loss: 31.613; Val_Loss: 880.592   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.650\n",
      "(Epoch 2329 / 10000) Train_Loss: 28.893; Val_Loss: 929.923   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 3.789\n",
      "(Epoch 2330 / 10000) Train_Loss: 30.468; Val_Loss: 968.687   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.402\n",
      "(Epoch 2331 / 10000) Train_Loss: 29.608; Val_Loss: 911.848   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.343; Val_NMI: 4.567\n",
      "(Epoch 2332 / 10000) Train_Loss: 28.481; Val_Loss: 912.446   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 4.517\n",
      "(Epoch 2333 / 10000) Train_Loss: 27.665; Val_Loss: 942.060   Train_ACC: 15.239; Val_ACC: 20.370   Train_NMI: 0.397; Val_NMI: 5.752\n",
      "(Epoch 2334 / 10000) Train_Loss: 27.718; Val_Loss: 902.668   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 4.184\n",
      "(Epoch 2335 / 10000) Train_Loss: 29.408; Val_Loss: 913.788   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.796\n",
      "(Epoch 2336 / 10000) Train_Loss: 27.969; Val_Loss: 932.761   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 4.019\n",
      "(Epoch 2337 / 10000) Train_Loss: 27.839; Val_Loss: 905.693   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.319\n",
      "(Epoch 2338 / 10000) Train_Loss: 27.816; Val_Loss: 911.916   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 3.864\n",
      "(Epoch 2339 / 10000) Train_Loss: 27.754; Val_Loss: 867.913   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.395; Val_NMI: 4.274\n",
      "(Epoch 2340 / 10000) Train_Loss: 28.211; Val_Loss: 906.963   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 5.142\n",
      "(Epoch 2341 / 10000) Train_Loss: 27.798; Val_Loss: 888.245   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 4.097\n",
      "(Epoch 2342 / 10000) Train_Loss: 30.051; Val_Loss: 914.090   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.360; Val_NMI: 4.183\n",
      "(Epoch 2343 / 10000) Train_Loss: 31.366; Val_Loss: 909.563   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.311\n",
      "(Epoch 2344 / 10000) Train_Loss: 34.055; Val_Loss: 881.452   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.307\n",
      "(Epoch 2345 / 10000) Train_Loss: 33.621; Val_Loss: 898.033   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 4.463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2346 / 10000) Train_Loss: 31.646; Val_Loss: 929.855   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.325; Val_NMI: 4.552\n",
      "(Epoch 2347 / 10000) Train_Loss: 32.754; Val_Loss: 962.363   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.789\n",
      "(Epoch 2348 / 10000) Train_Loss: 29.585; Val_Loss: 905.344   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.249\n",
      "(Epoch 2349 / 10000) Train_Loss: 27.513; Val_Loss: 934.097   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.398; Val_NMI: 3.781\n",
      "(Epoch 2350 / 10000) Train_Loss: 28.276; Val_Loss: 891.211   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 3.963\n",
      "(Epoch 2351 / 10000) Train_Loss: 27.986; Val_Loss: 887.332   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.312; Val_NMI: 4.218\n",
      "(Epoch 2352 / 10000) Train_Loss: 28.086; Val_Loss: 947.162   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.319; Val_NMI: 4.987\n",
      "(Epoch 2353 / 10000) Train_Loss: 27.789; Val_Loss: 957.520   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.677\n",
      "(Epoch 2354 / 10000) Train_Loss: 28.488; Val_Loss: 891.241   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.708\n",
      "(Epoch 2355 / 10000) Train_Loss: 30.275; Val_Loss: 928.039   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.569\n",
      "(Epoch 2356 / 10000) Train_Loss: 33.291; Val_Loss: 942.833   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.232\n",
      "(Epoch 2357 / 10000) Train_Loss: 31.704; Val_Loss: 927.871   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 5.076\n",
      "(Epoch 2358 / 10000) Train_Loss: 31.537; Val_Loss: 911.788   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.279\n",
      "(Epoch 2359 / 10000) Train_Loss: 28.263; Val_Loss: 907.988   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.597\n",
      "(Epoch 2360 / 10000) Train_Loss: 26.773; Val_Loss: 869.778   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.377; Val_NMI: 4.330\n",
      "(Epoch 2361 / 10000) Train_Loss: 28.805; Val_Loss: 914.362   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.314; Val_NMI: 4.166\n",
      "(Epoch 2362 / 10000) Train_Loss: 29.588; Val_Loss: 940.594   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.037\n",
      "(Epoch 2363 / 10000) Train_Loss: 27.469; Val_Loss: 893.360   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.029\n",
      "(Epoch 2364 / 10000) Train_Loss: 29.852; Val_Loss: 900.823   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.252\n",
      "(Epoch 2365 / 10000) Train_Loss: 29.991; Val_Loss: 945.172   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.240\n",
      "(Epoch 2366 / 10000) Train_Loss: 28.550; Val_Loss: 924.938   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.405; Val_NMI: 3.812\n",
      "(Epoch 2367 / 10000) Train_Loss: 28.332; Val_Loss: 889.172   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 3.787\n",
      "(Epoch 2368 / 10000) Train_Loss: 28.193; Val_Loss: 934.923   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 4.432\n",
      "(Epoch 2369 / 10000) Train_Loss: 28.366; Val_Loss: 849.771   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 4.705\n",
      "(Epoch 2370 / 10000) Train_Loss: 28.202; Val_Loss: 889.179   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.861\n",
      "(Epoch 2371 / 10000) Train_Loss: 28.088; Val_Loss: 897.059   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.207\n",
      "(Epoch 2372 / 10000) Train_Loss: 28.621; Val_Loss: 964.296   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.363; Val_NMI: 4.192\n",
      "(Epoch 2373 / 10000) Train_Loss: 28.554; Val_Loss: 918.186   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 3.679\n",
      "(Epoch 2374 / 10000) Train_Loss: 28.849; Val_Loss: 917.125   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 3.658\n",
      "(Epoch 2375 / 10000) Train_Loss: 29.050; Val_Loss: 911.653   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 4.757\n",
      "(Epoch 2376 / 10000) Train_Loss: 28.441; Val_Loss: 937.712   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.321; Val_NMI: 4.309\n",
      "(Epoch 2377 / 10000) Train_Loss: 30.445; Val_Loss: 934.706   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.352; Val_NMI: 4.910\n",
      "(Epoch 2378 / 10000) Train_Loss: 28.631; Val_Loss: 923.364   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 3.739\n",
      "(Epoch 2379 / 10000) Train_Loss: 28.282; Val_Loss: 958.213   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.173\n",
      "(Epoch 2380 / 10000) Train_Loss: 28.013; Val_Loss: 914.485   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 3.800\n",
      "(Epoch 2381 / 10000) Train_Loss: 28.091; Val_Loss: 876.074   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 4.056\n",
      "(Epoch 2382 / 10000) Train_Loss: 30.153; Val_Loss: 958.585   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.017\n",
      "(Epoch 2383 / 10000) Train_Loss: 28.988; Val_Loss: 956.182   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.377; Val_NMI: 3.673\n",
      "(Epoch 2384 / 10000) Train_Loss: 28.605; Val_Loss: 898.786   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 3.874\n",
      "(Epoch 2385 / 10000) Train_Loss: 29.124; Val_Loss: 910.426   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 4.285\n",
      "(Epoch 2386 / 10000) Train_Loss: 31.492; Val_Loss: 960.993   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.379; Val_NMI: 3.635\n",
      "(Epoch 2387 / 10000) Train_Loss: 29.896; Val_Loss: 926.360   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.400; Val_NMI: 4.082\n",
      "(Epoch 2388 / 10000) Train_Loss: 28.818; Val_Loss: 936.339   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.410; Val_NMI: 4.452\n",
      "(Epoch 2389 / 10000) Train_Loss: 29.086; Val_Loss: 936.592   Train_ACC: 14.580; Val_ACC: 18.519   Train_NMI: 0.335; Val_NMI: 4.215\n",
      "(Epoch 2390 / 10000) Train_Loss: 29.358; Val_Loss: 895.215   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.387; Val_NMI: 4.233\n",
      "(Epoch 2391 / 10000) Train_Loss: 28.341; Val_Loss: 890.275   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.367; Val_NMI: 3.871\n",
      "(Epoch 2392 / 10000) Train_Loss: 27.987; Val_Loss: 921.651   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.407; Val_NMI: 4.355\n",
      "(Epoch 2393 / 10000) Train_Loss: 27.767; Val_Loss: 944.561   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.492\n",
      "(Epoch 2394 / 10000) Train_Loss: 27.369; Val_Loss: 941.116   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.332\n",
      "(Epoch 2395 / 10000) Train_Loss: 28.810; Val_Loss: 870.457   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 4.034\n",
      "(Epoch 2396 / 10000) Train_Loss: 28.358; Val_Loss: 920.971   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.307\n",
      "(Epoch 2397 / 10000) Train_Loss: 28.038; Val_Loss: 915.816   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 4.544\n",
      "(Epoch 2398 / 10000) Train_Loss: 28.443; Val_Loss: 900.172   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.330\n",
      "(Epoch 2399 / 10000) Train_Loss: 28.660; Val_Loss: 929.085   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.381; Val_NMI: 4.647\n",
      "(Epoch 2400 / 10000) Train_Loss: 28.687; Val_Loss: 913.042   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.260\n",
      "(Epoch 2401 / 10000) Train_Loss: 28.511; Val_Loss: 929.648   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.355; Val_NMI: 3.788\n",
      "(Epoch 2402 / 10000) Train_Loss: 28.590; Val_Loss: 894.560   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.320; Val_NMI: 4.101\n",
      "(Epoch 2403 / 10000) Train_Loss: 29.659; Val_Loss: 981.296   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.339; Val_NMI: 3.989\n",
      "(Epoch 2404 / 10000) Train_Loss: 28.950; Val_Loss: 889.236   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.146\n",
      "(Epoch 2405 / 10000) Train_Loss: 30.732; Val_Loss: 930.549   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 3.969\n",
      "(Epoch 2406 / 10000) Train_Loss: 30.722; Val_Loss: 920.980   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 3.793\n",
      "(Epoch 2407 / 10000) Train_Loss: 29.705; Val_Loss: 896.844   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.378; Val_NMI: 4.186\n",
      "(Epoch 2408 / 10000) Train_Loss: 28.410; Val_Loss: 890.593   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2409 / 10000) Train_Loss: 28.816; Val_Loss: 921.920   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.603\n",
      "(Epoch 2410 / 10000) Train_Loss: 28.565; Val_Loss: 941.527   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.422\n",
      "(Epoch 2411 / 10000) Train_Loss: 28.149; Val_Loss: 950.939   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.411; Val_NMI: 4.006\n",
      "(Epoch 2412 / 10000) Train_Loss: 27.738; Val_Loss: 903.744   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.421; Val_NMI: 3.671\n",
      "(Epoch 2413 / 10000) Train_Loss: 27.799; Val_Loss: 902.682   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 3.518\n",
      "(Epoch 2414 / 10000) Train_Loss: 27.962; Val_Loss: 930.897   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.369; Val_NMI: 4.291\n",
      "(Epoch 2415 / 10000) Train_Loss: 28.654; Val_Loss: 918.497   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.349; Val_NMI: 4.580\n",
      "(Epoch 2416 / 10000) Train_Loss: 28.625; Val_Loss: 924.730   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.373\n",
      "(Epoch 2417 / 10000) Train_Loss: 28.157; Val_Loss: 915.866   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.405; Val_NMI: 4.720\n",
      "(Epoch 2418 / 10000) Train_Loss: 29.018; Val_Loss: 934.498   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.351; Val_NMI: 4.642\n",
      "(Epoch 2419 / 10000) Train_Loss: 30.397; Val_Loss: 945.116   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.334\n",
      "(Epoch 2420 / 10000) Train_Loss: 30.257; Val_Loss: 914.275   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.414\n",
      "(Epoch 2421 / 10000) Train_Loss: 32.121; Val_Loss: 922.636   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.373; Val_NMI: 4.354\n",
      "(Epoch 2422 / 10000) Train_Loss: 30.709; Val_Loss: 894.005   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 4.263\n",
      "(Epoch 2423 / 10000) Train_Loss: 28.631; Val_Loss: 853.369   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.196\n",
      "(Epoch 2424 / 10000) Train_Loss: 28.486; Val_Loss: 906.237   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 4.088\n",
      "(Epoch 2425 / 10000) Train_Loss: 31.711; Val_Loss: 918.342   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 4.296\n",
      "(Epoch 2426 / 10000) Train_Loss: 28.716; Val_Loss: 875.975   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.175\n",
      "(Epoch 2427 / 10000) Train_Loss: 27.413; Val_Loss: 875.832   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.043\n",
      "(Epoch 2428 / 10000) Train_Loss: 28.815; Val_Loss: 944.675   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 4.078\n",
      "(Epoch 2429 / 10000) Train_Loss: 28.368; Val_Loss: 885.212   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.311\n",
      "(Epoch 2430 / 10000) Train_Loss: 30.702; Val_Loss: 971.538   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.008\n",
      "(Epoch 2431 / 10000) Train_Loss: 29.900; Val_Loss: 988.527   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 4.117\n",
      "(Epoch 2432 / 10000) Train_Loss: 29.333; Val_Loss: 945.714   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 4.426\n",
      "(Epoch 2433 / 10000) Train_Loss: 27.768; Val_Loss: 901.330   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 3.890\n",
      "(Epoch 2434 / 10000) Train_Loss: 27.155; Val_Loss: 943.811   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 3.941\n",
      "(Epoch 2435 / 10000) Train_Loss: 27.903; Val_Loss: 933.883   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.325; Val_NMI: 4.071\n",
      "(Epoch 2436 / 10000) Train_Loss: 27.815; Val_Loss: 894.597   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.062\n",
      "(Epoch 2437 / 10000) Train_Loss: 28.050; Val_Loss: 926.245   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.345; Val_NMI: 3.546\n",
      "(Epoch 2438 / 10000) Train_Loss: 29.114; Val_Loss: 880.373   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.301; Val_NMI: 4.386\n",
      "(Epoch 2439 / 10000) Train_Loss: 29.589; Val_Loss: 914.856   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.349\n",
      "(Epoch 2440 / 10000) Train_Loss: 28.124; Val_Loss: 980.944   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.039\n",
      "(Epoch 2441 / 10000) Train_Loss: 28.060; Val_Loss: 925.225   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.698\n",
      "(Epoch 2442 / 10000) Train_Loss: 29.042; Val_Loss: 884.459   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.390; Val_NMI: 4.327\n",
      "(Epoch 2443 / 10000) Train_Loss: 29.099; Val_Loss: 868.603   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.188\n",
      "(Epoch 2444 / 10000) Train_Loss: 29.410; Val_Loss: 876.497   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.380; Val_NMI: 3.962\n",
      "(Epoch 2445 / 10000) Train_Loss: 28.764; Val_Loss: 926.046   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 3.877\n",
      "(Epoch 2446 / 10000) Train_Loss: 28.820; Val_Loss: 908.602   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.292; Val_NMI: 4.151\n",
      "(Epoch 2447 / 10000) Train_Loss: 27.694; Val_Loss: 920.825   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 4.343\n",
      "(Epoch 2448 / 10000) Train_Loss: 27.267; Val_Loss: 863.691   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.370; Val_NMI: 4.384\n",
      "(Epoch 2449 / 10000) Train_Loss: 30.996; Val_Loss: 949.923   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.413\n",
      "(Epoch 2450 / 10000) Train_Loss: 34.797; Val_Loss: 975.103   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.439; Val_NMI: 3.969\n",
      "(Epoch 2451 / 10000) Train_Loss: 30.934; Val_Loss: 888.720   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 3.890\n",
      "(Epoch 2452 / 10000) Train_Loss: 28.397; Val_Loss: 929.032   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.875\n",
      "(Epoch 2453 / 10000) Train_Loss: 28.276; Val_Loss: 912.447   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.425\n",
      "(Epoch 2454 / 10000) Train_Loss: 29.245; Val_Loss: 925.301   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 4.209\n",
      "(Epoch 2455 / 10000) Train_Loss: 29.243; Val_Loss: 922.782   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.326; Val_NMI: 4.621\n",
      "(Epoch 2456 / 10000) Train_Loss: 29.817; Val_Loss: 958.396   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.349; Val_NMI: 4.493\n",
      "(Epoch 2457 / 10000) Train_Loss: 29.181; Val_Loss: 910.450   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 4.481\n",
      "(Epoch 2458 / 10000) Train_Loss: 29.181; Val_Loss: 940.752   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.542\n",
      "(Epoch 2459 / 10000) Train_Loss: 28.259; Val_Loss: 914.778   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 5.123\n",
      "(Epoch 2460 / 10000) Train_Loss: 29.086; Val_Loss: 968.958   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.027\n",
      "(Epoch 2461 / 10000) Train_Loss: 28.897; Val_Loss: 880.446   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.048\n",
      "(Epoch 2462 / 10000) Train_Loss: 28.557; Val_Loss: 890.879   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 4.545\n",
      "(Epoch 2463 / 10000) Train_Loss: 27.564; Val_Loss: 960.310   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.328; Val_NMI: 4.462\n",
      "(Epoch 2464 / 10000) Train_Loss: 27.566; Val_Loss: 907.919   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 4.158\n",
      "(Epoch 2465 / 10000) Train_Loss: 28.453; Val_Loss: 951.493   Train_ACC: 14.539; Val_ACC: 18.519   Train_NMI: 0.325; Val_NMI: 3.822\n",
      "(Epoch 2466 / 10000) Train_Loss: 29.357; Val_Loss: 959.750   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.527\n",
      "(Epoch 2467 / 10000) Train_Loss: 30.566; Val_Loss: 936.024   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.207\n",
      "(Epoch 2468 / 10000) Train_Loss: 29.234; Val_Loss: 946.253   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.406; Val_NMI: 4.242\n",
      "(Epoch 2469 / 10000) Train_Loss: 27.478; Val_Loss: 984.936   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.310; Val_NMI: 3.926\n",
      "(Epoch 2470 / 10000) Train_Loss: 27.221; Val_Loss: 889.737   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.318; Val_NMI: 4.104\n",
      "(Epoch 2471 / 10000) Train_Loss: 30.567; Val_Loss: 905.496   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.332; Val_NMI: 4.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2472 / 10000) Train_Loss: 30.817; Val_Loss: 952.274   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.369; Val_NMI: 4.528\n",
      "(Epoch 2473 / 10000) Train_Loss: 27.862; Val_Loss: 898.766   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.422; Val_NMI: 3.942\n",
      "(Epoch 2474 / 10000) Train_Loss: 27.015; Val_Loss: 951.319   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 3.750\n",
      "(Epoch 2475 / 10000) Train_Loss: 30.723; Val_Loss: 974.414   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 4.437\n",
      "(Epoch 2476 / 10000) Train_Loss: 29.275; Val_Loss: 938.406   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.353; Val_NMI: 3.960\n",
      "(Epoch 2477 / 10000) Train_Loss: 28.679; Val_Loss: 917.922   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.363; Val_NMI: 3.773\n",
      "(Epoch 2478 / 10000) Train_Loss: 32.886; Val_Loss: 901.279   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.404; Val_NMI: 4.183\n",
      "(Epoch 2479 / 10000) Train_Loss: 30.382; Val_Loss: 920.722   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 4.119\n",
      "(Epoch 2480 / 10000) Train_Loss: 29.343; Val_Loss: 942.084   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.396; Val_NMI: 4.798\n",
      "(Epoch 2481 / 10000) Train_Loss: 30.392; Val_Loss: 889.703   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.171\n",
      "(Epoch 2482 / 10000) Train_Loss: 29.331; Val_Loss: 886.680   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 4.474\n",
      "(Epoch 2483 / 10000) Train_Loss: 29.071; Val_Loss: 926.642   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.362; Val_NMI: 4.095\n",
      "(Epoch 2484 / 10000) Train_Loss: 27.652; Val_Loss: 932.524   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.319; Val_NMI: 3.646\n",
      "(Epoch 2485 / 10000) Train_Loss: 28.236; Val_Loss: 915.260   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 3.899\n",
      "(Epoch 2486 / 10000) Train_Loss: 27.840; Val_Loss: 923.545   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 4.447\n",
      "(Epoch 2487 / 10000) Train_Loss: 27.521; Val_Loss: 979.927   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.597\n",
      "(Epoch 2488 / 10000) Train_Loss: 27.074; Val_Loss: 918.790   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.246\n",
      "(Epoch 2489 / 10000) Train_Loss: 27.964; Val_Loss: 927.827   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.789\n",
      "(Epoch 2490 / 10000) Train_Loss: 27.992; Val_Loss: 912.585   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.679\n",
      "(Epoch 2491 / 10000) Train_Loss: 28.298; Val_Loss: 908.880   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 4.116\n",
      "(Epoch 2492 / 10000) Train_Loss: 27.304; Val_Loss: 972.547   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.324\n",
      "(Epoch 2493 / 10000) Train_Loss: 29.463; Val_Loss: 922.440   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.770\n",
      "(Epoch 2494 / 10000) Train_Loss: 29.445; Val_Loss: 899.454   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 3.822\n",
      "(Epoch 2495 / 10000) Train_Loss: 29.481; Val_Loss: 921.603   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.362; Val_NMI: 4.290\n",
      "(Epoch 2496 / 10000) Train_Loss: 28.006; Val_Loss: 942.941   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.346; Val_NMI: 3.610\n",
      "(Epoch 2497 / 10000) Train_Loss: 27.570; Val_Loss: 948.635   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 5.120\n",
      "(Epoch 2498 / 10000) Train_Loss: 27.736; Val_Loss: 915.292   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 4.859\n",
      "(Epoch 2499 / 10000) Train_Loss: 28.435; Val_Loss: 905.853   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.744\n",
      "(Epoch 2500 / 10000) Train_Loss: 28.586; Val_Loss: 955.304   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.265\n",
      "(Epoch 2501 / 10000) Train_Loss: 28.719; Val_Loss: 951.293   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 4.332\n",
      "(Epoch 2502 / 10000) Train_Loss: 29.675; Val_Loss: 947.156   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.319\n",
      "(Epoch 2503 / 10000) Train_Loss: 27.902; Val_Loss: 946.624   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 3.805\n",
      "(Epoch 2504 / 10000) Train_Loss: 27.774; Val_Loss: 944.215   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.498\n",
      "(Epoch 2505 / 10000) Train_Loss: 29.410; Val_Loss: 913.680   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 4.452\n",
      "(Epoch 2506 / 10000) Train_Loss: 29.039; Val_Loss: 894.203   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.438; Val_NMI: 4.008\n",
      "(Epoch 2507 / 10000) Train_Loss: 30.687; Val_Loss: 934.252   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.412; Val_NMI: 3.693\n",
      "(Epoch 2508 / 10000) Train_Loss: 31.761; Val_Loss: 946.234   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 4.157\n",
      "(Epoch 2509 / 10000) Train_Loss: 31.503; Val_Loss: 969.187   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 4.019\n",
      "(Epoch 2510 / 10000) Train_Loss: 31.164; Val_Loss: 943.556   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 4.787\n",
      "(Epoch 2511 / 10000) Train_Loss: 28.904; Val_Loss: 894.901   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.359; Val_NMI: 3.561\n",
      "(Epoch 2512 / 10000) Train_Loss: 31.323; Val_Loss: 904.213   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 3.974\n",
      "(Epoch 2513 / 10000) Train_Loss: 29.948; Val_Loss: 934.518   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.338; Val_NMI: 4.256\n",
      "(Epoch 2514 / 10000) Train_Loss: 28.245; Val_Loss: 953.978   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 3.860\n",
      "(Epoch 2515 / 10000) Train_Loss: 28.320; Val_Loss: 929.465   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 3.479\n",
      "(Epoch 2516 / 10000) Train_Loss: 28.040; Val_Loss: 965.530   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.373; Val_NMI: 3.706\n",
      "(Epoch 2517 / 10000) Train_Loss: 27.453; Val_Loss: 944.005   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.306\n",
      "(Epoch 2518 / 10000) Train_Loss: 27.403; Val_Loss: 918.297   Train_ACC: 14.456; Val_ACC: 18.519   Train_NMI: 0.326; Val_NMI: 4.042\n",
      "(Epoch 2519 / 10000) Train_Loss: 27.664; Val_Loss: 881.867   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.258\n",
      "(Epoch 2520 / 10000) Train_Loss: 33.021; Val_Loss: 902.622   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.387; Val_NMI: 3.702\n",
      "(Epoch 2521 / 10000) Train_Loss: 31.016; Val_Loss: 925.923   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.109\n",
      "(Epoch 2522 / 10000) Train_Loss: 28.960; Val_Loss: 911.323   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.417; Val_NMI: 4.264\n",
      "(Epoch 2523 / 10000) Train_Loss: 28.003; Val_Loss: 933.798   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.054\n",
      "(Epoch 2524 / 10000) Train_Loss: 27.289; Val_Loss: 889.803   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.243\n",
      "(Epoch 2525 / 10000) Train_Loss: 28.074; Val_Loss: 918.138   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 4.089\n",
      "(Epoch 2526 / 10000) Train_Loss: 28.753; Val_Loss: 881.368   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.606\n",
      "(Epoch 2527 / 10000) Train_Loss: 30.161; Val_Loss: 953.661   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 3.770\n",
      "(Epoch 2528 / 10000) Train_Loss: 27.943; Val_Loss: 899.961   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.258; Val_NMI: 4.756\n",
      "(Epoch 2529 / 10000) Train_Loss: 28.679; Val_Loss: 956.050   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 4.488\n",
      "(Epoch 2530 / 10000) Train_Loss: 27.613; Val_Loss: 938.053   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.956\n",
      "(Epoch 2531 / 10000) Train_Loss: 28.226; Val_Loss: 890.297   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.256\n",
      "(Epoch 2532 / 10000) Train_Loss: 29.557; Val_Loss: 934.511   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 3.941\n",
      "(Epoch 2533 / 10000) Train_Loss: 29.293; Val_Loss: 963.515   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.407; Val_NMI: 4.330\n",
      "(Epoch 2534 / 10000) Train_Loss: 28.600; Val_Loss: 1006.840   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.285; Val_NMI: 4.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2535 / 10000) Train_Loss: 28.055; Val_Loss: 895.188   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.311; Val_NMI: 3.960\n",
      "(Epoch 2536 / 10000) Train_Loss: 34.236; Val_Loss: 954.127   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 3.766\n",
      "(Epoch 2537 / 10000) Train_Loss: 33.312; Val_Loss: 941.154   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 3.791\n",
      "(Epoch 2538 / 10000) Train_Loss: 30.547; Val_Loss: 870.255   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 3.955\n",
      "(Epoch 2539 / 10000) Train_Loss: 28.392; Val_Loss: 928.750   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.318; Val_NMI: 4.607\n",
      "(Epoch 2540 / 10000) Train_Loss: 28.538; Val_Loss: 909.873   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 3.812\n",
      "(Epoch 2541 / 10000) Train_Loss: 31.175; Val_Loss: 927.155   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 3.986\n",
      "(Epoch 2542 / 10000) Train_Loss: 30.386; Val_Loss: 836.946   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 4.490\n",
      "(Epoch 2543 / 10000) Train_Loss: 27.375; Val_Loss: 916.427   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.302; Val_NMI: 3.738\n",
      "(Epoch 2544 / 10000) Train_Loss: 26.444; Val_Loss: 931.324   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 4.239\n",
      "(Epoch 2545 / 10000) Train_Loss: 26.579; Val_Loss: 890.796   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 3.640\n",
      "(Epoch 2546 / 10000) Train_Loss: 27.693; Val_Loss: 988.587   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.317; Val_NMI: 3.720\n",
      "(Epoch 2547 / 10000) Train_Loss: 28.903; Val_Loss: 943.803   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.278\n",
      "(Epoch 2548 / 10000) Train_Loss: 27.908; Val_Loss: 945.338   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.396; Val_NMI: 3.804\n",
      "(Epoch 2549 / 10000) Train_Loss: 28.788; Val_Loss: 915.293   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 3.719\n",
      "(Epoch 2550 / 10000) Train_Loss: 27.895; Val_Loss: 978.554   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.420\n",
      "(Epoch 2551 / 10000) Train_Loss: 27.414; Val_Loss: 969.175   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.327; Val_NMI: 3.990\n",
      "(Epoch 2552 / 10000) Train_Loss: 29.372; Val_Loss: 923.971   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.367; Val_NMI: 4.320\n",
      "(Epoch 2553 / 10000) Train_Loss: 27.554; Val_Loss: 936.853   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.829\n",
      "(Epoch 2554 / 10000) Train_Loss: 27.408; Val_Loss: 926.968   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.327; Val_NMI: 4.106\n",
      "(Epoch 2555 / 10000) Train_Loss: 27.370; Val_Loss: 973.821   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 3.737\n",
      "(Epoch 2556 / 10000) Train_Loss: 29.766; Val_Loss: 935.534   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 3.817\n",
      "(Epoch 2557 / 10000) Train_Loss: 30.713; Val_Loss: 952.250   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 3.679\n",
      "(Epoch 2558 / 10000) Train_Loss: 28.015; Val_Loss: 970.078   Train_ACC: 15.198; Val_ACC: 20.370   Train_NMI: 0.424; Val_NMI: 3.727\n",
      "(Epoch 2559 / 10000) Train_Loss: 26.609; Val_Loss: 967.950   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 3.671\n",
      "(Epoch 2560 / 10000) Train_Loss: 28.938; Val_Loss: 972.253   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.381; Val_NMI: 3.705\n",
      "(Epoch 2561 / 10000) Train_Loss: 28.333; Val_Loss: 944.950   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.324; Val_NMI: 3.930\n",
      "(Epoch 2562 / 10000) Train_Loss: 27.779; Val_Loss: 902.273   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 3.994\n",
      "(Epoch 2563 / 10000) Train_Loss: 29.774; Val_Loss: 915.916   Train_ACC: 15.033; Val_ACC: 20.741   Train_NMI: 0.354; Val_NMI: 3.951\n",
      "(Epoch 2564 / 10000) Train_Loss: 29.108; Val_Loss: 878.895   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 3.621\n",
      "(Epoch 2565 / 10000) Train_Loss: 29.831; Val_Loss: 957.427   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.329; Val_NMI: 3.911\n",
      "(Epoch 2566 / 10000) Train_Loss: 27.490; Val_Loss: 848.943   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.332; Val_NMI: 4.228\n",
      "(Epoch 2567 / 10000) Train_Loss: 27.907; Val_Loss: 874.228   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 3.748\n",
      "(Epoch 2568 / 10000) Train_Loss: 28.608; Val_Loss: 945.124   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.668\n",
      "(Epoch 2569 / 10000) Train_Loss: 28.836; Val_Loss: 950.484   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 3.789\n",
      "(Epoch 2570 / 10000) Train_Loss: 28.364; Val_Loss: 949.997   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.127\n",
      "(Epoch 2571 / 10000) Train_Loss: 28.259; Val_Loss: 976.544   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.402; Val_NMI: 4.278\n",
      "(Epoch 2572 / 10000) Train_Loss: 27.754; Val_Loss: 922.642   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 3.689\n",
      "(Epoch 2573 / 10000) Train_Loss: 28.637; Val_Loss: 912.723   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.046\n",
      "(Epoch 2574 / 10000) Train_Loss: 29.500; Val_Loss: 945.324   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 3.954\n",
      "(Epoch 2575 / 10000) Train_Loss: 28.351; Val_Loss: 925.295   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.367; Val_NMI: 4.812\n",
      "(Epoch 2576 / 10000) Train_Loss: 30.561; Val_Loss: 883.839   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.333; Val_NMI: 4.026\n",
      "(Epoch 2577 / 10000) Train_Loss: 29.547; Val_Loss: 911.574   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 3.825\n",
      "(Epoch 2578 / 10000) Train_Loss: 29.728; Val_Loss: 949.760   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 4.385\n",
      "(Epoch 2579 / 10000) Train_Loss: 31.391; Val_Loss: 932.085   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.282\n",
      "(Epoch 2580 / 10000) Train_Loss: 31.383; Val_Loss: 895.845   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.393; Val_NMI: 3.998\n",
      "(Epoch 2581 / 10000) Train_Loss: 29.652; Val_Loss: 879.996   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.377; Val_NMI: 4.149\n",
      "(Epoch 2582 / 10000) Train_Loss: 27.699; Val_Loss: 971.156   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 3.996\n",
      "(Epoch 2583 / 10000) Train_Loss: 28.522; Val_Loss: 947.503   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 3.877\n",
      "(Epoch 2584 / 10000) Train_Loss: 29.555; Val_Loss: 954.641   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 3.986\n",
      "(Epoch 2585 / 10000) Train_Loss: 31.944; Val_Loss: 945.796   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.056\n",
      "(Epoch 2586 / 10000) Train_Loss: 32.233; Val_Loss: 949.151   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.358\n",
      "(Epoch 2587 / 10000) Train_Loss: 31.205; Val_Loss: 925.268   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.609\n",
      "(Epoch 2588 / 10000) Train_Loss: 31.625; Val_Loss: 957.459   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.319; Val_NMI: 4.101\n",
      "(Epoch 2589 / 10000) Train_Loss: 30.482; Val_Loss: 898.022   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 3.868\n",
      "(Epoch 2590 / 10000) Train_Loss: 28.825; Val_Loss: 924.831   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 3.978\n",
      "(Epoch 2591 / 10000) Train_Loss: 27.544; Val_Loss: 923.118   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.396; Val_NMI: 4.131\n",
      "(Epoch 2592 / 10000) Train_Loss: 27.511; Val_Loss: 913.921   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.319; Val_NMI: 4.398\n",
      "(Epoch 2593 / 10000) Train_Loss: 26.717; Val_Loss: 895.306   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 3.847\n",
      "(Epoch 2594 / 10000) Train_Loss: 27.781; Val_Loss: 934.203   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 4.309\n",
      "(Epoch 2595 / 10000) Train_Loss: 28.718; Val_Loss: 950.608   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 3.964\n",
      "(Epoch 2596 / 10000) Train_Loss: 27.983; Val_Loss: 945.408   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.276; Val_NMI: 3.787\n",
      "(Epoch 2597 / 10000) Train_Loss: 29.044; Val_Loss: 916.466   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2598 / 10000) Train_Loss: 27.368; Val_Loss: 888.876   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.324; Val_NMI: 4.550\n",
      "(Epoch 2599 / 10000) Train_Loss: 27.851; Val_Loss: 984.266   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 4.008\n",
      "(Epoch 2600 / 10000) Train_Loss: 27.897; Val_Loss: 933.882   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.263\n",
      "(Epoch 2601 / 10000) Train_Loss: 28.594; Val_Loss: 973.765   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 4.233\n",
      "(Epoch 2602 / 10000) Train_Loss: 28.189; Val_Loss: 962.744   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.324; Val_NMI: 4.263\n",
      "(Epoch 2603 / 10000) Train_Loss: 29.201; Val_Loss: 901.728   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 3.847\n",
      "(Epoch 2604 / 10000) Train_Loss: 30.579; Val_Loss: 950.502   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.189\n",
      "(Epoch 2605 / 10000) Train_Loss: 27.766; Val_Loss: 963.286   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.112\n",
      "(Epoch 2606 / 10000) Train_Loss: 26.801; Val_Loss: 969.410   Train_ACC: 14.456; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 4.031\n",
      "(Epoch 2607 / 10000) Train_Loss: 28.645; Val_Loss: 942.669   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.370; Val_NMI: 3.854\n",
      "(Epoch 2608 / 10000) Train_Loss: 27.755; Val_Loss: 971.691   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.085\n",
      "(Epoch 2609 / 10000) Train_Loss: 29.567; Val_Loss: 951.688   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.403; Val_NMI: 4.284\n",
      "(Epoch 2610 / 10000) Train_Loss: 29.443; Val_Loss: 937.031   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 3.816\n",
      "(Epoch 2611 / 10000) Train_Loss: 28.847; Val_Loss: 930.907   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.300; Val_NMI: 4.042\n",
      "(Epoch 2612 / 10000) Train_Loss: 28.265; Val_Loss: 896.526   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.067\n",
      "(Epoch 2613 / 10000) Train_Loss: 28.687; Val_Loss: 988.749   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.063\n",
      "(Epoch 2614 / 10000) Train_Loss: 28.571; Val_Loss: 971.807   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 3.865\n",
      "(Epoch 2615 / 10000) Train_Loss: 27.931; Val_Loss: 960.858   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.437; Val_NMI: 4.118\n",
      "(Epoch 2616 / 10000) Train_Loss: 27.962; Val_Loss: 949.711   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.304; Val_NMI: 4.555\n",
      "(Epoch 2617 / 10000) Train_Loss: 28.339; Val_Loss: 954.243   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 4.150\n",
      "(Epoch 2618 / 10000) Train_Loss: 29.611; Val_Loss: 917.305   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 4.003\n",
      "(Epoch 2619 / 10000) Train_Loss: 29.515; Val_Loss: 950.202   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.782\n",
      "(Epoch 2620 / 10000) Train_Loss: 27.445; Val_Loss: 921.486   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.390; Val_NMI: 4.323\n",
      "(Epoch 2621 / 10000) Train_Loss: 27.135; Val_Loss: 998.817   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 3.983\n",
      "(Epoch 2622 / 10000) Train_Loss: 27.171; Val_Loss: 924.149   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.491\n",
      "(Epoch 2623 / 10000) Train_Loss: 27.282; Val_Loss: 928.084   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.363; Val_NMI: 4.131\n",
      "(Epoch 2624 / 10000) Train_Loss: 27.954; Val_Loss: 967.687   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 3.867\n",
      "(Epoch 2625 / 10000) Train_Loss: 27.836; Val_Loss: 953.577   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.071\n",
      "(Epoch 2626 / 10000) Train_Loss: 29.893; Val_Loss: 974.060   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 4.775\n",
      "(Epoch 2627 / 10000) Train_Loss: 30.778; Val_Loss: 988.399   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.633\n",
      "(Epoch 2628 / 10000) Train_Loss: 28.567; Val_Loss: 966.056   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.445\n",
      "(Epoch 2629 / 10000) Train_Loss: 27.537; Val_Loss: 968.409   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 4.252\n",
      "(Epoch 2630 / 10000) Train_Loss: 27.328; Val_Loss: 955.183   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.395; Val_NMI: 4.275\n",
      "(Epoch 2631 / 10000) Train_Loss: 27.485; Val_Loss: 888.400   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 3.911\n",
      "(Epoch 2632 / 10000) Train_Loss: 26.915; Val_Loss: 945.832   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 4.161\n",
      "(Epoch 2633 / 10000) Train_Loss: 27.240; Val_Loss: 970.873   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 4.252\n",
      "(Epoch 2634 / 10000) Train_Loss: 27.795; Val_Loss: 952.440   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.588\n",
      "(Epoch 2635 / 10000) Train_Loss: 27.752; Val_Loss: 899.961   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 4.437\n",
      "(Epoch 2636 / 10000) Train_Loss: 27.991; Val_Loss: 927.625   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.398; Val_NMI: 4.185\n",
      "(Epoch 2637 / 10000) Train_Loss: 28.103; Val_Loss: 904.894   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.289\n",
      "(Epoch 2638 / 10000) Train_Loss: 28.341; Val_Loss: 916.322   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.826\n",
      "(Epoch 2639 / 10000) Train_Loss: 31.936; Val_Loss: 985.402   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.316; Val_NMI: 4.164\n",
      "(Epoch 2640 / 10000) Train_Loss: 34.286; Val_Loss: 915.897   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 4.758\n",
      "(Epoch 2641 / 10000) Train_Loss: 33.767; Val_Loss: 962.263   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.596\n",
      "(Epoch 2642 / 10000) Train_Loss: 37.254; Val_Loss: 903.271   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.393; Val_NMI: 4.060\n",
      "(Epoch 2643 / 10000) Train_Loss: 34.730; Val_Loss: 945.203   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 4.514\n",
      "(Epoch 2644 / 10000) Train_Loss: 29.587; Val_Loss: 950.899   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 4.007\n",
      "(Epoch 2645 / 10000) Train_Loss: 30.174; Val_Loss: 930.260   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.343; Val_NMI: 4.579\n",
      "(Epoch 2646 / 10000) Train_Loss: 28.953; Val_Loss: 956.741   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.365; Val_NMI: 3.766\n",
      "(Epoch 2647 / 10000) Train_Loss: 27.806; Val_Loss: 954.716   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.428; Val_NMI: 4.258\n",
      "(Epoch 2648 / 10000) Train_Loss: 27.650; Val_Loss: 894.821   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.605\n",
      "(Epoch 2649 / 10000) Train_Loss: 27.368; Val_Loss: 925.768   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 3.620\n",
      "(Epoch 2650 / 10000) Train_Loss: 26.767; Val_Loss: 962.548   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.857\n",
      "(Epoch 2651 / 10000) Train_Loss: 27.895; Val_Loss: 953.993   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 3.996\n",
      "(Epoch 2652 / 10000) Train_Loss: 28.752; Val_Loss: 949.228   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.330; Val_NMI: 3.745\n",
      "(Epoch 2653 / 10000) Train_Loss: 27.823; Val_Loss: 921.817   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.366; Val_NMI: 3.602\n",
      "(Epoch 2654 / 10000) Train_Loss: 28.318; Val_Loss: 925.618   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.358; Val_NMI: 3.778\n",
      "(Epoch 2655 / 10000) Train_Loss: 29.027; Val_Loss: 954.792   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.424; Val_NMI: 3.897\n",
      "(Epoch 2656 / 10000) Train_Loss: 28.987; Val_Loss: 950.908   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.431; Val_NMI: 3.867\n",
      "(Epoch 2657 / 10000) Train_Loss: 27.193; Val_Loss: 932.183   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.408; Val_NMI: 4.463\n",
      "(Epoch 2658 / 10000) Train_Loss: 28.026; Val_Loss: 940.447   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.382; Val_NMI: 4.190\n",
      "(Epoch 2659 / 10000) Train_Loss: 28.351; Val_Loss: 976.299   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.411; Val_NMI: 4.239\n",
      "(Epoch 2660 / 10000) Train_Loss: 27.180; Val_Loss: 931.574   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.402; Val_NMI: 4.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2661 / 10000) Train_Loss: 26.656; Val_Loss: 951.407   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.362; Val_NMI: 3.846\n",
      "(Epoch 2662 / 10000) Train_Loss: 29.871; Val_Loss: 918.817   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.386; Val_NMI: 3.815\n",
      "(Epoch 2663 / 10000) Train_Loss: 29.912; Val_Loss: 930.954   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.250\n",
      "(Epoch 2664 / 10000) Train_Loss: 28.338; Val_Loss: 969.716   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 4.116\n",
      "(Epoch 2665 / 10000) Train_Loss: 27.950; Val_Loss: 901.921   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 4.025\n",
      "(Epoch 2666 / 10000) Train_Loss: 26.734; Val_Loss: 931.408   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.173\n",
      "(Epoch 2667 / 10000) Train_Loss: 27.216; Val_Loss: 915.432   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 4.416\n",
      "(Epoch 2668 / 10000) Train_Loss: 27.177; Val_Loss: 977.729   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.225\n",
      "(Epoch 2669 / 10000) Train_Loss: 27.363; Val_Loss: 992.559   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 4.200\n",
      "(Epoch 2670 / 10000) Train_Loss: 35.753; Val_Loss: 936.454   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.120\n",
      "(Epoch 2671 / 10000) Train_Loss: 32.177; Val_Loss: 972.179   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.391; Val_NMI: 3.688\n",
      "(Epoch 2672 / 10000) Train_Loss: 29.712; Val_Loss: 895.141   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 3.997\n",
      "(Epoch 2673 / 10000) Train_Loss: 27.351; Val_Loss: 943.041   Train_ACC: 15.115; Val_ACC: 18.148   Train_NMI: 0.430; Val_NMI: 3.531\n",
      "(Epoch 2674 / 10000) Train_Loss: 28.258; Val_Loss: 928.007   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 3.926\n",
      "(Epoch 2675 / 10000) Train_Loss: 29.994; Val_Loss: 967.145   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.863\n",
      "(Epoch 2676 / 10000) Train_Loss: 29.307; Val_Loss: 1011.526   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 4.332\n",
      "(Epoch 2677 / 10000) Train_Loss: 28.070; Val_Loss: 928.784   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.398; Val_NMI: 3.951\n",
      "(Epoch 2678 / 10000) Train_Loss: 27.092; Val_Loss: 872.809   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.761\n",
      "(Epoch 2679 / 10000) Train_Loss: 27.014; Val_Loss: 944.362   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.353; Val_NMI: 4.004\n",
      "(Epoch 2680 / 10000) Train_Loss: 27.332; Val_Loss: 915.467   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.316; Val_NMI: 3.843\n",
      "(Epoch 2681 / 10000) Train_Loss: 26.636; Val_Loss: 935.547   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.404\n",
      "(Epoch 2682 / 10000) Train_Loss: 26.822; Val_Loss: 926.361   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 4.093\n",
      "(Epoch 2683 / 10000) Train_Loss: 27.416; Val_Loss: 940.026   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.255\n",
      "(Epoch 2684 / 10000) Train_Loss: 30.081; Val_Loss: 965.467   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 4.378\n",
      "(Epoch 2685 / 10000) Train_Loss: 29.649; Val_Loss: 930.572   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.341; Val_NMI: 4.009\n",
      "(Epoch 2686 / 10000) Train_Loss: 27.853; Val_Loss: 903.137   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.368; Val_NMI: 3.776\n",
      "(Epoch 2687 / 10000) Train_Loss: 28.148; Val_Loss: 891.268   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 4.030\n",
      "(Epoch 2688 / 10000) Train_Loss: 27.285; Val_Loss: 924.509   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.328; Val_NMI: 4.063\n",
      "(Epoch 2689 / 10000) Train_Loss: 30.193; Val_Loss: 908.977   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.375\n",
      "(Epoch 2690 / 10000) Train_Loss: 32.909; Val_Loss: 940.363   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.363; Val_NMI: 4.432\n",
      "(Epoch 2691 / 10000) Train_Loss: 34.697; Val_Loss: 949.432   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.230\n",
      "(Epoch 2692 / 10000) Train_Loss: 29.703; Val_Loss: 961.939   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.334\n",
      "(Epoch 2693 / 10000) Train_Loss: 27.384; Val_Loss: 914.742   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.240\n",
      "(Epoch 2694 / 10000) Train_Loss: 27.814; Val_Loss: 937.745   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.313\n",
      "(Epoch 2695 / 10000) Train_Loss: 28.477; Val_Loss: 998.124   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 3.749\n",
      "(Epoch 2696 / 10000) Train_Loss: 30.107; Val_Loss: 976.726   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 3.998\n",
      "(Epoch 2697 / 10000) Train_Loss: 29.327; Val_Loss: 958.092   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 3.976\n",
      "(Epoch 2698 / 10000) Train_Loss: 29.551; Val_Loss: 929.838   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.866\n",
      "(Epoch 2699 / 10000) Train_Loss: 28.305; Val_Loss: 949.138   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.411; Val_NMI: 4.312\n",
      "(Epoch 2700 / 10000) Train_Loss: 27.360; Val_Loss: 932.770   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.115\n",
      "(Epoch 2701 / 10000) Train_Loss: 29.252; Val_Loss: 914.743   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 4.626\n",
      "(Epoch 2702 / 10000) Train_Loss: 27.883; Val_Loss: 910.206   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.399; Val_NMI: 3.552\n",
      "(Epoch 2703 / 10000) Train_Loss: 26.927; Val_Loss: 914.747   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.466\n",
      "(Epoch 2704 / 10000) Train_Loss: 27.304; Val_Loss: 915.155   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.309; Val_NMI: 4.236\n",
      "(Epoch 2705 / 10000) Train_Loss: 27.633; Val_Loss: 973.898   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.316; Val_NMI: 3.648\n",
      "(Epoch 2706 / 10000) Train_Loss: 26.472; Val_Loss: 975.809   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.346; Val_NMI: 4.539\n",
      "(Epoch 2707 / 10000) Train_Loss: 26.547; Val_Loss: 904.585   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.329\n",
      "(Epoch 2708 / 10000) Train_Loss: 27.692; Val_Loss: 935.833   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.310; Val_NMI: 4.444\n",
      "(Epoch 2709 / 10000) Train_Loss: 27.621; Val_Loss: 877.153   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.210\n",
      "(Epoch 2710 / 10000) Train_Loss: 30.001; Val_Loss: 930.326   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.098\n",
      "(Epoch 2711 / 10000) Train_Loss: 28.513; Val_Loss: 957.867   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.365; Val_NMI: 3.595\n",
      "(Epoch 2712 / 10000) Train_Loss: 28.785; Val_Loss: 913.263   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.297; Val_NMI: 3.662\n",
      "(Epoch 2713 / 10000) Train_Loss: 28.051; Val_Loss: 923.327   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.659\n",
      "(Epoch 2714 / 10000) Train_Loss: 27.929; Val_Loss: 918.627   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 3.974\n",
      "(Epoch 2715 / 10000) Train_Loss: 28.368; Val_Loss: 933.921   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.872\n",
      "(Epoch 2716 / 10000) Train_Loss: 29.407; Val_Loss: 938.849   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.377; Val_NMI: 4.333\n",
      "(Epoch 2717 / 10000) Train_Loss: 28.322; Val_Loss: 943.574   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 4.057\n",
      "(Epoch 2718 / 10000) Train_Loss: 27.557; Val_Loss: 940.120   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.341; Val_NMI: 3.633\n",
      "(Epoch 2719 / 10000) Train_Loss: 27.064; Val_Loss: 921.139   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.345; Val_NMI: 3.911\n",
      "(Epoch 2720 / 10000) Train_Loss: 26.798; Val_Loss: 960.292   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.355; Val_NMI: 3.792\n",
      "(Epoch 2721 / 10000) Train_Loss: 26.684; Val_Loss: 942.499   Train_ACC: 14.539; Val_ACC: 18.519   Train_NMI: 0.302; Val_NMI: 3.887\n",
      "(Epoch 2722 / 10000) Train_Loss: 28.915; Val_Loss: 907.632   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 4.188\n",
      "(Epoch 2723 / 10000) Train_Loss: 28.470; Val_Loss: 945.344   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.311; Val_NMI: 4.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2724 / 10000) Train_Loss: 27.322; Val_Loss: 919.381   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.644\n",
      "(Epoch 2725 / 10000) Train_Loss: 28.441; Val_Loss: 951.445   Train_ACC: 14.621; Val_ACC: 18.519   Train_NMI: 0.339; Val_NMI: 3.725\n",
      "(Epoch 2726 / 10000) Train_Loss: 28.988; Val_Loss: 917.683   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 4.200\n",
      "(Epoch 2727 / 10000) Train_Loss: 29.166; Val_Loss: 963.047   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.356; Val_NMI: 4.098\n",
      "(Epoch 2728 / 10000) Train_Loss: 28.637; Val_Loss: 930.644   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.494\n",
      "(Epoch 2729 / 10000) Train_Loss: 31.167; Val_Loss: 948.275   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 3.982\n",
      "(Epoch 2730 / 10000) Train_Loss: 30.135; Val_Loss: 972.688   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.317; Val_NMI: 4.430\n",
      "(Epoch 2731 / 10000) Train_Loss: 29.155; Val_Loss: 958.535   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.408\n",
      "(Epoch 2732 / 10000) Train_Loss: 28.434; Val_Loss: 935.973   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.288\n",
      "(Epoch 2733 / 10000) Train_Loss: 27.882; Val_Loss: 965.430   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.429; Val_NMI: 3.827\n",
      "(Epoch 2734 / 10000) Train_Loss: 29.580; Val_Loss: 985.358   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 4.345\n",
      "(Epoch 2735 / 10000) Train_Loss: 27.900; Val_Loss: 869.065   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 4.282\n",
      "(Epoch 2736 / 10000) Train_Loss: 27.939; Val_Loss: 969.840   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.338; Val_NMI: 4.036\n",
      "(Epoch 2737 / 10000) Train_Loss: 28.740; Val_Loss: 928.828   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.107\n",
      "(Epoch 2738 / 10000) Train_Loss: 28.516; Val_Loss: 916.638   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.298; Val_NMI: 4.495\n",
      "(Epoch 2739 / 10000) Train_Loss: 31.334; Val_Loss: 932.674   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.084\n",
      "(Epoch 2740 / 10000) Train_Loss: 30.922; Val_Loss: 919.546   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.338\n",
      "(Epoch 2741 / 10000) Train_Loss: 30.472; Val_Loss: 936.038   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.329; Val_NMI: 3.509\n",
      "(Epoch 2742 / 10000) Train_Loss: 29.026; Val_Loss: 912.932   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 4.338\n",
      "(Epoch 2743 / 10000) Train_Loss: 26.369; Val_Loss: 927.930   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.544\n",
      "(Epoch 2744 / 10000) Train_Loss: 26.758; Val_Loss: 931.552   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.341\n",
      "(Epoch 2745 / 10000) Train_Loss: 28.228; Val_Loss: 938.360   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.393\n",
      "(Epoch 2746 / 10000) Train_Loss: 29.225; Val_Loss: 954.180   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.346; Val_NMI: 4.208\n",
      "(Epoch 2747 / 10000) Train_Loss: 28.196; Val_Loss: 931.892   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.564\n",
      "(Epoch 2748 / 10000) Train_Loss: 28.509; Val_Loss: 968.752   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.569\n",
      "(Epoch 2749 / 10000) Train_Loss: 28.073; Val_Loss: 969.467   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.385; Val_NMI: 4.380\n",
      "(Epoch 2750 / 10000) Train_Loss: 28.041; Val_Loss: 926.266   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.438; Val_NMI: 4.117\n",
      "(Epoch 2751 / 10000) Train_Loss: 27.609; Val_Loss: 982.505   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.381; Val_NMI: 3.992\n",
      "(Epoch 2752 / 10000) Train_Loss: 27.480; Val_Loss: 948.896   Train_ACC: 14.868; Val_ACC: 18.148   Train_NMI: 0.403; Val_NMI: 3.617\n",
      "(Epoch 2753 / 10000) Train_Loss: 28.159; Val_Loss: 952.068   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.370\n",
      "(Epoch 2754 / 10000) Train_Loss: 28.928; Val_Loss: 942.688   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.173\n",
      "(Epoch 2755 / 10000) Train_Loss: 28.630; Val_Loss: 965.451   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 3.822\n",
      "(Epoch 2756 / 10000) Train_Loss: 27.629; Val_Loss: 925.247   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 3.805\n",
      "(Epoch 2757 / 10000) Train_Loss: 27.837; Val_Loss: 901.735   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.376; Val_NMI: 3.506\n",
      "(Epoch 2758 / 10000) Train_Loss: 28.841; Val_Loss: 947.387   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 3.866\n",
      "(Epoch 2759 / 10000) Train_Loss: 28.100; Val_Loss: 877.798   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.193\n",
      "(Epoch 2760 / 10000) Train_Loss: 27.929; Val_Loss: 960.761   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.407; Val_NMI: 3.375\n",
      "(Epoch 2761 / 10000) Train_Loss: 26.939; Val_Loss: 958.598   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.376; Val_NMI: 3.514\n",
      "(Epoch 2762 / 10000) Train_Loss: 27.242; Val_Loss: 975.466   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.289; Val_NMI: 3.829\n",
      "(Epoch 2763 / 10000) Train_Loss: 26.974; Val_Loss: 891.320   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.402; Val_NMI: 4.337\n",
      "(Epoch 2764 / 10000) Train_Loss: 28.293; Val_Loss: 937.311   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 3.550\n",
      "(Epoch 2765 / 10000) Train_Loss: 28.859; Val_Loss: 914.810   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.024\n",
      "(Epoch 2766 / 10000) Train_Loss: 27.328; Val_Loss: 938.599   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.311; Val_NMI: 4.045\n",
      "(Epoch 2767 / 10000) Train_Loss: 27.186; Val_Loss: 890.911   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.301\n",
      "(Epoch 2768 / 10000) Train_Loss: 27.311; Val_Loss: 929.471   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.391\n",
      "(Epoch 2769 / 10000) Train_Loss: 27.919; Val_Loss: 893.143   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.063\n",
      "(Epoch 2770 / 10000) Train_Loss: 27.842; Val_Loss: 1031.250   Train_ACC: 14.580; Val_ACC: 18.519   Train_NMI: 0.315; Val_NMI: 3.790\n",
      "(Epoch 2771 / 10000) Train_Loss: 29.872; Val_Loss: 935.991   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.324; Val_NMI: 3.799\n",
      "(Epoch 2772 / 10000) Train_Loss: 29.681; Val_Loss: 937.847   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.528\n",
      "(Epoch 2773 / 10000) Train_Loss: 28.363; Val_Loss: 882.365   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.357; Val_NMI: 3.745\n",
      "(Epoch 2774 / 10000) Train_Loss: 27.185; Val_Loss: 938.980   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 4.146\n",
      "(Epoch 2775 / 10000) Train_Loss: 27.413; Val_Loss: 935.414   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.298\n",
      "(Epoch 2776 / 10000) Train_Loss: 28.964; Val_Loss: 922.578   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.402; Val_NMI: 4.463\n",
      "(Epoch 2777 / 10000) Train_Loss: 29.009; Val_Loss: 917.859   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.360; Val_NMI: 4.121\n",
      "(Epoch 2778 / 10000) Train_Loss: 28.884; Val_Loss: 934.618   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 4.245\n",
      "(Epoch 2779 / 10000) Train_Loss: 28.537; Val_Loss: 936.996   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.379; Val_NMI: 4.464\n",
      "(Epoch 2780 / 10000) Train_Loss: 28.330; Val_Loss: 909.647   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 4.373\n",
      "(Epoch 2781 / 10000) Train_Loss: 28.796; Val_Loss: 938.734   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.306\n",
      "(Epoch 2782 / 10000) Train_Loss: 28.892; Val_Loss: 950.477   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 4.422\n",
      "(Epoch 2783 / 10000) Train_Loss: 28.903; Val_Loss: 954.822   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 4.391\n",
      "(Epoch 2784 / 10000) Train_Loss: 28.657; Val_Loss: 942.579   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.827\n",
      "(Epoch 2785 / 10000) Train_Loss: 29.268; Val_Loss: 933.392   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.129\n",
      "(Epoch 2786 / 10000) Train_Loss: 28.622; Val_Loss: 958.541   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2787 / 10000) Train_Loss: 27.424; Val_Loss: 909.541   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 4.620\n",
      "(Epoch 2788 / 10000) Train_Loss: 28.744; Val_Loss: 917.534   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 3.959\n",
      "(Epoch 2789 / 10000) Train_Loss: 28.579; Val_Loss: 915.261   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.051\n",
      "(Epoch 2790 / 10000) Train_Loss: 28.430; Val_Loss: 921.604   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.363; Val_NMI: 4.171\n",
      "(Epoch 2791 / 10000) Train_Loss: 28.081; Val_Loss: 907.703   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.251\n",
      "(Epoch 2792 / 10000) Train_Loss: 31.311; Val_Loss: 953.107   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.379; Val_NMI: 4.335\n",
      "(Epoch 2793 / 10000) Train_Loss: 29.163; Val_Loss: 955.031   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.298; Val_NMI: 4.361\n",
      "(Epoch 2794 / 10000) Train_Loss: 28.021; Val_Loss: 915.061   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 4.369\n",
      "(Epoch 2795 / 10000) Train_Loss: 29.308; Val_Loss: 927.802   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.624\n",
      "(Epoch 2796 / 10000) Train_Loss: 30.272; Val_Loss: 932.362   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.291; Val_NMI: 4.907\n",
      "(Epoch 2797 / 10000) Train_Loss: 28.845; Val_Loss: 914.110   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 4.560\n",
      "(Epoch 2798 / 10000) Train_Loss: 28.115; Val_Loss: 960.720   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.170\n",
      "(Epoch 2799 / 10000) Train_Loss: 27.127; Val_Loss: 930.167   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.235\n",
      "(Epoch 2800 / 10000) Train_Loss: 28.440; Val_Loss: 941.672   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.381; Val_NMI: 4.305\n",
      "(Epoch 2801 / 10000) Train_Loss: 27.980; Val_Loss: 921.530   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.160\n",
      "(Epoch 2802 / 10000) Train_Loss: 26.758; Val_Loss: 972.226   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.312\n",
      "(Epoch 2803 / 10000) Train_Loss: 27.461; Val_Loss: 946.335   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.130\n",
      "(Epoch 2804 / 10000) Train_Loss: 28.569; Val_Loss: 925.481   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.359; Val_NMI: 4.818\n",
      "(Epoch 2805 / 10000) Train_Loss: 28.519; Val_Loss: 979.137   Train_ACC: 14.703; Val_ACC: 21.111   Train_NMI: 0.373; Val_NMI: 4.888\n",
      "(Epoch 2806 / 10000) Train_Loss: 30.418; Val_Loss: 955.260   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 3.578\n",
      "(Epoch 2807 / 10000) Train_Loss: 40.880; Val_Loss: 957.229   Train_ACC: 15.445; Val_ACC: 20.000   Train_NMI: 0.480; Val_NMI: 5.411\n",
      "(Epoch 2808 / 10000) Train_Loss: 35.622; Val_Loss: 972.730   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.305; Val_NMI: 4.565\n",
      "(Epoch 2809 / 10000) Train_Loss: 31.452; Val_Loss: 934.377   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.545\n",
      "(Epoch 2810 / 10000) Train_Loss: 31.205; Val_Loss: 973.496   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.398; Val_NMI: 4.427\n",
      "(Epoch 2811 / 10000) Train_Loss: 29.279; Val_Loss: 919.650   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.244\n",
      "(Epoch 2812 / 10000) Train_Loss: 27.742; Val_Loss: 960.484   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.411; Val_NMI: 4.423\n",
      "(Epoch 2813 / 10000) Train_Loss: 27.087; Val_Loss: 923.951   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.241\n",
      "(Epoch 2814 / 10000) Train_Loss: 27.760; Val_Loss: 951.882   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 3.822\n",
      "(Epoch 2815 / 10000) Train_Loss: 29.515; Val_Loss: 994.698   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.451\n",
      "(Epoch 2816 / 10000) Train_Loss: 30.599; Val_Loss: 924.859   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 4.117\n",
      "(Epoch 2817 / 10000) Train_Loss: 27.939; Val_Loss: 950.703   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 4.040\n",
      "(Epoch 2818 / 10000) Train_Loss: 28.151; Val_Loss: 929.409   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.397; Val_NMI: 3.837\n",
      "(Epoch 2819 / 10000) Train_Loss: 29.413; Val_Loss: 936.771   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.324; Val_NMI: 3.991\n",
      "(Epoch 2820 / 10000) Train_Loss: 27.557; Val_Loss: 955.017   Train_ACC: 14.456; Val_ACC: 19.630   Train_NMI: 0.309; Val_NMI: 3.949\n",
      "(Epoch 2821 / 10000) Train_Loss: 26.865; Val_Loss: 954.544   Train_ACC: 15.321; Val_ACC: 18.889   Train_NMI: 0.456; Val_NMI: 3.320\n",
      "(Epoch 2822 / 10000) Train_Loss: 27.358; Val_Loss: 927.961   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.381; Val_NMI: 3.539\n",
      "(Epoch 2823 / 10000) Train_Loss: 27.452; Val_Loss: 927.934   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.298\n",
      "(Epoch 2824 / 10000) Train_Loss: 27.888; Val_Loss: 911.406   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.360; Val_NMI: 3.422\n",
      "(Epoch 2825 / 10000) Train_Loss: 27.476; Val_Loss: 973.198   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.242\n",
      "(Epoch 2826 / 10000) Train_Loss: 27.314; Val_Loss: 947.642   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 3.720\n",
      "(Epoch 2827 / 10000) Train_Loss: 31.890; Val_Loss: 944.278   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.327\n",
      "(Epoch 2828 / 10000) Train_Loss: 34.461; Val_Loss: 935.868   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.429\n",
      "(Epoch 2829 / 10000) Train_Loss: 30.151; Val_Loss: 898.226   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.325; Val_NMI: 3.800\n",
      "(Epoch 2830 / 10000) Train_Loss: 29.835; Val_Loss: 916.221   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.412; Val_NMI: 4.050\n",
      "(Epoch 2831 / 10000) Train_Loss: 28.167; Val_Loss: 946.562   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 4.108\n",
      "(Epoch 2832 / 10000) Train_Loss: 28.523; Val_Loss: 924.543   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.392\n",
      "(Epoch 2833 / 10000) Train_Loss: 27.113; Val_Loss: 884.258   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.483\n",
      "(Epoch 2834 / 10000) Train_Loss: 26.231; Val_Loss: 952.444   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.161\n",
      "(Epoch 2835 / 10000) Train_Loss: 26.625; Val_Loss: 928.017   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.395; Val_NMI: 4.485\n",
      "(Epoch 2836 / 10000) Train_Loss: 28.903; Val_Loss: 965.311   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 3.889\n",
      "(Epoch 2837 / 10000) Train_Loss: 27.773; Val_Loss: 925.695   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 4.709\n",
      "(Epoch 2838 / 10000) Train_Loss: 28.041; Val_Loss: 925.133   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 3.713\n",
      "(Epoch 2839 / 10000) Train_Loss: 28.522; Val_Loss: 934.164   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 3.917\n",
      "(Epoch 2840 / 10000) Train_Loss: 28.164; Val_Loss: 899.863   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.391\n",
      "(Epoch 2841 / 10000) Train_Loss: 27.684; Val_Loss: 905.822   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 4.106\n",
      "(Epoch 2842 / 10000) Train_Loss: 26.632; Val_Loss: 971.582   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.296\n",
      "(Epoch 2843 / 10000) Train_Loss: 27.818; Val_Loss: 973.035   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.368; Val_NMI: 4.127\n",
      "(Epoch 2844 / 10000) Train_Loss: 28.623; Val_Loss: 903.933   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.379; Val_NMI: 3.945\n",
      "(Epoch 2845 / 10000) Train_Loss: 28.479; Val_Loss: 979.246   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.408; Val_NMI: 4.792\n",
      "(Epoch 2846 / 10000) Train_Loss: 27.116; Val_Loss: 984.140   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 4.827\n",
      "(Epoch 2847 / 10000) Train_Loss: 26.937; Val_Loss: 925.249   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.396; Val_NMI: 4.437\n",
      "(Epoch 2848 / 10000) Train_Loss: 28.611; Val_Loss: 926.964   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.729\n",
      "(Epoch 2849 / 10000) Train_Loss: 28.330; Val_Loss: 913.868   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2850 / 10000) Train_Loss: 26.969; Val_Loss: 910.061   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.360; Val_NMI: 4.057\n",
      "(Epoch 2851 / 10000) Train_Loss: 27.346; Val_Loss: 914.763   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.268\n",
      "(Epoch 2852 / 10000) Train_Loss: 26.897; Val_Loss: 964.552   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.074\n",
      "(Epoch 2853 / 10000) Train_Loss: 28.050; Val_Loss: 950.882   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.377; Val_NMI: 3.989\n",
      "(Epoch 2854 / 10000) Train_Loss: 27.515; Val_Loss: 920.990   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.613\n",
      "(Epoch 2855 / 10000) Train_Loss: 27.301; Val_Loss: 910.272   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 3.689\n",
      "(Epoch 2856 / 10000) Train_Loss: 26.337; Val_Loss: 934.656   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.776\n",
      "(Epoch 2857 / 10000) Train_Loss: 27.318; Val_Loss: 917.345   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 3.869\n",
      "(Epoch 2858 / 10000) Train_Loss: 27.886; Val_Loss: 952.995   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.343; Val_NMI: 3.845\n",
      "(Epoch 2859 / 10000) Train_Loss: 27.816; Val_Loss: 933.828   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 4.611\n",
      "(Epoch 2860 / 10000) Train_Loss: 28.345; Val_Loss: 919.747   Train_ACC: 15.280; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.267\n",
      "(Epoch 2861 / 10000) Train_Loss: 29.046; Val_Loss: 891.153   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.437; Val_NMI: 4.563\n",
      "(Epoch 2862 / 10000) Train_Loss: 30.845; Val_Loss: 950.967   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.405; Val_NMI: 4.237\n",
      "(Epoch 2863 / 10000) Train_Loss: 30.799; Val_Loss: 935.164   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.079\n",
      "(Epoch 2864 / 10000) Train_Loss: 30.512; Val_Loss: 934.183   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 3.944\n",
      "(Epoch 2865 / 10000) Train_Loss: 28.768; Val_Loss: 955.516   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.180\n",
      "(Epoch 2866 / 10000) Train_Loss: 29.611; Val_Loss: 878.003   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 3.985\n",
      "(Epoch 2867 / 10000) Train_Loss: 28.377; Val_Loss: 933.196   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.765\n",
      "(Epoch 2868 / 10000) Train_Loss: 27.497; Val_Loss: 944.364   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.317\n",
      "(Epoch 2869 / 10000) Train_Loss: 34.794; Val_Loss: 973.273   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.313; Val_NMI: 4.061\n",
      "(Epoch 2870 / 10000) Train_Loss: 42.595; Val_Loss: 976.589   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.428\n",
      "(Epoch 2871 / 10000) Train_Loss: 33.958; Val_Loss: 922.497   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.340\n",
      "(Epoch 2872 / 10000) Train_Loss: 29.738; Val_Loss: 949.427   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.343\n",
      "(Epoch 2873 / 10000) Train_Loss: 28.917; Val_Loss: 927.376   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.308; Val_NMI: 4.397\n",
      "(Epoch 2874 / 10000) Train_Loss: 26.914; Val_Loss: 914.784   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 3.893\n",
      "(Epoch 2875 / 10000) Train_Loss: 26.940; Val_Loss: 931.511   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 3.862\n",
      "(Epoch 2876 / 10000) Train_Loss: 27.082; Val_Loss: 995.934   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.497\n",
      "(Epoch 2877 / 10000) Train_Loss: 27.177; Val_Loss: 936.903   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 3.544\n",
      "(Epoch 2878 / 10000) Train_Loss: 26.773; Val_Loss: 947.397   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 4.212\n",
      "(Epoch 2879 / 10000) Train_Loss: 27.195; Val_Loss: 982.321   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 4.172\n",
      "(Epoch 2880 / 10000) Train_Loss: 26.588; Val_Loss: 891.238   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 3.945\n",
      "(Epoch 2881 / 10000) Train_Loss: 27.826; Val_Loss: 877.783   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 3.743\n",
      "(Epoch 2882 / 10000) Train_Loss: 27.623; Val_Loss: 876.484   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.909\n",
      "(Epoch 2883 / 10000) Train_Loss: 26.761; Val_Loss: 918.300   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 3.903\n",
      "(Epoch 2884 / 10000) Train_Loss: 27.102; Val_Loss: 897.750   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.404; Val_NMI: 4.366\n",
      "(Epoch 2885 / 10000) Train_Loss: 27.259; Val_Loss: 971.400   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 3.978\n",
      "(Epoch 2886 / 10000) Train_Loss: 27.959; Val_Loss: 904.148   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.206\n",
      "(Epoch 2887 / 10000) Train_Loss: 29.809; Val_Loss: 956.805   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.335; Val_NMI: 4.069\n",
      "(Epoch 2888 / 10000) Train_Loss: 28.204; Val_Loss: 950.061   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.185\n",
      "(Epoch 2889 / 10000) Train_Loss: 27.179; Val_Loss: 943.166   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.303; Val_NMI: 4.183\n",
      "(Epoch 2890 / 10000) Train_Loss: 26.513; Val_Loss: 885.815   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.248\n",
      "(Epoch 2891 / 10000) Train_Loss: 29.710; Val_Loss: 925.373   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.041\n",
      "(Epoch 2892 / 10000) Train_Loss: 28.103; Val_Loss: 960.558   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 4.274\n",
      "(Epoch 2893 / 10000) Train_Loss: 28.185; Val_Loss: 900.584   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 3.339\n",
      "(Epoch 2894 / 10000) Train_Loss: 28.526; Val_Loss: 939.322   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 3.737\n",
      "(Epoch 2895 / 10000) Train_Loss: 27.163; Val_Loss: 896.079   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 4.412\n",
      "(Epoch 2896 / 10000) Train_Loss: 27.523; Val_Loss: 930.536   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.427; Val_NMI: 4.714\n",
      "(Epoch 2897 / 10000) Train_Loss: 29.606; Val_Loss: 1014.819   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 4.219\n",
      "(Epoch 2898 / 10000) Train_Loss: 28.717; Val_Loss: 927.432   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.441; Val_NMI: 3.965\n",
      "(Epoch 2899 / 10000) Train_Loss: 27.668; Val_Loss: 944.467   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 3.926\n",
      "(Epoch 2900 / 10000) Train_Loss: 27.021; Val_Loss: 914.767   Train_ACC: 15.321; Val_ACC: 19.630   Train_NMI: 0.413; Val_NMI: 4.108\n",
      "(Epoch 2901 / 10000) Train_Loss: 27.926; Val_Loss: 920.818   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.014\n",
      "(Epoch 2902 / 10000) Train_Loss: 29.556; Val_Loss: 929.130   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.021\n",
      "(Epoch 2903 / 10000) Train_Loss: 28.137; Val_Loss: 945.628   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.393; Val_NMI: 3.829\n",
      "(Epoch 2904 / 10000) Train_Loss: 29.736; Val_Loss: 951.812   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.018\n",
      "(Epoch 2905 / 10000) Train_Loss: 29.879; Val_Loss: 947.613   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 4.394\n",
      "(Epoch 2906 / 10000) Train_Loss: 33.008; Val_Loss: 930.737   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 3.918\n",
      "(Epoch 2907 / 10000) Train_Loss: 30.016; Val_Loss: 884.412   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.203\n",
      "(Epoch 2908 / 10000) Train_Loss: 28.155; Val_Loss: 932.490   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.324; Val_NMI: 4.011\n",
      "(Epoch 2909 / 10000) Train_Loss: 28.602; Val_Loss: 919.959   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.290; Val_NMI: 4.375\n",
      "(Epoch 2910 / 10000) Train_Loss: 27.274; Val_Loss: 960.506   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 4.195\n",
      "(Epoch 2911 / 10000) Train_Loss: 27.532; Val_Loss: 939.030   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 3.767\n",
      "(Epoch 2912 / 10000) Train_Loss: 26.945; Val_Loss: 901.858   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 3.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2913 / 10000) Train_Loss: 27.233; Val_Loss: 900.429   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 3.946\n",
      "(Epoch 2914 / 10000) Train_Loss: 28.406; Val_Loss: 977.510   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.266\n",
      "(Epoch 2915 / 10000) Train_Loss: 28.774; Val_Loss: 939.401   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 3.890\n",
      "(Epoch 2916 / 10000) Train_Loss: 28.718; Val_Loss: 945.746   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.321; Val_NMI: 4.037\n",
      "(Epoch 2917 / 10000) Train_Loss: 28.306; Val_Loss: 948.768   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.341; Val_NMI: 4.020\n",
      "(Epoch 2918 / 10000) Train_Loss: 28.953; Val_Loss: 935.108   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 3.572\n",
      "(Epoch 2919 / 10000) Train_Loss: 27.864; Val_Loss: 968.800   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 3.650\n",
      "(Epoch 2920 / 10000) Train_Loss: 27.397; Val_Loss: 876.752   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 3.974\n",
      "(Epoch 2921 / 10000) Train_Loss: 27.952; Val_Loss: 1009.077   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 3.705\n",
      "(Epoch 2922 / 10000) Train_Loss: 27.139; Val_Loss: 892.239   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 3.712\n",
      "(Epoch 2923 / 10000) Train_Loss: 27.049; Val_Loss: 991.177   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 3.852\n",
      "(Epoch 2924 / 10000) Train_Loss: 26.579; Val_Loss: 994.499   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.411; Val_NMI: 3.601\n",
      "(Epoch 2925 / 10000) Train_Loss: 27.371; Val_Loss: 935.143   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.384; Val_NMI: 4.003\n",
      "(Epoch 2926 / 10000) Train_Loss: 27.656; Val_Loss: 928.606   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.031\n",
      "(Epoch 2927 / 10000) Train_Loss: 27.439; Val_Loss: 908.493   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.092\n",
      "(Epoch 2928 / 10000) Train_Loss: 27.382; Val_Loss: 941.499   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 3.995\n",
      "(Epoch 2929 / 10000) Train_Loss: 27.417; Val_Loss: 999.234   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.845\n",
      "(Epoch 2930 / 10000) Train_Loss: 27.033; Val_Loss: 1007.509   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.343; Val_NMI: 3.996\n",
      "(Epoch 2931 / 10000) Train_Loss: 27.504; Val_Loss: 955.020   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 3.885\n",
      "(Epoch 2932 / 10000) Train_Loss: 27.302; Val_Loss: 919.997   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 4.472\n",
      "(Epoch 2933 / 10000) Train_Loss: 27.742; Val_Loss: 919.162   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 3.735\n",
      "(Epoch 2934 / 10000) Train_Loss: 27.932; Val_Loss: 940.269   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 4.811\n",
      "(Epoch 2935 / 10000) Train_Loss: 27.942; Val_Loss: 953.387   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.007\n",
      "(Epoch 2936 / 10000) Train_Loss: 27.141; Val_Loss: 872.900   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.421; Val_NMI: 4.612\n",
      "(Epoch 2937 / 10000) Train_Loss: 29.123; Val_Loss: 912.838   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.312; Val_NMI: 4.403\n",
      "(Epoch 2938 / 10000) Train_Loss: 31.725; Val_Loss: 968.268   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.320; Val_NMI: 5.021\n",
      "(Epoch 2939 / 10000) Train_Loss: 31.958; Val_Loss: 972.125   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.434; Val_NMI: 4.543\n",
      "(Epoch 2940 / 10000) Train_Loss: 29.540; Val_Loss: 946.658   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.361\n",
      "(Epoch 2941 / 10000) Train_Loss: 27.230; Val_Loss: 973.633   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 4.314\n",
      "(Epoch 2942 / 10000) Train_Loss: 28.589; Val_Loss: 991.197   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.361; Val_NMI: 3.636\n",
      "(Epoch 2943 / 10000) Train_Loss: 29.097; Val_Loss: 937.889   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.524\n",
      "(Epoch 2944 / 10000) Train_Loss: 28.748; Val_Loss: 954.605   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.285\n",
      "(Epoch 2945 / 10000) Train_Loss: 29.471; Val_Loss: 918.671   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.413; Val_NMI: 4.405\n",
      "(Epoch 2946 / 10000) Train_Loss: 28.147; Val_Loss: 922.089   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 4.252\n",
      "(Epoch 2947 / 10000) Train_Loss: 27.075; Val_Loss: 912.910   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.431\n",
      "(Epoch 2948 / 10000) Train_Loss: 26.872; Val_Loss: 957.402   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.232\n",
      "(Epoch 2949 / 10000) Train_Loss: 29.513; Val_Loss: 952.568   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.323\n",
      "(Epoch 2950 / 10000) Train_Loss: 30.152; Val_Loss: 1020.048   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.349; Val_NMI: 3.814\n",
      "(Epoch 2951 / 10000) Train_Loss: 28.123; Val_Loss: 955.769   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.064\n",
      "(Epoch 2952 / 10000) Train_Loss: 27.498; Val_Loss: 986.010   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.274\n",
      "(Epoch 2953 / 10000) Train_Loss: 27.952; Val_Loss: 949.436   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.468\n",
      "(Epoch 2954 / 10000) Train_Loss: 28.828; Val_Loss: 980.786   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.336; Val_NMI: 4.280\n",
      "(Epoch 2955 / 10000) Train_Loss: 27.146; Val_Loss: 991.340   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.371; Val_NMI: 3.847\n",
      "(Epoch 2956 / 10000) Train_Loss: 29.007; Val_Loss: 977.292   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.395; Val_NMI: 4.401\n",
      "(Epoch 2957 / 10000) Train_Loss: 30.294; Val_Loss: 976.771   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.113\n",
      "(Epoch 2958 / 10000) Train_Loss: 29.223; Val_Loss: 953.392   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.397\n",
      "(Epoch 2959 / 10000) Train_Loss: 27.880; Val_Loss: 937.845   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.378; Val_NMI: 4.320\n",
      "(Epoch 2960 / 10000) Train_Loss: 27.208; Val_Loss: 968.622   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.326\n",
      "(Epoch 2961 / 10000) Train_Loss: 26.544; Val_Loss: 931.270   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.388; Val_NMI: 3.891\n",
      "(Epoch 2962 / 10000) Train_Loss: 27.907; Val_Loss: 956.239   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 3.672\n",
      "(Epoch 2963 / 10000) Train_Loss: 27.691; Val_Loss: 948.514   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.329; Val_NMI: 4.392\n",
      "(Epoch 2964 / 10000) Train_Loss: 27.440; Val_Loss: 957.820   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.243\n",
      "(Epoch 2965 / 10000) Train_Loss: 27.814; Val_Loss: 1000.338   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.144\n",
      "(Epoch 2966 / 10000) Train_Loss: 30.121; Val_Loss: 916.389   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.227\n",
      "(Epoch 2967 / 10000) Train_Loss: 33.476; Val_Loss: 932.969   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 3.902\n",
      "(Epoch 2968 / 10000) Train_Loss: 31.004; Val_Loss: 918.101   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.244\n",
      "(Epoch 2969 / 10000) Train_Loss: 28.453; Val_Loss: 974.998   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.390; Val_NMI: 4.520\n",
      "(Epoch 2970 / 10000) Train_Loss: 28.439; Val_Loss: 961.298   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 4.419\n",
      "(Epoch 2971 / 10000) Train_Loss: 28.414; Val_Loss: 910.655   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 4.443\n",
      "(Epoch 2972 / 10000) Train_Loss: 28.098; Val_Loss: 960.594   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.307; Val_NMI: 4.092\n",
      "(Epoch 2973 / 10000) Train_Loss: 28.233; Val_Loss: 891.851   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.324; Val_NMI: 4.695\n",
      "(Epoch 2974 / 10000) Train_Loss: 27.439; Val_Loss: 982.928   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.350; Val_NMI: 4.392\n",
      "(Epoch 2975 / 10000) Train_Loss: 28.264; Val_Loss: 993.682   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 3.732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2976 / 10000) Train_Loss: 30.151; Val_Loss: 931.989   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 3.916\n",
      "(Epoch 2977 / 10000) Train_Loss: 29.625; Val_Loss: 944.773   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.364; Val_NMI: 4.667\n",
      "(Epoch 2978 / 10000) Train_Loss: 29.598; Val_Loss: 930.197   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.278\n",
      "(Epoch 2979 / 10000) Train_Loss: 28.098; Val_Loss: 955.790   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.100\n",
      "(Epoch 2980 / 10000) Train_Loss: 27.849; Val_Loss: 958.325   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.400; Val_NMI: 4.002\n",
      "(Epoch 2981 / 10000) Train_Loss: 27.307; Val_Loss: 915.071   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.430; Val_NMI: 4.098\n",
      "(Epoch 2982 / 10000) Train_Loss: 27.282; Val_Loss: 933.289   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.748\n",
      "(Epoch 2983 / 10000) Train_Loss: 30.390; Val_Loss: 994.138   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.889\n",
      "(Epoch 2984 / 10000) Train_Loss: 28.344; Val_Loss: 941.476   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.339; Val_NMI: 4.783\n",
      "(Epoch 2985 / 10000) Train_Loss: 27.508; Val_Loss: 908.857   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.162\n",
      "(Epoch 2986 / 10000) Train_Loss: 31.070; Val_Loss: 959.839   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.523\n",
      "(Epoch 2987 / 10000) Train_Loss: 29.869; Val_Loss: 914.848   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.406; Val_NMI: 4.632\n",
      "(Epoch 2988 / 10000) Train_Loss: 27.238; Val_Loss: 913.030   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 4.693\n",
      "(Epoch 2989 / 10000) Train_Loss: 27.297; Val_Loss: 927.552   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.739\n",
      "(Epoch 2990 / 10000) Train_Loss: 26.803; Val_Loss: 941.116   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.717\n",
      "(Epoch 2991 / 10000) Train_Loss: 26.479; Val_Loss: 907.148   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.374; Val_NMI: 4.478\n",
      "(Epoch 2992 / 10000) Train_Loss: 26.204; Val_Loss: 959.271   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 4.669\n",
      "(Epoch 2993 / 10000) Train_Loss: 27.109; Val_Loss: 1000.255   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.433\n",
      "(Epoch 2994 / 10000) Train_Loss: 27.261; Val_Loss: 965.774   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.622\n",
      "(Epoch 2995 / 10000) Train_Loss: 28.557; Val_Loss: 978.076   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.089\n",
      "(Epoch 2996 / 10000) Train_Loss: 28.066; Val_Loss: 980.258   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 4.623\n",
      "(Epoch 2997 / 10000) Train_Loss: 26.876; Val_Loss: 933.580   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.349; Val_NMI: 4.172\n",
      "(Epoch 2998 / 10000) Train_Loss: 26.153; Val_Loss: 960.086   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.336; Val_NMI: 4.134\n",
      "(Epoch 2999 / 10000) Train_Loss: 26.577; Val_Loss: 959.163   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 4.187\n",
      "(Epoch 3000 / 10000) Train_Loss: 27.490; Val_Loss: 911.506   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 4.094\n",
      "(Epoch 3001 / 10000) Train_Loss: 28.153; Val_Loss: 914.871   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.380; Val_NMI: 4.812\n",
      "(Epoch 3002 / 10000) Train_Loss: 31.262; Val_Loss: 987.587   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.609\n",
      "(Epoch 3003 / 10000) Train_Loss: 29.319; Val_Loss: 945.655   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 4.425\n",
      "(Epoch 3004 / 10000) Train_Loss: 29.289; Val_Loss: 1010.505   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.318; Val_NMI: 4.257\n",
      "(Epoch 3005 / 10000) Train_Loss: 30.076; Val_Loss: 947.833   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 4.841\n",
      "(Epoch 3006 / 10000) Train_Loss: 29.375; Val_Loss: 912.212   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.350; Val_NMI: 5.140\n",
      "(Epoch 3007 / 10000) Train_Loss: 27.977; Val_Loss: 935.771   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 5.103\n",
      "(Epoch 3008 / 10000) Train_Loss: 27.924; Val_Loss: 993.329   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.544\n",
      "(Epoch 3009 / 10000) Train_Loss: 27.979; Val_Loss: 969.617   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.091\n",
      "(Epoch 3010 / 10000) Train_Loss: 28.588; Val_Loss: 997.839   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 4.034\n",
      "(Epoch 3011 / 10000) Train_Loss: 27.473; Val_Loss: 1018.494   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 4.893\n",
      "(Epoch 3012 / 10000) Train_Loss: 27.087; Val_Loss: 941.364   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 3.949\n",
      "(Epoch 3013 / 10000) Train_Loss: 28.458; Val_Loss: 957.210   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.296; Val_NMI: 3.957\n",
      "(Epoch 3014 / 10000) Train_Loss: 31.350; Val_Loss: 975.314   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.582\n",
      "(Epoch 3015 / 10000) Train_Loss: 31.717; Val_Loss: 976.940   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 4.511\n",
      "(Epoch 3016 / 10000) Train_Loss: 27.975; Val_Loss: 971.992   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.079\n",
      "(Epoch 3017 / 10000) Train_Loss: 26.887; Val_Loss: 925.305   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.374; Val_NMI: 4.107\n",
      "(Epoch 3018 / 10000) Train_Loss: 26.922; Val_Loss: 907.524   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.367; Val_NMI: 3.688\n",
      "(Epoch 3019 / 10000) Train_Loss: 27.708; Val_Loss: 962.978   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.324\n",
      "(Epoch 3020 / 10000) Train_Loss: 26.257; Val_Loss: 987.965   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.059\n",
      "(Epoch 3021 / 10000) Train_Loss: 26.558; Val_Loss: 958.416   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.651\n",
      "(Epoch 3022 / 10000) Train_Loss: 26.726; Val_Loss: 951.182   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.242\n",
      "(Epoch 3023 / 10000) Train_Loss: 26.824; Val_Loss: 929.483   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 4.340\n",
      "(Epoch 3024 / 10000) Train_Loss: 26.732; Val_Loss: 928.209   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 3.957\n",
      "(Epoch 3025 / 10000) Train_Loss: 26.825; Val_Loss: 961.992   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.406; Val_NMI: 3.825\n",
      "(Epoch 3026 / 10000) Train_Loss: 27.412; Val_Loss: 965.169   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 4.716\n",
      "(Epoch 3027 / 10000) Train_Loss: 26.888; Val_Loss: 922.119   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.046\n",
      "(Epoch 3028 / 10000) Train_Loss: 27.822; Val_Loss: 994.320   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.393; Val_NMI: 3.869\n",
      "(Epoch 3029 / 10000) Train_Loss: 28.233; Val_Loss: 951.230   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 3.914\n",
      "(Epoch 3030 / 10000) Train_Loss: 27.233; Val_Loss: 958.222   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 4.242\n",
      "(Epoch 3031 / 10000) Train_Loss: 28.680; Val_Loss: 862.903   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.922\n",
      "(Epoch 3032 / 10000) Train_Loss: 31.639; Val_Loss: 998.192   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.207\n",
      "(Epoch 3033 / 10000) Train_Loss: 31.126; Val_Loss: 922.079   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 4.316\n",
      "(Epoch 3034 / 10000) Train_Loss: 29.454; Val_Loss: 998.195   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 3.794\n",
      "(Epoch 3035 / 10000) Train_Loss: 27.865; Val_Loss: 956.323   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.363; Val_NMI: 4.239\n",
      "(Epoch 3036 / 10000) Train_Loss: 27.749; Val_Loss: 981.288   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.401; Val_NMI: 4.252\n",
      "(Epoch 3037 / 10000) Train_Loss: 30.819; Val_Loss: 993.145   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.345; Val_NMI: 4.022\n",
      "(Epoch 3038 / 10000) Train_Loss: 32.418; Val_Loss: 958.330   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 4.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3039 / 10000) Train_Loss: 29.173; Val_Loss: 954.905   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.923\n",
      "(Epoch 3040 / 10000) Train_Loss: 27.499; Val_Loss: 912.399   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 4.588\n",
      "(Epoch 3041 / 10000) Train_Loss: 26.901; Val_Loss: 947.754   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.326; Val_NMI: 4.133\n",
      "(Epoch 3042 / 10000) Train_Loss: 28.942; Val_Loss: 960.798   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.332; Val_NMI: 4.711\n",
      "(Epoch 3043 / 10000) Train_Loss: 28.594; Val_Loss: 993.165   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.397; Val_NMI: 3.953\n",
      "(Epoch 3044 / 10000) Train_Loss: 27.371; Val_Loss: 982.193   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 4.214\n",
      "(Epoch 3045 / 10000) Train_Loss: 29.663; Val_Loss: 908.610   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 4.277\n",
      "(Epoch 3046 / 10000) Train_Loss: 30.063; Val_Loss: 979.444   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.550\n",
      "(Epoch 3047 / 10000) Train_Loss: 27.899; Val_Loss: 901.840   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.343; Val_NMI: 4.035\n",
      "(Epoch 3048 / 10000) Train_Loss: 26.984; Val_Loss: 954.149   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.235\n",
      "(Epoch 3049 / 10000) Train_Loss: 27.715; Val_Loss: 963.685   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 3.922\n",
      "(Epoch 3050 / 10000) Train_Loss: 27.142; Val_Loss: 990.520   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.558\n",
      "(Epoch 3051 / 10000) Train_Loss: 26.968; Val_Loss: 948.065   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.227\n",
      "(Epoch 3052 / 10000) Train_Loss: 26.864; Val_Loss: 980.254   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.370; Val_NMI: 4.415\n",
      "(Epoch 3053 / 10000) Train_Loss: 27.749; Val_Loss: 974.769   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.184\n",
      "(Epoch 3054 / 10000) Train_Loss: 27.125; Val_Loss: 997.379   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.405; Val_NMI: 4.083\n",
      "(Epoch 3055 / 10000) Train_Loss: 29.279; Val_Loss: 989.247   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.339; Val_NMI: 3.772\n",
      "(Epoch 3056 / 10000) Train_Loss: 29.853; Val_Loss: 1001.925   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.799\n",
      "(Epoch 3057 / 10000) Train_Loss: 27.097; Val_Loss: 999.813   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.311; Val_NMI: 4.108\n",
      "(Epoch 3058 / 10000) Train_Loss: 26.436; Val_Loss: 957.299   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.711\n",
      "(Epoch 3059 / 10000) Train_Loss: 28.565; Val_Loss: 955.475   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 4.071\n",
      "(Epoch 3060 / 10000) Train_Loss: 27.704; Val_Loss: 936.952   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.513\n",
      "(Epoch 3061 / 10000) Train_Loss: 26.726; Val_Loss: 967.167   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.365; Val_NMI: 4.535\n",
      "(Epoch 3062 / 10000) Train_Loss: 27.024; Val_Loss: 992.594   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 3.843\n",
      "(Epoch 3063 / 10000) Train_Loss: 28.541; Val_Loss: 983.745   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 3.844\n",
      "(Epoch 3064 / 10000) Train_Loss: 27.748; Val_Loss: 955.415   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.406\n",
      "(Epoch 3065 / 10000) Train_Loss: 27.387; Val_Loss: 945.572   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 3.693\n",
      "(Epoch 3066 / 10000) Train_Loss: 27.783; Val_Loss: 982.874   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 3.681\n",
      "(Epoch 3067 / 10000) Train_Loss: 27.852; Val_Loss: 967.507   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.438\n",
      "(Epoch 3068 / 10000) Train_Loss: 28.140; Val_Loss: 938.728   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.422; Val_NMI: 3.407\n",
      "(Epoch 3069 / 10000) Train_Loss: 27.238; Val_Loss: 945.298   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.921\n",
      "(Epoch 3070 / 10000) Train_Loss: 28.313; Val_Loss: 944.591   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.340; Val_NMI: 3.685\n",
      "(Epoch 3071 / 10000) Train_Loss: 30.018; Val_Loss: 943.992   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.152\n",
      "(Epoch 3072 / 10000) Train_Loss: 29.135; Val_Loss: 946.744   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.401; Val_NMI: 4.480\n",
      "(Epoch 3073 / 10000) Train_Loss: 29.317; Val_Loss: 952.836   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 3.984\n",
      "(Epoch 3074 / 10000) Train_Loss: 29.854; Val_Loss: 966.065   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 3.790\n",
      "(Epoch 3075 / 10000) Train_Loss: 30.915; Val_Loss: 901.599   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 3.770\n",
      "(Epoch 3076 / 10000) Train_Loss: 32.795; Val_Loss: 1011.169   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.403; Val_NMI: 3.895\n",
      "(Epoch 3077 / 10000) Train_Loss: 33.339; Val_Loss: 1016.505   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.307; Val_NMI: 3.767\n",
      "(Epoch 3078 / 10000) Train_Loss: 31.797; Val_Loss: 924.144   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.414; Val_NMI: 3.590\n",
      "(Epoch 3079 / 10000) Train_Loss: 29.655; Val_Loss: 954.326   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.186\n",
      "(Epoch 3080 / 10000) Train_Loss: 28.257; Val_Loss: 921.246   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.204\n",
      "(Epoch 3081 / 10000) Train_Loss: 26.687; Val_Loss: 963.030   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 4.596\n",
      "(Epoch 3082 / 10000) Train_Loss: 28.611; Val_Loss: 925.484   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.408; Val_NMI: 3.735\n",
      "(Epoch 3083 / 10000) Train_Loss: 29.556; Val_Loss: 995.271   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 3.688\n",
      "(Epoch 3084 / 10000) Train_Loss: 27.795; Val_Loss: 977.617   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 3.663\n",
      "(Epoch 3085 / 10000) Train_Loss: 27.094; Val_Loss: 972.163   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.281; Val_NMI: 3.895\n",
      "(Epoch 3086 / 10000) Train_Loss: 26.175; Val_Loss: 935.719   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 3.824\n",
      "(Epoch 3087 / 10000) Train_Loss: 26.380; Val_Loss: 964.513   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.381; Val_NMI: 3.762\n",
      "(Epoch 3088 / 10000) Train_Loss: 28.815; Val_Loss: 969.527   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.130\n",
      "(Epoch 3089 / 10000) Train_Loss: 29.539; Val_Loss: 954.770   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.298; Val_NMI: 4.075\n",
      "(Epoch 3090 / 10000) Train_Loss: 28.949; Val_Loss: 935.839   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.404; Val_NMI: 3.601\n",
      "(Epoch 3091 / 10000) Train_Loss: 27.441; Val_Loss: 971.049   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.418; Val_NMI: 4.175\n",
      "(Epoch 3092 / 10000) Train_Loss: 27.463; Val_Loss: 1005.766   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 3.584\n",
      "(Epoch 3093 / 10000) Train_Loss: 26.724; Val_Loss: 969.649   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.404\n",
      "(Epoch 3094 / 10000) Train_Loss: 26.911; Val_Loss: 942.049   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.089\n",
      "(Epoch 3095 / 10000) Train_Loss: 26.651; Val_Loss: 997.994   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.041\n",
      "(Epoch 3096 / 10000) Train_Loss: 26.893; Val_Loss: 962.334   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 4.020\n",
      "(Epoch 3097 / 10000) Train_Loss: 27.992; Val_Loss: 953.529   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.434; Val_NMI: 4.352\n",
      "(Epoch 3098 / 10000) Train_Loss: 27.372; Val_Loss: 1030.932   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.096\n",
      "(Epoch 3099 / 10000) Train_Loss: 28.331; Val_Loss: 981.680   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.300; Val_NMI: 3.992\n",
      "(Epoch 3100 / 10000) Train_Loss: 29.147; Val_Loss: 959.535   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.112\n",
      "(Epoch 3101 / 10000) Train_Loss: 28.015; Val_Loss: 943.997   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3102 / 10000) Train_Loss: 27.539; Val_Loss: 963.000   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.331; Val_NMI: 4.493\n",
      "(Epoch 3103 / 10000) Train_Loss: 26.716; Val_Loss: 1022.273   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.910\n",
      "(Epoch 3104 / 10000) Train_Loss: 26.975; Val_Loss: 1021.362   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.361; Val_NMI: 3.662\n",
      "(Epoch 3105 / 10000) Train_Loss: 29.559; Val_Loss: 987.973   Train_ACC: 15.157; Val_ACC: 18.519   Train_NMI: 0.359; Val_NMI: 3.522\n",
      "(Epoch 3106 / 10000) Train_Loss: 31.604; Val_Loss: 958.779   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.337; Val_NMI: 3.712\n",
      "(Epoch 3107 / 10000) Train_Loss: 33.464; Val_Loss: 951.248   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.240\n",
      "(Epoch 3108 / 10000) Train_Loss: 31.799; Val_Loss: 994.719   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.738\n",
      "(Epoch 3109 / 10000) Train_Loss: 30.483; Val_Loss: 938.131   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.967\n",
      "(Epoch 3110 / 10000) Train_Loss: 31.024; Val_Loss: 955.039   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 3.959\n",
      "(Epoch 3111 / 10000) Train_Loss: 28.172; Val_Loss: 1003.073   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.114\n",
      "(Epoch 3112 / 10000) Train_Loss: 27.368; Val_Loss: 1020.302   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 3.563\n",
      "(Epoch 3113 / 10000) Train_Loss: 27.201; Val_Loss: 906.814   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 3.931\n",
      "(Epoch 3114 / 10000) Train_Loss: 28.843; Val_Loss: 995.780   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 3.797\n",
      "(Epoch 3115 / 10000) Train_Loss: 28.972; Val_Loss: 919.539   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 3.941\n",
      "(Epoch 3116 / 10000) Train_Loss: 27.102; Val_Loss: 1032.446   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.835\n",
      "(Epoch 3117 / 10000) Train_Loss: 26.667; Val_Loss: 994.640   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 3.981\n",
      "(Epoch 3118 / 10000) Train_Loss: 27.011; Val_Loss: 970.065   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.578\n",
      "(Epoch 3119 / 10000) Train_Loss: 26.718; Val_Loss: 953.494   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.266\n",
      "(Epoch 3120 / 10000) Train_Loss: 26.047; Val_Loss: 957.295   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.071\n",
      "(Epoch 3121 / 10000) Train_Loss: 25.769; Val_Loss: 950.721   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.411; Val_NMI: 4.115\n",
      "(Epoch 3122 / 10000) Train_Loss: 27.303; Val_Loss: 1005.171   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.206\n",
      "(Epoch 3123 / 10000) Train_Loss: 27.582; Val_Loss: 986.284   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 4.409\n",
      "(Epoch 3124 / 10000) Train_Loss: 27.297; Val_Loss: 1001.919   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 3.894\n",
      "(Epoch 3125 / 10000) Train_Loss: 26.828; Val_Loss: 1023.852   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.620\n",
      "(Epoch 3126 / 10000) Train_Loss: 27.019; Val_Loss: 927.195   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.125\n",
      "(Epoch 3127 / 10000) Train_Loss: 26.959; Val_Loss: 1004.305   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 3.822\n",
      "(Epoch 3128 / 10000) Train_Loss: 27.189; Val_Loss: 1024.472   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.869\n",
      "(Epoch 3129 / 10000) Train_Loss: 26.508; Val_Loss: 940.656   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.415; Val_NMI: 4.015\n",
      "(Epoch 3130 / 10000) Train_Loss: 26.699; Val_Loss: 982.841   Train_ACC: 15.404; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 4.113\n",
      "(Epoch 3131 / 10000) Train_Loss: 27.982; Val_Loss: 933.917   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.309\n",
      "(Epoch 3132 / 10000) Train_Loss: 26.618; Val_Loss: 928.966   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 4.062\n",
      "(Epoch 3133 / 10000) Train_Loss: 28.044; Val_Loss: 951.199   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 3.879\n",
      "(Epoch 3134 / 10000) Train_Loss: 30.126; Val_Loss: 983.542   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.397; Val_NMI: 4.527\n",
      "(Epoch 3135 / 10000) Train_Loss: 28.315; Val_Loss: 990.238   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 4.101\n",
      "(Epoch 3136 / 10000) Train_Loss: 27.650; Val_Loss: 979.124   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.659\n",
      "(Epoch 3137 / 10000) Train_Loss: 28.322; Val_Loss: 944.266   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 3.822\n",
      "(Epoch 3138 / 10000) Train_Loss: 26.992; Val_Loss: 924.927   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.480\n",
      "(Epoch 3139 / 10000) Train_Loss: 26.713; Val_Loss: 966.694   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.422; Val_NMI: 3.897\n",
      "(Epoch 3140 / 10000) Train_Loss: 29.068; Val_Loss: 945.020   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.172\n",
      "(Epoch 3141 / 10000) Train_Loss: 28.001; Val_Loss: 959.379   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.074\n",
      "(Epoch 3142 / 10000) Train_Loss: 26.796; Val_Loss: 958.040   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.132\n",
      "(Epoch 3143 / 10000) Train_Loss: 27.146; Val_Loss: 960.477   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.029\n",
      "(Epoch 3144 / 10000) Train_Loss: 26.602; Val_Loss: 1002.549   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.297; Val_NMI: 4.358\n",
      "(Epoch 3145 / 10000) Train_Loss: 27.559; Val_Loss: 966.209   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.277; Val_NMI: 4.216\n",
      "(Epoch 3146 / 10000) Train_Loss: 28.601; Val_Loss: 1005.291   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.766\n",
      "(Epoch 3147 / 10000) Train_Loss: 31.334; Val_Loss: 969.438   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.183\n",
      "(Epoch 3148 / 10000) Train_Loss: 28.826; Val_Loss: 985.764   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.396; Val_NMI: 3.907\n",
      "(Epoch 3149 / 10000) Train_Loss: 26.983; Val_Loss: 946.273   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 3.369\n",
      "(Epoch 3150 / 10000) Train_Loss: 27.671; Val_Loss: 953.490   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 3.876\n",
      "(Epoch 3151 / 10000) Train_Loss: 29.735; Val_Loss: 1034.013   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 3.972\n",
      "(Epoch 3152 / 10000) Train_Loss: 32.755; Val_Loss: 993.153   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 4.012\n",
      "(Epoch 3153 / 10000) Train_Loss: 31.364; Val_Loss: 951.060   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.105\n",
      "(Epoch 3154 / 10000) Train_Loss: 30.586; Val_Loss: 975.464   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 3.890\n",
      "(Epoch 3155 / 10000) Train_Loss: 28.446; Val_Loss: 965.262   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.289\n",
      "(Epoch 3156 / 10000) Train_Loss: 27.523; Val_Loss: 927.231   Train_ACC: 15.239; Val_ACC: 18.889   Train_NMI: 0.399; Val_NMI: 4.060\n",
      "(Epoch 3157 / 10000) Train_Loss: 27.073; Val_Loss: 947.738   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.360; Val_NMI: 3.956\n",
      "(Epoch 3158 / 10000) Train_Loss: 26.869; Val_Loss: 959.376   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.562\n",
      "(Epoch 3159 / 10000) Train_Loss: 26.617; Val_Loss: 1001.618   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 3.971\n",
      "(Epoch 3160 / 10000) Train_Loss: 26.733; Val_Loss: 963.208   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.405; Val_NMI: 3.579\n",
      "(Epoch 3161 / 10000) Train_Loss: 28.472; Val_Loss: 946.242   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.384; Val_NMI: 3.918\n",
      "(Epoch 3162 / 10000) Train_Loss: 27.328; Val_Loss: 993.739   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.349; Val_NMI: 3.830\n",
      "(Epoch 3163 / 10000) Train_Loss: 27.264; Val_Loss: 907.665   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 3.957\n",
      "(Epoch 3164 / 10000) Train_Loss: 27.777; Val_Loss: 992.234   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 4.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3165 / 10000) Train_Loss: 27.388; Val_Loss: 995.072   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 3.894\n",
      "(Epoch 3166 / 10000) Train_Loss: 27.176; Val_Loss: 961.493   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.426; Val_NMI: 3.811\n",
      "(Epoch 3167 / 10000) Train_Loss: 28.070; Val_Loss: 1001.447   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.009\n",
      "(Epoch 3168 / 10000) Train_Loss: 26.816; Val_Loss: 1023.424   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.392; Val_NMI: 3.846\n",
      "(Epoch 3169 / 10000) Train_Loss: 26.972; Val_Loss: 917.411   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 4.256\n",
      "(Epoch 3170 / 10000) Train_Loss: 27.185; Val_Loss: 1009.346   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.178\n",
      "(Epoch 3171 / 10000) Train_Loss: 28.697; Val_Loss: 1031.821   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.251\n",
      "(Epoch 3172 / 10000) Train_Loss: 27.431; Val_Loss: 971.499   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 3.965\n",
      "(Epoch 3173 / 10000) Train_Loss: 26.630; Val_Loss: 937.495   Train_ACC: 15.280; Val_ACC: 19.630   Train_NMI: 0.415; Val_NMI: 4.438\n",
      "(Epoch 3174 / 10000) Train_Loss: 27.765; Val_Loss: 955.546   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.376; Val_NMI: 4.754\n",
      "(Epoch 3175 / 10000) Train_Loss: 28.301; Val_Loss: 972.337   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.300\n",
      "(Epoch 3176 / 10000) Train_Loss: 26.812; Val_Loss: 1025.638   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.395; Val_NMI: 3.568\n",
      "(Epoch 3177 / 10000) Train_Loss: 26.276; Val_Loss: 985.292   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.537\n",
      "(Epoch 3178 / 10000) Train_Loss: 27.032; Val_Loss: 953.833   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.407; Val_NMI: 4.217\n",
      "(Epoch 3179 / 10000) Train_Loss: 27.101; Val_Loss: 985.834   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.410; Val_NMI: 4.157\n",
      "(Epoch 3180 / 10000) Train_Loss: 34.272; Val_Loss: 988.935   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.368; Val_NMI: 4.498\n",
      "(Epoch 3181 / 10000) Train_Loss: 29.832; Val_Loss: 950.400   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 3.794\n",
      "(Epoch 3182 / 10000) Train_Loss: 28.233; Val_Loss: 952.269   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.141\n",
      "(Epoch 3183 / 10000) Train_Loss: 26.958; Val_Loss: 969.499   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.424; Val_NMI: 4.947\n",
      "(Epoch 3184 / 10000) Train_Loss: 26.726; Val_Loss: 971.834   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.227\n",
      "(Epoch 3185 / 10000) Train_Loss: 28.737; Val_Loss: 939.474   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 4.477\n",
      "(Epoch 3186 / 10000) Train_Loss: 28.778; Val_Loss: 941.274   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.341; Val_NMI: 4.456\n",
      "(Epoch 3187 / 10000) Train_Loss: 28.317; Val_Loss: 952.419   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 3.677\n",
      "(Epoch 3188 / 10000) Train_Loss: 29.223; Val_Loss: 933.775   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.376; Val_NMI: 3.561\n",
      "(Epoch 3189 / 10000) Train_Loss: 33.743; Val_Loss: 974.509   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.375; Val_NMI: 3.873\n",
      "(Epoch 3190 / 10000) Train_Loss: 30.309; Val_Loss: 956.315   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 4.317\n",
      "(Epoch 3191 / 10000) Train_Loss: 28.472; Val_Loss: 950.168   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.606\n",
      "(Epoch 3192 / 10000) Train_Loss: 28.126; Val_Loss: 943.410   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.376; Val_NMI: 4.193\n",
      "(Epoch 3193 / 10000) Train_Loss: 28.365; Val_Loss: 980.825   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.846\n",
      "(Epoch 3194 / 10000) Train_Loss: 31.096; Val_Loss: 966.967   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 4.361\n",
      "(Epoch 3195 / 10000) Train_Loss: 28.355; Val_Loss: 989.907   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.356; Val_NMI: 4.892\n",
      "(Epoch 3196 / 10000) Train_Loss: 26.431; Val_Loss: 947.153   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.424; Val_NMI: 3.483\n",
      "(Epoch 3197 / 10000) Train_Loss: 27.224; Val_Loss: 1012.130   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.167\n",
      "(Epoch 3198 / 10000) Train_Loss: 28.167; Val_Loss: 958.264   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.341; Val_NMI: 4.145\n",
      "(Epoch 3199 / 10000) Train_Loss: 27.283; Val_Loss: 956.617   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.412; Val_NMI: 4.098\n",
      "(Epoch 3200 / 10000) Train_Loss: 26.985; Val_Loss: 1033.058   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.398; Val_NMI: 4.434\n",
      "(Epoch 3201 / 10000) Train_Loss: 25.985; Val_Loss: 932.685   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 3.781\n",
      "(Epoch 3202 / 10000) Train_Loss: 26.349; Val_Loss: 916.132   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 3.849\n",
      "(Epoch 3203 / 10000) Train_Loss: 27.489; Val_Loss: 993.478   Train_ACC: 15.115; Val_ACC: 18.148   Train_NMI: 0.411; Val_NMI: 3.486\n",
      "(Epoch 3204 / 10000) Train_Loss: 28.062; Val_Loss: 986.347   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 4.260\n",
      "(Epoch 3205 / 10000) Train_Loss: 29.189; Val_Loss: 972.111   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.312; Val_NMI: 4.056\n",
      "(Epoch 3206 / 10000) Train_Loss: 30.493; Val_Loss: 1006.598   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.325; Val_NMI: 4.646\n",
      "(Epoch 3207 / 10000) Train_Loss: 29.820; Val_Loss: 952.974   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.402; Val_NMI: 3.702\n",
      "(Epoch 3208 / 10000) Train_Loss: 27.466; Val_Loss: 976.537   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 4.044\n",
      "(Epoch 3209 / 10000) Train_Loss: 27.238; Val_Loss: 984.868   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 4.392\n",
      "(Epoch 3210 / 10000) Train_Loss: 29.147; Val_Loss: 985.861   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 3.494\n",
      "(Epoch 3211 / 10000) Train_Loss: 30.769; Val_Loss: 930.028   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 4.380\n",
      "(Epoch 3212 / 10000) Train_Loss: 29.553; Val_Loss: 932.601   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.222\n",
      "(Epoch 3213 / 10000) Train_Loss: 27.987; Val_Loss: 974.187   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 4.219\n",
      "(Epoch 3214 / 10000) Train_Loss: 27.543; Val_Loss: 996.240   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.395; Val_NMI: 3.934\n",
      "(Epoch 3215 / 10000) Train_Loss: 27.076; Val_Loss: 987.518   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 3.938\n",
      "(Epoch 3216 / 10000) Train_Loss: 26.509; Val_Loss: 935.219   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.432; Val_NMI: 4.718\n",
      "(Epoch 3217 / 10000) Train_Loss: 26.609; Val_Loss: 961.361   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.360; Val_NMI: 4.269\n",
      "(Epoch 3218 / 10000) Train_Loss: 26.681; Val_Loss: 969.257   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.407; Val_NMI: 3.948\n",
      "(Epoch 3219 / 10000) Train_Loss: 26.645; Val_Loss: 973.102   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.953\n",
      "(Epoch 3220 / 10000) Train_Loss: 27.180; Val_Loss: 918.115   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.416; Val_NMI: 4.271\n",
      "(Epoch 3221 / 10000) Train_Loss: 28.188; Val_Loss: 966.792   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.413; Val_NMI: 3.939\n",
      "(Epoch 3222 / 10000) Train_Loss: 27.163; Val_Loss: 991.524   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 4.120\n",
      "(Epoch 3223 / 10000) Train_Loss: 26.026; Val_Loss: 951.880   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 3.994\n",
      "(Epoch 3224 / 10000) Train_Loss: 26.816; Val_Loss: 1015.886   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.468\n",
      "(Epoch 3225 / 10000) Train_Loss: 27.531; Val_Loss: 974.592   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.433; Val_NMI: 4.415\n",
      "(Epoch 3226 / 10000) Train_Loss: 29.779; Val_Loss: 967.106   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.450; Val_NMI: 4.073\n",
      "(Epoch 3227 / 10000) Train_Loss: 28.060; Val_Loss: 964.042   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3228 / 10000) Train_Loss: 27.093; Val_Loss: 915.832   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.599\n",
      "(Epoch 3229 / 10000) Train_Loss: 27.537; Val_Loss: 1050.606   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 4.243\n",
      "(Epoch 3230 / 10000) Train_Loss: 27.250; Val_Loss: 996.238   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.365; Val_NMI: 4.387\n",
      "(Epoch 3231 / 10000) Train_Loss: 28.245; Val_Loss: 946.367   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.517\n",
      "(Epoch 3232 / 10000) Train_Loss: 27.492; Val_Loss: 985.819   Train_ACC: 14.745; Val_ACC: 18.519   Train_NMI: 0.343; Val_NMI: 3.877\n",
      "(Epoch 3233 / 10000) Train_Loss: 26.544; Val_Loss: 979.692   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.371; Val_NMI: 3.974\n",
      "(Epoch 3234 / 10000) Train_Loss: 27.576; Val_Loss: 1024.423   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 3.869\n",
      "(Epoch 3235 / 10000) Train_Loss: 28.244; Val_Loss: 943.611   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.352\n",
      "(Epoch 3236 / 10000) Train_Loss: 27.678; Val_Loss: 958.548   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.389; Val_NMI: 4.191\n",
      "(Epoch 3237 / 10000) Train_Loss: 28.454; Val_Loss: 937.714   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 3.989\n",
      "(Epoch 3238 / 10000) Train_Loss: 27.717; Val_Loss: 963.317   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.372; Val_NMI: 3.813\n",
      "(Epoch 3239 / 10000) Train_Loss: 27.613; Val_Loss: 978.502   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.372; Val_NMI: 3.837\n",
      "(Epoch 3240 / 10000) Train_Loss: 28.231; Val_Loss: 984.909   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.372\n",
      "(Epoch 3241 / 10000) Train_Loss: 26.972; Val_Loss: 963.790   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.372; Val_NMI: 4.105\n",
      "(Epoch 3242 / 10000) Train_Loss: 26.997; Val_Loss: 1033.973   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 3.887\n",
      "(Epoch 3243 / 10000) Train_Loss: 27.443; Val_Loss: 1007.283   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.078\n",
      "(Epoch 3244 / 10000) Train_Loss: 28.622; Val_Loss: 1000.190   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.285; Val_NMI: 3.875\n",
      "(Epoch 3245 / 10000) Train_Loss: 28.250; Val_Loss: 942.366   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.279; Val_NMI: 4.438\n",
      "(Epoch 3246 / 10000) Train_Loss: 27.762; Val_Loss: 957.998   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.056\n",
      "(Epoch 3247 / 10000) Train_Loss: 27.737; Val_Loss: 976.453   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.322; Val_NMI: 3.580\n",
      "(Epoch 3248 / 10000) Train_Loss: 28.118; Val_Loss: 926.804   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.312; Val_NMI: 4.287\n",
      "(Epoch 3249 / 10000) Train_Loss: 27.752; Val_Loss: 944.962   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.347; Val_NMI: 3.717\n",
      "(Epoch 3250 / 10000) Train_Loss: 27.682; Val_Loss: 998.044   Train_ACC: 14.951; Val_ACC: 18.148   Train_NMI: 0.325; Val_NMI: 3.362\n",
      "(Epoch 3251 / 10000) Train_Loss: 33.112; Val_Loss: 945.166   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.976\n",
      "(Epoch 3252 / 10000) Train_Loss: 32.745; Val_Loss: 941.371   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.296; Val_NMI: 4.371\n",
      "(Epoch 3253 / 10000) Train_Loss: 29.457; Val_Loss: 951.813   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 3.990\n",
      "(Epoch 3254 / 10000) Train_Loss: 27.921; Val_Loss: 1018.606   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.312; Val_NMI: 4.227\n",
      "(Epoch 3255 / 10000) Train_Loss: 26.820; Val_Loss: 1006.009   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.387; Val_NMI: 5.233\n",
      "(Epoch 3256 / 10000) Train_Loss: 32.235; Val_Loss: 987.361   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.343; Val_NMI: 3.722\n",
      "(Epoch 3257 / 10000) Train_Loss: 46.817; Val_Loss: 985.478   Train_ACC: 15.362; Val_ACC: 18.519   Train_NMI: 0.400; Val_NMI: 3.738\n",
      "(Epoch 3258 / 10000) Train_Loss: 35.834; Val_Loss: 939.604   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.384; Val_NMI: 3.274\n",
      "(Epoch 3259 / 10000) Train_Loss: 30.167; Val_Loss: 959.532   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.939\n",
      "(Epoch 3260 / 10000) Train_Loss: 27.539; Val_Loss: 958.472   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.745\n",
      "(Epoch 3261 / 10000) Train_Loss: 28.322; Val_Loss: 992.535   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.297; Val_NMI: 5.202\n",
      "(Epoch 3262 / 10000) Train_Loss: 28.460; Val_Loss: 980.895   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.360\n",
      "(Epoch 3263 / 10000) Train_Loss: 28.496; Val_Loss: 976.644   Train_ACC: 15.404; Val_ACC: 19.630   Train_NMI: 0.485; Val_NMI: 4.919\n",
      "(Epoch 3264 / 10000) Train_Loss: 26.879; Val_Loss: 972.175   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.908\n",
      "(Epoch 3265 / 10000) Train_Loss: 26.682; Val_Loss: 947.349   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.989\n",
      "(Epoch 3266 / 10000) Train_Loss: 26.535; Val_Loss: 929.014   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.436; Val_NMI: 3.493\n",
      "(Epoch 3267 / 10000) Train_Loss: 26.477; Val_Loss: 998.899   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.206\n",
      "(Epoch 3268 / 10000) Train_Loss: 26.881; Val_Loss: 941.867   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 3.888\n",
      "(Epoch 3269 / 10000) Train_Loss: 27.271; Val_Loss: 988.544   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 3.747\n",
      "(Epoch 3270 / 10000) Train_Loss: 26.521; Val_Loss: 1025.603   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.122\n",
      "(Epoch 3271 / 10000) Train_Loss: 27.207; Val_Loss: 1003.912   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.384; Val_NMI: 3.672\n",
      "(Epoch 3272 / 10000) Train_Loss: 27.311; Val_Loss: 1007.683   Train_ACC: 15.033; Val_ACC: 18.519   Train_NMI: 0.395; Val_NMI: 3.571\n",
      "(Epoch 3273 / 10000) Train_Loss: 26.578; Val_Loss: 951.548   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 3.703\n",
      "(Epoch 3274 / 10000) Train_Loss: 27.159; Val_Loss: 1006.790   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 3.695\n",
      "(Epoch 3275 / 10000) Train_Loss: 27.914; Val_Loss: 992.322   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.401; Val_NMI: 3.415\n",
      "(Epoch 3276 / 10000) Train_Loss: 28.767; Val_Loss: 915.581   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.545\n",
      "(Epoch 3277 / 10000) Train_Loss: 27.188; Val_Loss: 983.519   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.277\n",
      "(Epoch 3278 / 10000) Train_Loss: 27.661; Val_Loss: 951.758   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.005\n",
      "(Epoch 3279 / 10000) Train_Loss: 27.485; Val_Loss: 957.047   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.247; Val_NMI: 3.788\n",
      "(Epoch 3280 / 10000) Train_Loss: 27.522; Val_Loss: 994.686   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 3.982\n",
      "(Epoch 3281 / 10000) Train_Loss: 27.390; Val_Loss: 944.386   Train_ACC: 14.621; Val_ACC: 18.519   Train_NMI: 0.310; Val_NMI: 3.270\n",
      "(Epoch 3282 / 10000) Train_Loss: 29.304; Val_Loss: 967.993   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.392; Val_NMI: 3.350\n",
      "(Epoch 3283 / 10000) Train_Loss: 26.983; Val_Loss: 972.904   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 4.186\n",
      "(Epoch 3284 / 10000) Train_Loss: 29.125; Val_Loss: 902.022   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.395; Val_NMI: 3.771\n",
      "(Epoch 3285 / 10000) Train_Loss: 27.723; Val_Loss: 966.741   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.614\n",
      "(Epoch 3286 / 10000) Train_Loss: 26.848; Val_Loss: 983.057   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.962\n",
      "(Epoch 3287 / 10000) Train_Loss: 27.257; Val_Loss: 1002.786   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.246\n",
      "(Epoch 3288 / 10000) Train_Loss: 27.736; Val_Loss: 932.848   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 4.074\n",
      "(Epoch 3289 / 10000) Train_Loss: 27.046; Val_Loss: 996.347   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.297; Val_NMI: 4.277\n",
      "(Epoch 3290 / 10000) Train_Loss: 27.121; Val_Loss: 973.169   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3291 / 10000) Train_Loss: 27.523; Val_Loss: 1026.478   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.349; Val_NMI: 4.050\n",
      "(Epoch 3292 / 10000) Train_Loss: 27.660; Val_Loss: 950.251   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.071\n",
      "(Epoch 3293 / 10000) Train_Loss: 36.200; Val_Loss: 1002.043   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.334; Val_NMI: 3.918\n",
      "(Epoch 3294 / 10000) Train_Loss: 37.917; Val_Loss: 1002.137   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 3.784\n",
      "(Epoch 3295 / 10000) Train_Loss: 30.479; Val_Loss: 931.979   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.351; Val_NMI: 3.869\n",
      "(Epoch 3296 / 10000) Train_Loss: 27.729; Val_Loss: 944.232   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.284; Val_NMI: 3.705\n",
      "(Epoch 3297 / 10000) Train_Loss: 27.163; Val_Loss: 962.924   Train_ACC: 14.415; Val_ACC: 19.259   Train_NMI: 0.242; Val_NMI: 3.996\n",
      "(Epoch 3298 / 10000) Train_Loss: 26.714; Val_Loss: 992.394   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.305; Val_NMI: 3.970\n",
      "(Epoch 3299 / 10000) Train_Loss: 26.834; Val_Loss: 953.413   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 3.607\n",
      "(Epoch 3300 / 10000) Train_Loss: 26.256; Val_Loss: 992.263   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 4.240\n",
      "(Epoch 3301 / 10000) Train_Loss: 28.778; Val_Loss: 985.035   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.309; Val_NMI: 3.869\n",
      "(Epoch 3302 / 10000) Train_Loss: 27.978; Val_Loss: 928.848   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 3.435\n",
      "(Epoch 3303 / 10000) Train_Loss: 27.380; Val_Loss: 994.360   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 3.853\n",
      "(Epoch 3304 / 10000) Train_Loss: 26.202; Val_Loss: 982.542   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 4.204\n",
      "(Epoch 3305 / 10000) Train_Loss: 25.823; Val_Loss: 981.026   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 3.402\n",
      "(Epoch 3306 / 10000) Train_Loss: 26.499; Val_Loss: 932.765   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.363; Val_NMI: 3.694\n",
      "(Epoch 3307 / 10000) Train_Loss: 27.001; Val_Loss: 987.470   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 3.711\n",
      "(Epoch 3308 / 10000) Train_Loss: 26.428; Val_Loss: 966.285   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 3.553\n",
      "(Epoch 3309 / 10000) Train_Loss: 26.604; Val_Loss: 988.401   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 3.371\n",
      "(Epoch 3310 / 10000) Train_Loss: 27.711; Val_Loss: 937.716   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.014\n",
      "(Epoch 3311 / 10000) Train_Loss: 28.121; Val_Loss: 942.455   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.334; Val_NMI: 3.483\n",
      "(Epoch 3312 / 10000) Train_Loss: 27.811; Val_Loss: 963.582   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 4.284\n",
      "(Epoch 3313 / 10000) Train_Loss: 29.028; Val_Loss: 1004.814   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.287; Val_NMI: 3.535\n",
      "(Epoch 3314 / 10000) Train_Loss: 27.136; Val_Loss: 999.697   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 3.534\n",
      "(Epoch 3315 / 10000) Train_Loss: 26.795; Val_Loss: 986.128   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.398; Val_NMI: 3.880\n",
      "(Epoch 3316 / 10000) Train_Loss: 26.930; Val_Loss: 1006.247   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 3.609\n",
      "(Epoch 3317 / 10000) Train_Loss: 27.863; Val_Loss: 989.369   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.379; Val_NMI: 3.615\n",
      "(Epoch 3318 / 10000) Train_Loss: 27.860; Val_Loss: 1003.489   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.243\n",
      "(Epoch 3319 / 10000) Train_Loss: 26.607; Val_Loss: 1010.168   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.419; Val_NMI: 3.427\n",
      "(Epoch 3320 / 10000) Train_Loss: 27.598; Val_Loss: 994.072   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.197\n",
      "(Epoch 3321 / 10000) Train_Loss: 27.659; Val_Loss: 979.594   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.324; Val_NMI: 3.071\n",
      "(Epoch 3322 / 10000) Train_Loss: 26.732; Val_Loss: 954.865   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 3.210\n",
      "(Epoch 3323 / 10000) Train_Loss: 27.595; Val_Loss: 922.689   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 3.245\n",
      "(Epoch 3324 / 10000) Train_Loss: 29.342; Val_Loss: 956.387   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 3.963\n",
      "(Epoch 3325 / 10000) Train_Loss: 27.873; Val_Loss: 917.374   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 3.887\n",
      "(Epoch 3326 / 10000) Train_Loss: 27.071; Val_Loss: 964.946   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.380; Val_NMI: 3.885\n",
      "(Epoch 3327 / 10000) Train_Loss: 26.731; Val_Loss: 932.142   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 4.180\n",
      "(Epoch 3328 / 10000) Train_Loss: 27.314; Val_Loss: 963.639   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 3.889\n",
      "(Epoch 3329 / 10000) Train_Loss: 27.461; Val_Loss: 910.080   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 3.913\n",
      "(Epoch 3330 / 10000) Train_Loss: 27.141; Val_Loss: 948.069   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.084\n",
      "(Epoch 3331 / 10000) Train_Loss: 26.882; Val_Loss: 989.198   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.357; Val_NMI: 3.218\n",
      "(Epoch 3332 / 10000) Train_Loss: 28.372; Val_Loss: 1027.359   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.369; Val_NMI: 4.167\n",
      "(Epoch 3333 / 10000) Train_Loss: 27.732; Val_Loss: 987.517   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 4.177\n",
      "(Epoch 3334 / 10000) Train_Loss: 26.601; Val_Loss: 996.629   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.016\n",
      "(Epoch 3335 / 10000) Train_Loss: 30.202; Val_Loss: 939.585   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.386; Val_NMI: 3.763\n",
      "(Epoch 3336 / 10000) Train_Loss: 31.916; Val_Loss: 977.182   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.397; Val_NMI: 3.715\n",
      "(Epoch 3337 / 10000) Train_Loss: 28.941; Val_Loss: 950.713   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.331; Val_NMI: 4.001\n",
      "(Epoch 3338 / 10000) Train_Loss: 27.204; Val_Loss: 1001.715   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.427; Val_NMI: 4.083\n",
      "(Epoch 3339 / 10000) Train_Loss: 27.163; Val_Loss: 956.837   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 3.898\n",
      "(Epoch 3340 / 10000) Train_Loss: 26.184; Val_Loss: 963.010   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 3.956\n",
      "(Epoch 3341 / 10000) Train_Loss: 28.173; Val_Loss: 981.853   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 3.526\n",
      "(Epoch 3342 / 10000) Train_Loss: 29.043; Val_Loss: 991.561   Train_ACC: 14.621; Val_ACC: 18.519   Train_NMI: 0.317; Val_NMI: 3.900\n",
      "(Epoch 3343 / 10000) Train_Loss: 30.399; Val_Loss: 945.261   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.362; Val_NMI: 3.626\n",
      "(Epoch 3344 / 10000) Train_Loss: 33.797; Val_Loss: 958.098   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.328; Val_NMI: 3.770\n",
      "(Epoch 3345 / 10000) Train_Loss: 30.009; Val_Loss: 978.965   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.479\n",
      "(Epoch 3346 / 10000) Train_Loss: 27.697; Val_Loss: 985.207   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 3.985\n",
      "(Epoch 3347 / 10000) Train_Loss: 26.639; Val_Loss: 977.567   Train_ACC: 14.621; Val_ACC: 18.519   Train_NMI: 0.370; Val_NMI: 3.736\n",
      "(Epoch 3348 / 10000) Train_Loss: 26.758; Val_Loss: 951.150   Train_ACC: 15.033; Val_ACC: 18.148   Train_NMI: 0.368; Val_NMI: 3.621\n",
      "(Epoch 3349 / 10000) Train_Loss: 27.036; Val_Loss: 932.681   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.354; Val_NMI: 3.520\n",
      "(Epoch 3350 / 10000) Train_Loss: 29.646; Val_Loss: 928.593   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.315; Val_NMI: 4.015\n",
      "(Epoch 3351 / 10000) Train_Loss: 28.171; Val_Loss: 972.067   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.398; Val_NMI: 3.983\n",
      "(Epoch 3352 / 10000) Train_Loss: 28.955; Val_Loss: 959.404   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.402; Val_NMI: 4.137\n",
      "(Epoch 3353 / 10000) Train_Loss: 27.322; Val_Loss: 977.523   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 4.384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3354 / 10000) Train_Loss: 26.386; Val_Loss: 926.729   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 4.126\n",
      "(Epoch 3355 / 10000) Train_Loss: 26.612; Val_Loss: 976.416   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 4.002\n",
      "(Epoch 3356 / 10000) Train_Loss: 25.384; Val_Loss: 1005.391   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 4.197\n",
      "(Epoch 3357 / 10000) Train_Loss: 28.216; Val_Loss: 915.444   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 4.290\n",
      "(Epoch 3358 / 10000) Train_Loss: 28.396; Val_Loss: 973.628   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 4.424\n",
      "(Epoch 3359 / 10000) Train_Loss: 27.456; Val_Loss: 921.685   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 4.547\n",
      "(Epoch 3360 / 10000) Train_Loss: 26.548; Val_Loss: 940.713   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 4.325\n",
      "(Epoch 3361 / 10000) Train_Loss: 27.450; Val_Loss: 986.453   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 4.302\n",
      "(Epoch 3362 / 10000) Train_Loss: 27.171; Val_Loss: 955.447   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.313; Val_NMI: 4.263\n",
      "(Epoch 3363 / 10000) Train_Loss: 27.068; Val_Loss: 1001.456   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.317; Val_NMI: 3.823\n",
      "(Epoch 3364 / 10000) Train_Loss: 26.711; Val_Loss: 1015.274   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.262\n",
      "(Epoch 3365 / 10000) Train_Loss: 28.184; Val_Loss: 968.395   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.306; Val_NMI: 3.963\n",
      "(Epoch 3366 / 10000) Train_Loss: 28.085; Val_Loss: 949.441   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.016\n",
      "(Epoch 3367 / 10000) Train_Loss: 28.134; Val_Loss: 984.819   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 3.859\n",
      "(Epoch 3368 / 10000) Train_Loss: 31.654; Val_Loss: 1007.942   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 3.944\n",
      "(Epoch 3369 / 10000) Train_Loss: 29.317; Val_Loss: 958.908   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.280; Val_NMI: 3.567\n",
      "(Epoch 3370 / 10000) Train_Loss: 27.349; Val_Loss: 1022.955   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 3.923\n",
      "(Epoch 3371 / 10000) Train_Loss: 27.624; Val_Loss: 967.591   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.363\n",
      "(Epoch 3372 / 10000) Train_Loss: 29.093; Val_Loss: 993.735   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.310; Val_NMI: 3.921\n",
      "(Epoch 3373 / 10000) Train_Loss: 27.501; Val_Loss: 963.760   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.595\n",
      "(Epoch 3374 / 10000) Train_Loss: 32.091; Val_Loss: 989.706   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 4.282\n",
      "(Epoch 3375 / 10000) Train_Loss: 31.279; Val_Loss: 947.043   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.281; Val_NMI: 3.715\n",
      "(Epoch 3376 / 10000) Train_Loss: 29.882; Val_Loss: 961.987   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.359; Val_NMI: 4.546\n",
      "(Epoch 3377 / 10000) Train_Loss: 28.255; Val_Loss: 967.261   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 4.044\n",
      "(Epoch 3378 / 10000) Train_Loss: 26.536; Val_Loss: 979.030   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.382; Val_NMI: 4.235\n",
      "(Epoch 3379 / 10000) Train_Loss: 26.156; Val_Loss: 920.657   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.523\n",
      "(Epoch 3380 / 10000) Train_Loss: 26.493; Val_Loss: 981.559   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.365; Val_NMI: 4.085\n",
      "(Epoch 3381 / 10000) Train_Loss: 27.808; Val_Loss: 978.010   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.383\n",
      "(Epoch 3382 / 10000) Train_Loss: 26.979; Val_Loss: 933.922   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.367; Val_NMI: 4.136\n",
      "(Epoch 3383 / 10000) Train_Loss: 26.770; Val_Loss: 1035.164   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.198\n",
      "(Epoch 3384 / 10000) Train_Loss: 28.431; Val_Loss: 965.978   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.330; Val_NMI: 3.690\n",
      "(Epoch 3385 / 10000) Train_Loss: 26.595; Val_Loss: 949.056   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 3.734\n",
      "(Epoch 3386 / 10000) Train_Loss: 26.448; Val_Loss: 1001.799   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.653\n",
      "(Epoch 3387 / 10000) Train_Loss: 26.468; Val_Loss: 1013.502   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.326; Val_NMI: 4.474\n",
      "(Epoch 3388 / 10000) Train_Loss: 27.933; Val_Loss: 915.384   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.804\n",
      "(Epoch 3389 / 10000) Train_Loss: 31.652; Val_Loss: 980.477   Train_ACC: 14.621; Val_ACC: 18.148   Train_NMI: 0.337; Val_NMI: 3.537\n",
      "(Epoch 3390 / 10000) Train_Loss: 28.613; Val_Loss: 948.423   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.304; Val_NMI: 3.742\n",
      "(Epoch 3391 / 10000) Train_Loss: 28.209; Val_Loss: 976.624   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.651\n",
      "(Epoch 3392 / 10000) Train_Loss: 28.482; Val_Loss: 999.861   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.259\n",
      "(Epoch 3393 / 10000) Train_Loss: 26.782; Val_Loss: 969.310   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 3.859\n",
      "(Epoch 3394 / 10000) Train_Loss: 27.534; Val_Loss: 923.230   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.002\n",
      "(Epoch 3395 / 10000) Train_Loss: 28.196; Val_Loss: 964.532   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.217\n",
      "(Epoch 3396 / 10000) Train_Loss: 27.313; Val_Loss: 972.647   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.252\n",
      "(Epoch 3397 / 10000) Train_Loss: 27.465; Val_Loss: 992.611   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.386\n",
      "(Epoch 3398 / 10000) Train_Loss: 27.213; Val_Loss: 980.568   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.021\n",
      "(Epoch 3399 / 10000) Train_Loss: 26.114; Val_Loss: 973.326   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 3.930\n",
      "(Epoch 3400 / 10000) Train_Loss: 25.966; Val_Loss: 999.415   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 4.417\n",
      "(Epoch 3401 / 10000) Train_Loss: 26.621; Val_Loss: 985.972   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.515\n",
      "(Epoch 3402 / 10000) Train_Loss: 27.771; Val_Loss: 977.088   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.401; Val_NMI: 4.188\n",
      "(Epoch 3403 / 10000) Train_Loss: 27.866; Val_Loss: 1017.881   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 4.258\n",
      "(Epoch 3404 / 10000) Train_Loss: 31.158; Val_Loss: 1013.288   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 4.276\n",
      "(Epoch 3405 / 10000) Train_Loss: 28.418; Val_Loss: 973.972   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.354; Val_NMI: 4.254\n",
      "(Epoch 3406 / 10000) Train_Loss: 26.341; Val_Loss: 1014.621   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.038\n",
      "(Epoch 3407 / 10000) Train_Loss: 26.386; Val_Loss: 993.384   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.193\n",
      "(Epoch 3408 / 10000) Train_Loss: 26.980; Val_Loss: 958.030   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 4.012\n",
      "(Epoch 3409 / 10000) Train_Loss: 26.742; Val_Loss: 925.201   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.062\n",
      "(Epoch 3410 / 10000) Train_Loss: 26.325; Val_Loss: 962.755   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.591\n",
      "(Epoch 3411 / 10000) Train_Loss: 27.679; Val_Loss: 996.989   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 4.370\n",
      "(Epoch 3412 / 10000) Train_Loss: 27.618; Val_Loss: 980.701   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.388; Val_NMI: 4.457\n",
      "(Epoch 3413 / 10000) Train_Loss: 26.877; Val_Loss: 981.590   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.619\n",
      "(Epoch 3414 / 10000) Train_Loss: 27.938; Val_Loss: 970.801   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.659\n",
      "(Epoch 3415 / 10000) Train_Loss: 27.369; Val_Loss: 987.537   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.613\n",
      "(Epoch 3416 / 10000) Train_Loss: 27.985; Val_Loss: 976.584   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.321; Val_NMI: 4.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3417 / 10000) Train_Loss: 26.884; Val_Loss: 935.374   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 4.131\n",
      "(Epoch 3418 / 10000) Train_Loss: 27.080; Val_Loss: 972.223   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 4.914\n",
      "(Epoch 3419 / 10000) Train_Loss: 30.239; Val_Loss: 964.607   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.398\n",
      "(Epoch 3420 / 10000) Train_Loss: 32.110; Val_Loss: 983.804   Train_ACC: 15.445; Val_ACC: 18.889   Train_NMI: 0.460; Val_NMI: 4.780\n",
      "(Epoch 3421 / 10000) Train_Loss: 30.498; Val_Loss: 946.361   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.292\n",
      "(Epoch 3422 / 10000) Train_Loss: 28.909; Val_Loss: 953.716   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.377; Val_NMI: 3.844\n",
      "(Epoch 3423 / 10000) Train_Loss: 29.179; Val_Loss: 981.936   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.357; Val_NMI: 4.381\n",
      "(Epoch 3424 / 10000) Train_Loss: 29.156; Val_Loss: 993.045   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.872\n",
      "(Epoch 3425 / 10000) Train_Loss: 28.165; Val_Loss: 1003.595   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.386; Val_NMI: 4.486\n",
      "(Epoch 3426 / 10000) Train_Loss: 28.287; Val_Loss: 1034.310   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 5.300\n",
      "(Epoch 3427 / 10000) Train_Loss: 28.325; Val_Loss: 1022.452   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 4.976\n",
      "(Epoch 3428 / 10000) Train_Loss: 27.758; Val_Loss: 924.937   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.328; Val_NMI: 5.004\n",
      "(Epoch 3429 / 10000) Train_Loss: 27.635; Val_Loss: 1031.249   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.687\n",
      "(Epoch 3430 / 10000) Train_Loss: 28.192; Val_Loss: 987.761   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.378; Val_NMI: 4.313\n",
      "(Epoch 3431 / 10000) Train_Loss: 27.489; Val_Loss: 1003.916   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 3.763\n",
      "(Epoch 3432 / 10000) Train_Loss: 27.758; Val_Loss: 950.305   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.343; Val_NMI: 4.197\n",
      "(Epoch 3433 / 10000) Train_Loss: 27.948; Val_Loss: 1026.195   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.377; Val_NMI: 3.627\n",
      "(Epoch 3434 / 10000) Train_Loss: 27.932; Val_Loss: 1006.477   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 3.915\n",
      "(Epoch 3435 / 10000) Train_Loss: 28.217; Val_Loss: 981.688   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 3.664\n",
      "(Epoch 3436 / 10000) Train_Loss: 29.022; Val_Loss: 977.960   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.313; Val_NMI: 3.529\n",
      "(Epoch 3437 / 10000) Train_Loss: 27.220; Val_Loss: 1001.073   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.369; Val_NMI: 4.741\n",
      "(Epoch 3438 / 10000) Train_Loss: 28.499; Val_Loss: 961.332   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.994\n",
      "(Epoch 3439 / 10000) Train_Loss: 30.255; Val_Loss: 980.362   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 3.838\n",
      "(Epoch 3440 / 10000) Train_Loss: 28.212; Val_Loss: 1013.918   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.401; Val_NMI: 4.211\n",
      "(Epoch 3441 / 10000) Train_Loss: 27.616; Val_Loss: 946.260   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 3.793\n",
      "(Epoch 3442 / 10000) Train_Loss: 26.474; Val_Loss: 992.282   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 4.787\n",
      "(Epoch 3443 / 10000) Train_Loss: 26.120; Val_Loss: 952.345   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 4.237\n",
      "(Epoch 3444 / 10000) Train_Loss: 26.553; Val_Loss: 988.866   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.356; Val_NMI: 4.021\n",
      "(Epoch 3445 / 10000) Train_Loss: 26.511; Val_Loss: 1014.783   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.394\n",
      "(Epoch 3446 / 10000) Train_Loss: 27.006; Val_Loss: 919.288   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.396; Val_NMI: 3.909\n",
      "(Epoch 3447 / 10000) Train_Loss: 27.499; Val_Loss: 968.709   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.231\n",
      "(Epoch 3448 / 10000) Train_Loss: 26.408; Val_Loss: 964.656   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.360; Val_NMI: 3.305\n",
      "(Epoch 3449 / 10000) Train_Loss: 27.241; Val_Loss: 902.703   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.405; Val_NMI: 3.879\n",
      "(Epoch 3450 / 10000) Train_Loss: 31.977; Val_Loss: 974.790   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.368; Val_NMI: 3.542\n",
      "(Epoch 3451 / 10000) Train_Loss: 29.811; Val_Loss: 940.184   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 4.655\n",
      "(Epoch 3452 / 10000) Train_Loss: 29.302; Val_Loss: 1013.278   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.390; Val_NMI: 4.082\n",
      "(Epoch 3453 / 10000) Train_Loss: 28.020; Val_Loss: 1012.574   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 3.939\n",
      "(Epoch 3454 / 10000) Train_Loss: 28.538; Val_Loss: 972.235   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.354; Val_NMI: 3.840\n",
      "(Epoch 3455 / 10000) Train_Loss: 28.291; Val_Loss: 990.557   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.399; Val_NMI: 3.751\n",
      "(Epoch 3456 / 10000) Train_Loss: 29.441; Val_Loss: 956.026   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 3.690\n",
      "(Epoch 3457 / 10000) Train_Loss: 28.559; Val_Loss: 934.162   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.331; Val_NMI: 3.236\n",
      "(Epoch 3458 / 10000) Train_Loss: 28.061; Val_Loss: 946.110   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.387; Val_NMI: 4.162\n",
      "(Epoch 3459 / 10000) Train_Loss: 30.803; Val_Loss: 985.503   Train_ACC: 15.157; Val_ACC: 18.519   Train_NMI: 0.374; Val_NMI: 3.768\n",
      "(Epoch 3460 / 10000) Train_Loss: 30.678; Val_Loss: 935.248   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.507\n",
      "(Epoch 3461 / 10000) Train_Loss: 28.026; Val_Loss: 992.832   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.314; Val_NMI: 3.990\n",
      "(Epoch 3462 / 10000) Train_Loss: 28.593; Val_Loss: 956.426   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.407; Val_NMI: 4.124\n",
      "(Epoch 3463 / 10000) Train_Loss: 27.957; Val_Loss: 1008.477   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.391; Val_NMI: 3.932\n",
      "(Epoch 3464 / 10000) Train_Loss: 27.551; Val_Loss: 993.744   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.301; Val_NMI: 3.947\n",
      "(Epoch 3465 / 10000) Train_Loss: 28.885; Val_Loss: 1036.819   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 4.092\n",
      "(Epoch 3466 / 10000) Train_Loss: 26.965; Val_Loss: 983.049   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.325; Val_NMI: 3.970\n",
      "(Epoch 3467 / 10000) Train_Loss: 26.101; Val_Loss: 972.972   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.315\n",
      "(Epoch 3468 / 10000) Train_Loss: 26.827; Val_Loss: 1014.166   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.357; Val_NMI: 3.563\n",
      "(Epoch 3469 / 10000) Train_Loss: 25.992; Val_Loss: 953.257   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.283\n",
      "(Epoch 3470 / 10000) Train_Loss: 27.295; Val_Loss: 971.701   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.607\n",
      "(Epoch 3471 / 10000) Train_Loss: 26.873; Val_Loss: 986.977   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 3.960\n",
      "(Epoch 3472 / 10000) Train_Loss: 28.189; Val_Loss: 933.405   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.385; Val_NMI: 4.135\n",
      "(Epoch 3473 / 10000) Train_Loss: 27.932; Val_Loss: 924.724   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.411; Val_NMI: 3.913\n",
      "(Epoch 3474 / 10000) Train_Loss: 27.125; Val_Loss: 955.038   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.394; Val_NMI: 4.461\n",
      "(Epoch 3475 / 10000) Train_Loss: 26.293; Val_Loss: 924.296   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.489\n",
      "(Epoch 3476 / 10000) Train_Loss: 26.741; Val_Loss: 923.086   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 3.896\n",
      "(Epoch 3477 / 10000) Train_Loss: 29.788; Val_Loss: 1041.837   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.006\n",
      "(Epoch 3478 / 10000) Train_Loss: 28.317; Val_Loss: 1046.001   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.347; Val_NMI: 4.235\n",
      "(Epoch 3479 / 10000) Train_Loss: 28.514; Val_Loss: 975.315   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3480 / 10000) Train_Loss: 28.510; Val_Loss: 1017.339   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.401; Val_NMI: 4.037\n",
      "(Epoch 3481 / 10000) Train_Loss: 27.541; Val_Loss: 958.079   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.377; Val_NMI: 3.709\n",
      "(Epoch 3482 / 10000) Train_Loss: 26.807; Val_Loss: 945.737   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.023\n",
      "(Epoch 3483 / 10000) Train_Loss: 27.086; Val_Loss: 967.478   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 3.539\n",
      "(Epoch 3484 / 10000) Train_Loss: 30.831; Val_Loss: 1030.670   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 3.914\n",
      "(Epoch 3485 / 10000) Train_Loss: 28.857; Val_Loss: 963.508   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.361; Val_NMI: 4.765\n",
      "(Epoch 3486 / 10000) Train_Loss: 27.186; Val_Loss: 988.107   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.379; Val_NMI: 4.276\n",
      "(Epoch 3487 / 10000) Train_Loss: 27.660; Val_Loss: 914.040   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.318; Val_NMI: 4.443\n",
      "(Epoch 3488 / 10000) Train_Loss: 27.204; Val_Loss: 956.633   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.272\n",
      "(Epoch 3489 / 10000) Train_Loss: 27.316; Val_Loss: 980.650   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.304; Val_NMI: 4.240\n",
      "(Epoch 3490 / 10000) Train_Loss: 26.373; Val_Loss: 991.299   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 3.828\n",
      "(Epoch 3491 / 10000) Train_Loss: 26.697; Val_Loss: 944.525   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 3.751\n",
      "(Epoch 3492 / 10000) Train_Loss: 26.089; Val_Loss: 968.902   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 3.861\n",
      "(Epoch 3493 / 10000) Train_Loss: 26.525; Val_Loss: 984.962   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.303; Val_NMI: 4.189\n",
      "(Epoch 3494 / 10000) Train_Loss: 26.652; Val_Loss: 1017.892   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.451\n",
      "(Epoch 3495 / 10000) Train_Loss: 27.836; Val_Loss: 965.307   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.311; Val_NMI: 3.972\n",
      "(Epoch 3496 / 10000) Train_Loss: 27.732; Val_Loss: 959.488   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.392; Val_NMI: 4.257\n",
      "(Epoch 3497 / 10000) Train_Loss: 29.830; Val_Loss: 1004.330   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 3.908\n",
      "(Epoch 3498 / 10000) Train_Loss: 31.005; Val_Loss: 1033.411   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.120\n",
      "(Epoch 3499 / 10000) Train_Loss: 27.795; Val_Loss: 984.279   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.767\n",
      "(Epoch 3500 / 10000) Train_Loss: 26.979; Val_Loss: 971.277   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.028\n",
      "(Epoch 3501 / 10000) Train_Loss: 26.823; Val_Loss: 977.829   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.301; Val_NMI: 3.753\n",
      "(Epoch 3502 / 10000) Train_Loss: 28.976; Val_Loss: 1020.598   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 3.988\n",
      "(Epoch 3503 / 10000) Train_Loss: 27.490; Val_Loss: 959.167   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.471\n",
      "(Epoch 3504 / 10000) Train_Loss: 26.501; Val_Loss: 941.796   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.362; Val_NMI: 3.650\n",
      "(Epoch 3505 / 10000) Train_Loss: 25.712; Val_Loss: 946.916   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.375; Val_NMI: 4.620\n",
      "(Epoch 3506 / 10000) Train_Loss: 25.651; Val_Loss: 1043.738   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.365\n",
      "(Epoch 3507 / 10000) Train_Loss: 27.776; Val_Loss: 979.749   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.309; Val_NMI: 4.644\n",
      "(Epoch 3508 / 10000) Train_Loss: 28.472; Val_Loss: 990.224   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.319; Val_NMI: 3.603\n",
      "(Epoch 3509 / 10000) Train_Loss: 26.979; Val_Loss: 1019.189   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.322; Val_NMI: 4.356\n",
      "(Epoch 3510 / 10000) Train_Loss: 29.938; Val_Loss: 913.580   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 4.288\n",
      "(Epoch 3511 / 10000) Train_Loss: 32.222; Val_Loss: 940.093   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 3.908\n",
      "(Epoch 3512 / 10000) Train_Loss: 31.013; Val_Loss: 1016.893   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.375; Val_NMI: 4.056\n",
      "(Epoch 3513 / 10000) Train_Loss: 28.489; Val_Loss: 930.582   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.199\n",
      "(Epoch 3514 / 10000) Train_Loss: 27.121; Val_Loss: 1048.952   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.320\n",
      "(Epoch 3515 / 10000) Train_Loss: 27.007; Val_Loss: 997.388   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.343\n",
      "(Epoch 3516 / 10000) Train_Loss: 27.007; Val_Loss: 937.258   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.987\n",
      "(Epoch 3517 / 10000) Train_Loss: 27.491; Val_Loss: 991.155   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.069\n",
      "(Epoch 3518 / 10000) Train_Loss: 27.738; Val_Loss: 908.935   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 3.909\n",
      "(Epoch 3519 / 10000) Train_Loss: 26.859; Val_Loss: 935.495   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.303; Val_NMI: 3.730\n",
      "(Epoch 3520 / 10000) Train_Loss: 26.457; Val_Loss: 981.145   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 3.920\n",
      "(Epoch 3521 / 10000) Train_Loss: 26.255; Val_Loss: 1000.126   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.359; Val_NMI: 3.426\n",
      "(Epoch 3522 / 10000) Train_Loss: 26.453; Val_Loss: 956.592   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.099\n",
      "(Epoch 3523 / 10000) Train_Loss: 26.293; Val_Loss: 926.929   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.018\n",
      "(Epoch 3524 / 10000) Train_Loss: 26.768; Val_Loss: 1025.926   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.305\n",
      "(Epoch 3525 / 10000) Train_Loss: 26.976; Val_Loss: 996.893   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.328; Val_NMI: 4.244\n",
      "(Epoch 3526 / 10000) Train_Loss: 28.744; Val_Loss: 978.483   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.372; Val_NMI: 3.804\n",
      "(Epoch 3527 / 10000) Train_Loss: 28.213; Val_Loss: 971.088   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.879\n",
      "(Epoch 3528 / 10000) Train_Loss: 27.977; Val_Loss: 974.484   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.686\n",
      "(Epoch 3529 / 10000) Train_Loss: 26.210; Val_Loss: 1027.291   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.316; Val_NMI: 4.613\n",
      "(Epoch 3530 / 10000) Train_Loss: 28.096; Val_Loss: 980.919   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.399; Val_NMI: 4.229\n",
      "(Epoch 3531 / 10000) Train_Loss: 31.260; Val_Loss: 1005.121   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.210\n",
      "(Epoch 3532 / 10000) Train_Loss: 30.208; Val_Loss: 986.958   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 3.882\n",
      "(Epoch 3533 / 10000) Train_Loss: 29.844; Val_Loss: 994.603   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.825\n",
      "(Epoch 3534 / 10000) Train_Loss: 28.274; Val_Loss: 985.307   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 3.652\n",
      "(Epoch 3535 / 10000) Train_Loss: 28.073; Val_Loss: 1018.745   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.399; Val_NMI: 4.671\n",
      "(Epoch 3536 / 10000) Train_Loss: 29.041; Val_Loss: 967.592   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.490\n",
      "(Epoch 3537 / 10000) Train_Loss: 28.506; Val_Loss: 1052.794   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.630\n",
      "(Epoch 3538 / 10000) Train_Loss: 29.085; Val_Loss: 953.937   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.402; Val_NMI: 3.765\n",
      "(Epoch 3539 / 10000) Train_Loss: 27.376; Val_Loss: 974.517   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 3.632\n",
      "(Epoch 3540 / 10000) Train_Loss: 26.626; Val_Loss: 1015.741   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.352; Val_NMI: 3.576\n",
      "(Epoch 3541 / 10000) Train_Loss: 26.672; Val_Loss: 956.655   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.356; Val_NMI: 3.945\n",
      "(Epoch 3542 / 10000) Train_Loss: 26.654; Val_Loss: 1001.080   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3543 / 10000) Train_Loss: 27.624; Val_Loss: 1071.255   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.317; Val_NMI: 3.645\n",
      "(Epoch 3544 / 10000) Train_Loss: 26.485; Val_Loss: 921.958   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.831\n",
      "(Epoch 3545 / 10000) Train_Loss: 26.693; Val_Loss: 988.006   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.060\n",
      "(Epoch 3546 / 10000) Train_Loss: 27.398; Val_Loss: 979.696   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.378; Val_NMI: 4.646\n",
      "(Epoch 3547 / 10000) Train_Loss: 27.234; Val_Loss: 983.391   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.639\n",
      "(Epoch 3548 / 10000) Train_Loss: 28.082; Val_Loss: 991.164   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.562\n",
      "(Epoch 3549 / 10000) Train_Loss: 27.257; Val_Loss: 978.213   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.328; Val_NMI: 4.422\n",
      "(Epoch 3550 / 10000) Train_Loss: 26.578; Val_Loss: 961.646   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 3.374\n",
      "(Epoch 3551 / 10000) Train_Loss: 26.462; Val_Loss: 1004.975   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.224\n",
      "(Epoch 3552 / 10000) Train_Loss: 26.599; Val_Loss: 1007.648   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 3.894\n",
      "(Epoch 3553 / 10000) Train_Loss: 26.024; Val_Loss: 1027.917   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.391; Val_NMI: 3.871\n",
      "(Epoch 3554 / 10000) Train_Loss: 26.089; Val_Loss: 958.794   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.371; Val_NMI: 3.625\n",
      "(Epoch 3555 / 10000) Train_Loss: 26.883; Val_Loss: 978.395   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 3.919\n",
      "(Epoch 3556 / 10000) Train_Loss: 31.518; Val_Loss: 978.304   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.250\n",
      "(Epoch 3557 / 10000) Train_Loss: 29.909; Val_Loss: 955.214   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.602\n",
      "(Epoch 3558 / 10000) Train_Loss: 27.877; Val_Loss: 953.549   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 3.668\n",
      "(Epoch 3559 / 10000) Train_Loss: 26.747; Val_Loss: 1041.979   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.049\n",
      "(Epoch 3560 / 10000) Train_Loss: 26.758; Val_Loss: 1000.616   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.341; Val_NMI: 3.774\n",
      "(Epoch 3561 / 10000) Train_Loss: 28.638; Val_Loss: 952.096   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.318\n",
      "(Epoch 3562 / 10000) Train_Loss: 30.854; Val_Loss: 993.632   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.287; Val_NMI: 3.981\n",
      "(Epoch 3563 / 10000) Train_Loss: 28.842; Val_Loss: 972.142   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 4.381\n",
      "(Epoch 3564 / 10000) Train_Loss: 29.555; Val_Loss: 976.089   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.036\n",
      "(Epoch 3565 / 10000) Train_Loss: 28.825; Val_Loss: 991.133   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.319; Val_NMI: 3.764\n",
      "(Epoch 3566 / 10000) Train_Loss: 27.273; Val_Loss: 927.345   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.377; Val_NMI: 3.919\n",
      "(Epoch 3567 / 10000) Train_Loss: 26.996; Val_Loss: 989.629   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 3.730\n",
      "(Epoch 3568 / 10000) Train_Loss: 26.922; Val_Loss: 982.722   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.906\n",
      "(Epoch 3569 / 10000) Train_Loss: 27.052; Val_Loss: 1008.469   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.144\n",
      "(Epoch 3570 / 10000) Train_Loss: 30.368; Val_Loss: 946.417   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 4.027\n",
      "(Epoch 3571 / 10000) Train_Loss: 27.774; Val_Loss: 982.832   Train_ACC: 15.321; Val_ACC: 20.000   Train_NMI: 0.373; Val_NMI: 4.650\n",
      "(Epoch 3572 / 10000) Train_Loss: 26.082; Val_Loss: 1004.395   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 3.942\n",
      "(Epoch 3573 / 10000) Train_Loss: 26.315; Val_Loss: 990.385   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.332; Val_NMI: 3.690\n",
      "(Epoch 3574 / 10000) Train_Loss: 27.587; Val_Loss: 1012.776   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 4.471\n",
      "(Epoch 3575 / 10000) Train_Loss: 29.120; Val_Loss: 973.406   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.391; Val_NMI: 3.696\n",
      "(Epoch 3576 / 10000) Train_Loss: 28.825; Val_Loss: 991.930   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 3.999\n",
      "(Epoch 3577 / 10000) Train_Loss: 26.860; Val_Loss: 1025.075   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 3.906\n",
      "(Epoch 3578 / 10000) Train_Loss: 27.294; Val_Loss: 1052.755   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.374; Val_NMI: 4.091\n",
      "(Epoch 3579 / 10000) Train_Loss: 30.048; Val_Loss: 971.747   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.342; Val_NMI: 3.847\n",
      "(Epoch 3580 / 10000) Train_Loss: 28.010; Val_Loss: 999.541   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 3.948\n",
      "(Epoch 3581 / 10000) Train_Loss: 28.398; Val_Loss: 1023.481   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.519\n",
      "(Epoch 3582 / 10000) Train_Loss: 26.904; Val_Loss: 953.284   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.366; Val_NMI: 3.440\n",
      "(Epoch 3583 / 10000) Train_Loss: 25.811; Val_Loss: 951.010   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.295\n",
      "(Epoch 3584 / 10000) Train_Loss: 26.634; Val_Loss: 1031.100   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 4.176\n",
      "(Epoch 3585 / 10000) Train_Loss: 27.713; Val_Loss: 958.299   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.229\n",
      "(Epoch 3586 / 10000) Train_Loss: 30.861; Val_Loss: 954.922   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.410; Val_NMI: 4.383\n",
      "(Epoch 3587 / 10000) Train_Loss: 28.693; Val_Loss: 988.133   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.214\n",
      "(Epoch 3588 / 10000) Train_Loss: 29.686; Val_Loss: 1009.513   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.630\n",
      "(Epoch 3589 / 10000) Train_Loss: 30.571; Val_Loss: 1009.855   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 3.985\n",
      "(Epoch 3590 / 10000) Train_Loss: 27.578; Val_Loss: 922.110   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.325; Val_NMI: 3.299\n",
      "(Epoch 3591 / 10000) Train_Loss: 27.348; Val_Loss: 983.370   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.316; Val_NMI: 4.186\n",
      "(Epoch 3592 / 10000) Train_Loss: 27.266; Val_Loss: 918.963   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.331; Val_NMI: 4.470\n",
      "(Epoch 3593 / 10000) Train_Loss: 27.494; Val_Loss: 1015.043   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.365; Val_NMI: 4.117\n",
      "(Epoch 3594 / 10000) Train_Loss: 26.569; Val_Loss: 973.530   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.383; Val_NMI: 4.468\n",
      "(Epoch 3595 / 10000) Train_Loss: 26.269; Val_Loss: 1046.012   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.256\n",
      "(Epoch 3596 / 10000) Train_Loss: 27.144; Val_Loss: 968.815   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.389; Val_NMI: 4.954\n",
      "(Epoch 3597 / 10000) Train_Loss: 27.447; Val_Loss: 972.677   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.148\n",
      "(Epoch 3598 / 10000) Train_Loss: 27.452; Val_Loss: 948.086   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 4.261\n",
      "(Epoch 3599 / 10000) Train_Loss: 26.501; Val_Loss: 974.237   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.343; Val_NMI: 4.953\n",
      "(Epoch 3600 / 10000) Train_Loss: 27.856; Val_Loss: 984.577   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.348; Val_NMI: 4.694\n",
      "(Epoch 3601 / 10000) Train_Loss: 28.685; Val_Loss: 974.290   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.424; Val_NMI: 4.002\n",
      "(Epoch 3602 / 10000) Train_Loss: 27.113; Val_Loss: 949.796   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.196\n",
      "(Epoch 3603 / 10000) Train_Loss: 27.613; Val_Loss: 992.093   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 4.215\n",
      "(Epoch 3604 / 10000) Train_Loss: 28.349; Val_Loss: 1016.677   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.305\n",
      "(Epoch 3605 / 10000) Train_Loss: 28.628; Val_Loss: 966.337   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3606 / 10000) Train_Loss: 28.622; Val_Loss: 949.065   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.418; Val_NMI: 3.682\n",
      "(Epoch 3607 / 10000) Train_Loss: 28.789; Val_Loss: 1070.749   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 4.343\n",
      "(Epoch 3608 / 10000) Train_Loss: 28.344; Val_Loss: 977.989   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.483\n",
      "(Epoch 3609 / 10000) Train_Loss: 27.611; Val_Loss: 984.465   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.282; Val_NMI: 4.290\n",
      "(Epoch 3610 / 10000) Train_Loss: 26.981; Val_Loss: 980.940   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.191\n",
      "(Epoch 3611 / 10000) Train_Loss: 26.655; Val_Loss: 987.719   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.307; Val_NMI: 4.408\n",
      "(Epoch 3612 / 10000) Train_Loss: 27.297; Val_Loss: 1003.523   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.358\n",
      "(Epoch 3613 / 10000) Train_Loss: 27.250; Val_Loss: 959.960   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.334; Val_NMI: 3.928\n",
      "(Epoch 3614 / 10000) Train_Loss: 26.854; Val_Loss: 930.049   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.324; Val_NMI: 3.800\n",
      "(Epoch 3615 / 10000) Train_Loss: 27.277; Val_Loss: 1002.413   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.415\n",
      "(Epoch 3616 / 10000) Train_Loss: 29.629; Val_Loss: 954.152   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.624\n",
      "(Epoch 3617 / 10000) Train_Loss: 31.662; Val_Loss: 965.563   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.388; Val_NMI: 3.938\n",
      "(Epoch 3618 / 10000) Train_Loss: 28.535; Val_Loss: 1031.243   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.992\n",
      "(Epoch 3619 / 10000) Train_Loss: 26.750; Val_Loss: 969.384   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.206\n",
      "(Epoch 3620 / 10000) Train_Loss: 26.658; Val_Loss: 983.895   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.123\n",
      "(Epoch 3621 / 10000) Train_Loss: 26.257; Val_Loss: 1006.626   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 4.548\n",
      "(Epoch 3622 / 10000) Train_Loss: 26.881; Val_Loss: 945.575   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.387; Val_NMI: 3.799\n",
      "(Epoch 3623 / 10000) Train_Loss: 27.616; Val_Loss: 1040.263   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.429\n",
      "(Epoch 3624 / 10000) Train_Loss: 30.837; Val_Loss: 963.330   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 4.537\n",
      "(Epoch 3625 / 10000) Train_Loss: 29.168; Val_Loss: 975.916   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.215\n",
      "(Epoch 3626 / 10000) Train_Loss: 27.360; Val_Loss: 950.596   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.303; Val_NMI: 3.899\n",
      "(Epoch 3627 / 10000) Train_Loss: 26.179; Val_Loss: 923.345   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.348\n",
      "(Epoch 3628 / 10000) Train_Loss: 27.128; Val_Loss: 993.346   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 4.221\n",
      "(Epoch 3629 / 10000) Train_Loss: 27.912; Val_Loss: 990.208   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.594\n",
      "(Epoch 3630 / 10000) Train_Loss: 28.368; Val_Loss: 968.885   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 3.862\n",
      "(Epoch 3631 / 10000) Train_Loss: 27.919; Val_Loss: 1001.831   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.408; Val_NMI: 3.834\n",
      "(Epoch 3632 / 10000) Train_Loss: 26.877; Val_Loss: 989.253   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 4.012\n",
      "(Epoch 3633 / 10000) Train_Loss: 27.614; Val_Loss: 980.328   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 3.656\n",
      "(Epoch 3634 / 10000) Train_Loss: 26.766; Val_Loss: 1011.175   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.210\n",
      "(Epoch 3635 / 10000) Train_Loss: 26.322; Val_Loss: 1026.839   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.137\n",
      "(Epoch 3636 / 10000) Train_Loss: 27.123; Val_Loss: 1017.521   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.180\n",
      "(Epoch 3637 / 10000) Train_Loss: 28.079; Val_Loss: 976.723   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 4.279\n",
      "(Epoch 3638 / 10000) Train_Loss: 27.309; Val_Loss: 991.338   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.316; Val_NMI: 3.167\n",
      "(Epoch 3639 / 10000) Train_Loss: 28.336; Val_Loss: 1046.524   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.020\n",
      "(Epoch 3640 / 10000) Train_Loss: 27.550; Val_Loss: 957.133   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.552\n",
      "(Epoch 3641 / 10000) Train_Loss: 27.337; Val_Loss: 1004.591   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.595\n",
      "(Epoch 3642 / 10000) Train_Loss: 27.341; Val_Loss: 1023.214   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.385; Val_NMI: 4.261\n",
      "(Epoch 3643 / 10000) Train_Loss: 28.534; Val_Loss: 952.880   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.406; Val_NMI: 4.141\n",
      "(Epoch 3644 / 10000) Train_Loss: 28.281; Val_Loss: 942.482   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 3.892\n",
      "(Epoch 3645 / 10000) Train_Loss: 27.286; Val_Loss: 992.347   Train_ACC: 15.280; Val_ACC: 18.889   Train_NMI: 0.405; Val_NMI: 3.457\n",
      "(Epoch 3646 / 10000) Train_Loss: 29.013; Val_Loss: 956.067   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 4.245\n",
      "(Epoch 3647 / 10000) Train_Loss: 27.340; Val_Loss: 1022.935   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 3.762\n",
      "(Epoch 3648 / 10000) Train_Loss: 27.407; Val_Loss: 972.527   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.337\n",
      "(Epoch 3649 / 10000) Train_Loss: 26.872; Val_Loss: 1005.625   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.317; Val_NMI: 4.325\n",
      "(Epoch 3650 / 10000) Train_Loss: 25.855; Val_Loss: 991.592   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.140\n",
      "(Epoch 3651 / 10000) Train_Loss: 26.594; Val_Loss: 938.854   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.513\n",
      "(Epoch 3652 / 10000) Train_Loss: 27.396; Val_Loss: 1032.749   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 4.123\n",
      "(Epoch 3653 / 10000) Train_Loss: 26.501; Val_Loss: 1017.878   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.251\n",
      "(Epoch 3654 / 10000) Train_Loss: 29.011; Val_Loss: 1075.240   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 4.055\n",
      "(Epoch 3655 / 10000) Train_Loss: 28.655; Val_Loss: 1011.446   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.476\n",
      "(Epoch 3656 / 10000) Train_Loss: 28.042; Val_Loss: 965.047   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.382; Val_NMI: 4.401\n",
      "(Epoch 3657 / 10000) Train_Loss: 27.087; Val_Loss: 998.524   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.882\n",
      "(Epoch 3658 / 10000) Train_Loss: 27.195; Val_Loss: 987.883   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 4.315\n",
      "(Epoch 3659 / 10000) Train_Loss: 27.001; Val_Loss: 1021.371   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 3.988\n",
      "(Epoch 3660 / 10000) Train_Loss: 26.288; Val_Loss: 1008.493   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.317; Val_NMI: 4.022\n",
      "(Epoch 3661 / 10000) Train_Loss: 26.176; Val_Loss: 981.445   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.195\n",
      "(Epoch 3662 / 10000) Train_Loss: 26.925; Val_Loss: 1007.347   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.346; Val_NMI: 3.652\n",
      "(Epoch 3663 / 10000) Train_Loss: 27.715; Val_Loss: 975.054   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.296; Val_NMI: 3.732\n",
      "(Epoch 3664 / 10000) Train_Loss: 30.197; Val_Loss: 1001.789   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.387; Val_NMI: 3.687\n",
      "(Epoch 3665 / 10000) Train_Loss: 29.516; Val_Loss: 1016.776   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.368; Val_NMI: 3.409\n",
      "(Epoch 3666 / 10000) Train_Loss: 28.361; Val_Loss: 1007.981   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.332; Val_NMI: 4.363\n",
      "(Epoch 3667 / 10000) Train_Loss: 26.988; Val_Loss: 961.720   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.012\n",
      "(Epoch 3668 / 10000) Train_Loss: 26.382; Val_Loss: 969.651   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 3.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3669 / 10000) Train_Loss: 27.193; Val_Loss: 976.201   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 3.476\n",
      "(Epoch 3670 / 10000) Train_Loss: 26.664; Val_Loss: 1070.777   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.026\n",
      "(Epoch 3671 / 10000) Train_Loss: 27.954; Val_Loss: 999.981   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.321; Val_NMI: 4.118\n",
      "(Epoch 3672 / 10000) Train_Loss: 27.600; Val_Loss: 944.066   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.315; Val_NMI: 3.494\n",
      "(Epoch 3673 / 10000) Train_Loss: 27.366; Val_Loss: 983.270   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 3.958\n",
      "(Epoch 3674 / 10000) Train_Loss: 25.994; Val_Loss: 990.340   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 4.111\n",
      "(Epoch 3675 / 10000) Train_Loss: 26.379; Val_Loss: 922.272   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.353; Val_NMI: 4.423\n",
      "(Epoch 3676 / 10000) Train_Loss: 27.866; Val_Loss: 1029.847   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.274; Val_NMI: 3.910\n",
      "(Epoch 3677 / 10000) Train_Loss: 27.622; Val_Loss: 1027.653   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 3.640\n",
      "(Epoch 3678 / 10000) Train_Loss: 27.137; Val_Loss: 980.380   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.013\n",
      "(Epoch 3679 / 10000) Train_Loss: 26.854; Val_Loss: 931.567   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.310\n",
      "(Epoch 3680 / 10000) Train_Loss: 26.474; Val_Loss: 999.110   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 3.887\n",
      "(Epoch 3681 / 10000) Train_Loss: 28.302; Val_Loss: 1019.866   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.302; Val_NMI: 4.038\n",
      "(Epoch 3682 / 10000) Train_Loss: 27.644; Val_Loss: 979.319   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 3.697\n",
      "(Epoch 3683 / 10000) Train_Loss: 29.315; Val_Loss: 1016.622   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.068\n",
      "(Epoch 3684 / 10000) Train_Loss: 27.389; Val_Loss: 1029.275   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.302; Val_NMI: 4.419\n",
      "(Epoch 3685 / 10000) Train_Loss: 31.773; Val_Loss: 1010.917   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 3.731\n",
      "(Epoch 3686 / 10000) Train_Loss: 28.541; Val_Loss: 996.611   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.349; Val_NMI: 3.712\n",
      "(Epoch 3687 / 10000) Train_Loss: 26.697; Val_Loss: 1009.107   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.383; Val_NMI: 3.644\n",
      "(Epoch 3688 / 10000) Train_Loss: 27.406; Val_Loss: 1008.885   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 3.572\n",
      "(Epoch 3689 / 10000) Train_Loss: 26.501; Val_Loss: 1059.882   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.343; Val_NMI: 4.486\n",
      "(Epoch 3690 / 10000) Train_Loss: 28.014; Val_Loss: 984.713   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.317; Val_NMI: 3.908\n",
      "(Epoch 3691 / 10000) Train_Loss: 27.881; Val_Loss: 960.214   Train_ACC: 15.404; Val_ACC: 18.519   Train_NMI: 0.399; Val_NMI: 3.491\n",
      "(Epoch 3692 / 10000) Train_Loss: 27.138; Val_Loss: 1016.853   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 3.668\n",
      "(Epoch 3693 / 10000) Train_Loss: 25.878; Val_Loss: 1000.782   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.311; Val_NMI: 3.930\n",
      "(Epoch 3694 / 10000) Train_Loss: 28.126; Val_Loss: 976.396   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.354; Val_NMI: 3.763\n",
      "(Epoch 3695 / 10000) Train_Loss: 32.273; Val_Loss: 993.111   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 3.589\n",
      "(Epoch 3696 / 10000) Train_Loss: 30.631; Val_Loss: 962.262   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.355; Val_NMI: 3.459\n",
      "(Epoch 3697 / 10000) Train_Loss: 28.412; Val_Loss: 966.513   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 4.426\n",
      "(Epoch 3698 / 10000) Train_Loss: 28.728; Val_Loss: 964.231   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.308; Val_NMI: 4.064\n",
      "(Epoch 3699 / 10000) Train_Loss: 36.540; Val_Loss: 1011.961   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.899\n",
      "(Epoch 3700 / 10000) Train_Loss: 41.911; Val_Loss: 1065.912   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 3.571\n",
      "(Epoch 3701 / 10000) Train_Loss: 36.172; Val_Loss: 939.410   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.372; Val_NMI: 4.365\n",
      "(Epoch 3702 / 10000) Train_Loss: 29.391; Val_Loss: 959.034   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.280; Val_NMI: 3.498\n",
      "(Epoch 3703 / 10000) Train_Loss: 27.242; Val_Loss: 918.754   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.301; Val_NMI: 3.686\n",
      "(Epoch 3704 / 10000) Train_Loss: 26.498; Val_Loss: 993.308   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.480\n",
      "(Epoch 3705 / 10000) Train_Loss: 25.829; Val_Loss: 1029.101   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.297; Val_NMI: 3.240\n",
      "(Epoch 3706 / 10000) Train_Loss: 26.007; Val_Loss: 1045.107   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 3.927\n",
      "(Epoch 3707 / 10000) Train_Loss: 25.934; Val_Loss: 991.528   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.413; Val_NMI: 3.778\n",
      "(Epoch 3708 / 10000) Train_Loss: 26.368; Val_Loss: 972.958   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.359\n",
      "(Epoch 3709 / 10000) Train_Loss: 25.669; Val_Loss: 990.278   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.312; Val_NMI: 3.518\n",
      "(Epoch 3710 / 10000) Train_Loss: 26.817; Val_Loss: 960.643   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.259; Val_NMI: 4.474\n",
      "(Epoch 3711 / 10000) Train_Loss: 26.734; Val_Loss: 1018.408   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.374; Val_NMI: 4.107\n",
      "(Epoch 3712 / 10000) Train_Loss: 27.977; Val_Loss: 1036.724   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.028\n",
      "(Epoch 3713 / 10000) Train_Loss: 28.238; Val_Loss: 1019.829   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.329; Val_NMI: 3.513\n",
      "(Epoch 3714 / 10000) Train_Loss: 29.335; Val_Loss: 986.356   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.268; Val_NMI: 4.171\n",
      "(Epoch 3715 / 10000) Train_Loss: 26.652; Val_Loss: 955.580   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.284; Val_NMI: 3.913\n",
      "(Epoch 3716 / 10000) Train_Loss: 27.304; Val_Loss: 953.652   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.395; Val_NMI: 3.530\n",
      "(Epoch 3717 / 10000) Train_Loss: 26.684; Val_Loss: 957.425   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.321; Val_NMI: 4.038\n",
      "(Epoch 3718 / 10000) Train_Loss: 26.294; Val_Loss: 919.567   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.209\n",
      "(Epoch 3719 / 10000) Train_Loss: 27.041; Val_Loss: 916.481   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.343; Val_NMI: 3.436\n",
      "(Epoch 3720 / 10000) Train_Loss: 28.541; Val_Loss: 937.513   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.313; Val_NMI: 4.209\n",
      "(Epoch 3721 / 10000) Train_Loss: 27.464; Val_Loss: 964.681   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.472\n",
      "(Epoch 3722 / 10000) Train_Loss: 27.261; Val_Loss: 984.155   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.298; Val_NMI: 4.097\n",
      "(Epoch 3723 / 10000) Train_Loss: 25.913; Val_Loss: 969.934   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.315; Val_NMI: 3.753\n",
      "(Epoch 3724 / 10000) Train_Loss: 25.558; Val_Loss: 980.518   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 3.715\n",
      "(Epoch 3725 / 10000) Train_Loss: 27.221; Val_Loss: 996.444   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.345; Val_NMI: 3.856\n",
      "(Epoch 3726 / 10000) Train_Loss: 27.118; Val_Loss: 958.562   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.041\n",
      "(Epoch 3727 / 10000) Train_Loss: 26.495; Val_Loss: 926.206   Train_ACC: 15.115; Val_ACC: 20.370   Train_NMI: 0.369; Val_NMI: 4.379\n",
      "(Epoch 3728 / 10000) Train_Loss: 27.158; Val_Loss: 1005.613   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 3.787\n",
      "(Epoch 3729 / 10000) Train_Loss: 26.068; Val_Loss: 977.963   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.724\n",
      "(Epoch 3730 / 10000) Train_Loss: 26.223; Val_Loss: 979.263   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.654\n",
      "(Epoch 3731 / 10000) Train_Loss: 26.289; Val_Loss: 1028.625   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.394; Val_NMI: 2.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3732 / 10000) Train_Loss: 28.256; Val_Loss: 1026.288   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.292; Val_NMI: 4.425\n",
      "(Epoch 3733 / 10000) Train_Loss: 27.456; Val_Loss: 991.340   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.314; Val_NMI: 4.223\n",
      "(Epoch 3734 / 10000) Train_Loss: 27.027; Val_Loss: 1059.989   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.371; Val_NMI: 3.744\n",
      "(Epoch 3735 / 10000) Train_Loss: 26.605; Val_Loss: 989.129   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.320; Val_NMI: 4.476\n",
      "(Epoch 3736 / 10000) Train_Loss: 28.072; Val_Loss: 998.535   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.391; Val_NMI: 4.170\n",
      "(Epoch 3737 / 10000) Train_Loss: 27.908; Val_Loss: 973.726   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.279; Val_NMI: 4.221\n",
      "(Epoch 3738 / 10000) Train_Loss: 26.663; Val_Loss: 938.466   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.297; Val_NMI: 4.117\n",
      "(Epoch 3739 / 10000) Train_Loss: 25.972; Val_Loss: 945.170   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 3.977\n",
      "(Epoch 3740 / 10000) Train_Loss: 25.946; Val_Loss: 1013.107   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.319; Val_NMI: 3.320\n",
      "(Epoch 3741 / 10000) Train_Loss: 25.930; Val_Loss: 1024.862   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.408; Val_NMI: 3.963\n",
      "(Epoch 3742 / 10000) Train_Loss: 26.530; Val_Loss: 1017.731   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.351; Val_NMI: 3.408\n",
      "(Epoch 3743 / 10000) Train_Loss: 26.896; Val_Loss: 971.918   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 3.630\n",
      "(Epoch 3744 / 10000) Train_Loss: 26.990; Val_Loss: 1021.247   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.044\n",
      "(Epoch 3745 / 10000) Train_Loss: 26.648; Val_Loss: 929.049   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 3.849\n",
      "(Epoch 3746 / 10000) Train_Loss: 27.077; Val_Loss: 952.418   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.326; Val_NMI: 4.897\n",
      "(Epoch 3747 / 10000) Train_Loss: 27.626; Val_Loss: 965.328   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.303; Val_NMI: 4.252\n",
      "(Epoch 3748 / 10000) Train_Loss: 28.668; Val_Loss: 1005.543   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.358; Val_NMI: 3.995\n",
      "(Epoch 3749 / 10000) Train_Loss: 27.531; Val_Loss: 996.302   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 3.538\n",
      "(Epoch 3750 / 10000) Train_Loss: 27.176; Val_Loss: 978.334   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 3.611\n",
      "(Epoch 3751 / 10000) Train_Loss: 28.216; Val_Loss: 1004.589   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 3.994\n",
      "(Epoch 3752 / 10000) Train_Loss: 26.661; Val_Loss: 986.178   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.081\n",
      "(Epoch 3753 / 10000) Train_Loss: 26.425; Val_Loss: 991.825   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 3.856\n",
      "(Epoch 3754 / 10000) Train_Loss: 27.191; Val_Loss: 1023.576   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 4.009\n",
      "(Epoch 3755 / 10000) Train_Loss: 27.535; Val_Loss: 905.265   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 4.494\n",
      "(Epoch 3756 / 10000) Train_Loss: 27.509; Val_Loss: 1033.522   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.183\n",
      "(Epoch 3757 / 10000) Train_Loss: 26.687; Val_Loss: 929.447   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.360; Val_NMI: 4.263\n",
      "(Epoch 3758 / 10000) Train_Loss: 27.508; Val_Loss: 1001.071   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 3.667\n",
      "(Epoch 3759 / 10000) Train_Loss: 28.277; Val_Loss: 968.624   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 4.181\n",
      "(Epoch 3760 / 10000) Train_Loss: 29.195; Val_Loss: 959.116   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.330\n",
      "(Epoch 3761 / 10000) Train_Loss: 26.826; Val_Loss: 1001.503   Train_ACC: 15.239; Val_ACC: 18.889   Train_NMI: 0.391; Val_NMI: 3.606\n",
      "(Epoch 3762 / 10000) Train_Loss: 25.567; Val_Loss: 993.017   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.682\n",
      "(Epoch 3763 / 10000) Train_Loss: 26.046; Val_Loss: 951.269   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 3.883\n",
      "(Epoch 3764 / 10000) Train_Loss: 26.507; Val_Loss: 981.700   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.329; Val_NMI: 4.724\n",
      "(Epoch 3765 / 10000) Train_Loss: 28.340; Val_Loss: 996.559   Train_ACC: 15.239; Val_ACC: 19.630   Train_NMI: 0.407; Val_NMI: 4.695\n",
      "(Epoch 3766 / 10000) Train_Loss: 28.963; Val_Loss: 982.040   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.573\n",
      "(Epoch 3767 / 10000) Train_Loss: 28.363; Val_Loss: 961.286   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 4.532\n",
      "(Epoch 3768 / 10000) Train_Loss: 26.746; Val_Loss: 985.443   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 4.613\n",
      "(Epoch 3769 / 10000) Train_Loss: 28.211; Val_Loss: 1008.885   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 3.692\n",
      "(Epoch 3770 / 10000) Train_Loss: 32.985; Val_Loss: 983.258   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.327; Val_NMI: 3.790\n",
      "(Epoch 3771 / 10000) Train_Loss: 29.094; Val_Loss: 977.610   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.383; Val_NMI: 3.891\n",
      "(Epoch 3772 / 10000) Train_Loss: 26.499; Val_Loss: 961.857   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 4.169\n",
      "(Epoch 3773 / 10000) Train_Loss: 28.141; Val_Loss: 1019.530   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 4.336\n",
      "(Epoch 3774 / 10000) Train_Loss: 27.938; Val_Loss: 1006.857   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 4.012\n",
      "(Epoch 3775 / 10000) Train_Loss: 27.661; Val_Loss: 979.730   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.321; Val_NMI: 3.340\n",
      "(Epoch 3776 / 10000) Train_Loss: 27.830; Val_Loss: 948.668   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 3.958\n",
      "(Epoch 3777 / 10000) Train_Loss: 26.186; Val_Loss: 943.395   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.337; Val_NMI: 3.886\n",
      "(Epoch 3778 / 10000) Train_Loss: 25.904; Val_Loss: 995.145   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.163\n",
      "(Epoch 3779 / 10000) Train_Loss: 27.240; Val_Loss: 994.150   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 4.395\n",
      "(Epoch 3780 / 10000) Train_Loss: 27.160; Val_Loss: 958.552   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 3.829\n",
      "(Epoch 3781 / 10000) Train_Loss: 27.879; Val_Loss: 969.325   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.361\n",
      "(Epoch 3782 / 10000) Train_Loss: 26.356; Val_Loss: 1013.795   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 3.960\n",
      "(Epoch 3783 / 10000) Train_Loss: 26.340; Val_Loss: 1008.533   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 3.867\n",
      "(Epoch 3784 / 10000) Train_Loss: 31.419; Val_Loss: 1050.675   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.433; Val_NMI: 4.142\n",
      "(Epoch 3785 / 10000) Train_Loss: 32.440; Val_Loss: 983.446   Train_ACC: 15.321; Val_ACC: 19.630   Train_NMI: 0.425; Val_NMI: 3.780\n",
      "(Epoch 3786 / 10000) Train_Loss: 28.648; Val_Loss: 955.742   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.376; Val_NMI: 4.460\n",
      "(Epoch 3787 / 10000) Train_Loss: 27.951; Val_Loss: 951.374   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 3.723\n",
      "(Epoch 3788 / 10000) Train_Loss: 26.898; Val_Loss: 1033.772   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.030\n",
      "(Epoch 3789 / 10000) Train_Loss: 27.840; Val_Loss: 1004.038   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.384; Val_NMI: 4.451\n",
      "(Epoch 3790 / 10000) Train_Loss: 27.715; Val_Loss: 1023.683   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.385; Val_NMI: 3.644\n",
      "(Epoch 3791 / 10000) Train_Loss: 29.184; Val_Loss: 977.941   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.371; Val_NMI: 4.050\n",
      "(Epoch 3792 / 10000) Train_Loss: 27.639; Val_Loss: 991.260   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 3.941\n",
      "(Epoch 3793 / 10000) Train_Loss: 27.051; Val_Loss: 980.732   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.367; Val_NMI: 3.792\n",
      "(Epoch 3794 / 10000) Train_Loss: 26.433; Val_Loss: 1007.671   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3795 / 10000) Train_Loss: 26.218; Val_Loss: 999.379   Train_ACC: 15.239; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.489\n",
      "(Epoch 3796 / 10000) Train_Loss: 27.465; Val_Loss: 953.436   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.374; Val_NMI: 4.548\n",
      "(Epoch 3797 / 10000) Train_Loss: 28.227; Val_Loss: 1028.600   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.391; Val_NMI: 4.261\n",
      "(Epoch 3798 / 10000) Train_Loss: 27.428; Val_Loss: 987.436   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.070\n",
      "(Epoch 3799 / 10000) Train_Loss: 27.651; Val_Loss: 998.084   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.295; Val_NMI: 3.895\n",
      "(Epoch 3800 / 10000) Train_Loss: 28.275; Val_Loss: 1008.770   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.293; Val_NMI: 3.161\n",
      "(Epoch 3801 / 10000) Train_Loss: 26.785; Val_Loss: 960.526   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.355; Val_NMI: 3.855\n",
      "(Epoch 3802 / 10000) Train_Loss: 27.417; Val_Loss: 995.261   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.183\n",
      "(Epoch 3803 / 10000) Train_Loss: 26.408; Val_Loss: 956.098   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 3.952\n",
      "(Epoch 3804 / 10000) Train_Loss: 28.097; Val_Loss: 993.158   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.332; Val_NMI: 3.522\n",
      "(Epoch 3805 / 10000) Train_Loss: 28.953; Val_Loss: 1044.937   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.390; Val_NMI: 4.163\n",
      "(Epoch 3806 / 10000) Train_Loss: 28.786; Val_Loss: 997.382   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.355; Val_NMI: 4.356\n",
      "(Epoch 3807 / 10000) Train_Loss: 29.092; Val_Loss: 1052.564   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 4.071\n",
      "(Epoch 3808 / 10000) Train_Loss: 27.725; Val_Loss: 1008.380   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 3.673\n",
      "(Epoch 3809 / 10000) Train_Loss: 26.444; Val_Loss: 1027.092   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.064\n",
      "(Epoch 3810 / 10000) Train_Loss: 28.727; Val_Loss: 992.698   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.304; Val_NMI: 4.041\n",
      "(Epoch 3811 / 10000) Train_Loss: 28.057; Val_Loss: 976.317   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.324; Val_NMI: 4.148\n",
      "(Epoch 3812 / 10000) Train_Loss: 27.393; Val_Loss: 948.639   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.290; Val_NMI: 4.372\n",
      "(Epoch 3813 / 10000) Train_Loss: 27.610; Val_Loss: 1039.188   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.349; Val_NMI: 3.899\n",
      "(Epoch 3814 / 10000) Train_Loss: 26.709; Val_Loss: 924.162   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 3.636\n",
      "(Epoch 3815 / 10000) Train_Loss: 26.855; Val_Loss: 1047.739   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.387; Val_NMI: 3.978\n",
      "(Epoch 3816 / 10000) Train_Loss: 26.713; Val_Loss: 1026.377   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 3.699\n",
      "(Epoch 3817 / 10000) Train_Loss: 25.958; Val_Loss: 1053.634   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.138\n",
      "(Epoch 3818 / 10000) Train_Loss: 26.510; Val_Loss: 1020.215   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.338; Val_NMI: 4.235\n",
      "(Epoch 3819 / 10000) Train_Loss: 27.744; Val_Loss: 974.903   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.304; Val_NMI: 4.575\n",
      "(Epoch 3820 / 10000) Train_Loss: 27.845; Val_Loss: 998.016   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.118\n",
      "(Epoch 3821 / 10000) Train_Loss: 26.306; Val_Loss: 988.176   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.771\n",
      "(Epoch 3822 / 10000) Train_Loss: 25.898; Val_Loss: 1007.056   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 3.584\n",
      "(Epoch 3823 / 10000) Train_Loss: 27.132; Val_Loss: 974.706   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.179\n",
      "(Epoch 3824 / 10000) Train_Loss: 27.126; Val_Loss: 1060.827   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.360; Val_NMI: 3.528\n",
      "(Epoch 3825 / 10000) Train_Loss: 27.072; Val_Loss: 1047.208   Train_ACC: 15.074; Val_ACC: 18.889   Train_NMI: 0.380; Val_NMI: 3.555\n",
      "(Epoch 3826 / 10000) Train_Loss: 25.945; Val_Loss: 997.598   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.041\n",
      "(Epoch 3827 / 10000) Train_Loss: 28.263; Val_Loss: 936.794   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.399; Val_NMI: 3.775\n",
      "(Epoch 3828 / 10000) Train_Loss: 34.428; Val_Loss: 1043.972   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 3.617\n",
      "(Epoch 3829 / 10000) Train_Loss: 31.720; Val_Loss: 987.725   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.360; Val_NMI: 4.280\n",
      "(Epoch 3830 / 10000) Train_Loss: 28.638; Val_Loss: 966.237   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.311; Val_NMI: 3.900\n",
      "(Epoch 3831 / 10000) Train_Loss: 27.934; Val_Loss: 1005.419   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.027\n",
      "(Epoch 3832 / 10000) Train_Loss: 28.998; Val_Loss: 999.370   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.318; Val_NMI: 3.824\n",
      "(Epoch 3833 / 10000) Train_Loss: 29.186; Val_Loss: 1003.872   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 3.825\n",
      "(Epoch 3834 / 10000) Train_Loss: 27.408; Val_Loss: 1005.402   Train_ACC: 15.157; Val_ACC: 19.259   Train_NMI: 0.373; Val_NMI: 4.042\n",
      "(Epoch 3835 / 10000) Train_Loss: 28.555; Val_Loss: 931.540   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 3.900\n",
      "(Epoch 3836 / 10000) Train_Loss: 30.418; Val_Loss: 976.564   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.350; Val_NMI: 3.727\n",
      "(Epoch 3837 / 10000) Train_Loss: 28.387; Val_Loss: 989.246   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 4.284\n",
      "(Epoch 3838 / 10000) Train_Loss: 26.589; Val_Loss: 1003.256   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 3.697\n",
      "(Epoch 3839 / 10000) Train_Loss: 25.746; Val_Loss: 949.198   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.338; Val_NMI: 3.319\n",
      "(Epoch 3840 / 10000) Train_Loss: 26.156; Val_Loss: 1028.923   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 3.859\n",
      "(Epoch 3841 / 10000) Train_Loss: 26.621; Val_Loss: 942.446   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.385; Val_NMI: 3.464\n",
      "(Epoch 3842 / 10000) Train_Loss: 27.707; Val_Loss: 916.946   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.317; Val_NMI: 4.158\n",
      "(Epoch 3843 / 10000) Train_Loss: 26.527; Val_Loss: 947.498   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 3.935\n",
      "(Epoch 3844 / 10000) Train_Loss: 25.982; Val_Loss: 1025.466   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.349; Val_NMI: 4.111\n",
      "(Epoch 3845 / 10000) Train_Loss: 26.995; Val_Loss: 927.192   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.801\n",
      "(Epoch 3846 / 10000) Train_Loss: 27.035; Val_Loss: 980.255   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.303; Val_NMI: 3.911\n",
      "(Epoch 3847 / 10000) Train_Loss: 26.168; Val_Loss: 989.384   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 3.702\n",
      "(Epoch 3848 / 10000) Train_Loss: 25.885; Val_Loss: 971.918   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 3.995\n",
      "(Epoch 3849 / 10000) Train_Loss: 25.409; Val_Loss: 958.005   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.368; Val_NMI: 3.518\n",
      "(Epoch 3850 / 10000) Train_Loss: 26.967; Val_Loss: 996.156   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.391; Val_NMI: 3.862\n",
      "(Epoch 3851 / 10000) Train_Loss: 28.522; Val_Loss: 1000.772   Train_ACC: 15.074; Val_ACC: 20.370   Train_NMI: 0.386; Val_NMI: 4.644\n",
      "(Epoch 3852 / 10000) Train_Loss: 30.002; Val_Loss: 992.605   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 4.187\n",
      "(Epoch 3853 / 10000) Train_Loss: 27.877; Val_Loss: 1013.217   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 3.882\n",
      "(Epoch 3854 / 10000) Train_Loss: 26.308; Val_Loss: 1002.291   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 4.395\n",
      "(Epoch 3855 / 10000) Train_Loss: 27.145; Val_Loss: 966.286   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.395\n",
      "(Epoch 3856 / 10000) Train_Loss: 27.986; Val_Loss: 1025.984   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.080\n",
      "(Epoch 3857 / 10000) Train_Loss: 27.415; Val_Loss: 988.516   Train_ACC: 14.951; Val_ACC: 20.741   Train_NMI: 0.333; Val_NMI: 4.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3858 / 10000) Train_Loss: 32.299; Val_Loss: 952.969   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.244\n",
      "(Epoch 3859 / 10000) Train_Loss: 27.948; Val_Loss: 950.521   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.334; Val_NMI: 3.850\n",
      "(Epoch 3860 / 10000) Train_Loss: 27.443; Val_Loss: 970.993   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.225\n",
      "(Epoch 3861 / 10000) Train_Loss: 27.190; Val_Loss: 948.940   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.308; Val_NMI: 4.534\n",
      "(Epoch 3862 / 10000) Train_Loss: 26.358; Val_Loss: 959.825   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.318; Val_NMI: 4.739\n",
      "(Epoch 3863 / 10000) Train_Loss: 27.373; Val_Loss: 1008.464   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 4.648\n",
      "(Epoch 3864 / 10000) Train_Loss: 28.049; Val_Loss: 1005.972   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.308\n",
      "(Epoch 3865 / 10000) Train_Loss: 26.954; Val_Loss: 949.048   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 4.312\n",
      "(Epoch 3866 / 10000) Train_Loss: 26.565; Val_Loss: 953.584   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.368; Val_NMI: 4.571\n",
      "(Epoch 3867 / 10000) Train_Loss: 27.240; Val_Loss: 956.072   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.029\n",
      "(Epoch 3868 / 10000) Train_Loss: 25.601; Val_Loss: 949.902   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.373; Val_NMI: 4.069\n",
      "(Epoch 3869 / 10000) Train_Loss: 27.558; Val_Loss: 961.305   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.356; Val_NMI: 4.314\n",
      "(Epoch 3870 / 10000) Train_Loss: 27.891; Val_Loss: 987.032   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.299; Val_NMI: 4.701\n",
      "(Epoch 3871 / 10000) Train_Loss: 26.411; Val_Loss: 964.801   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.314; Val_NMI: 4.022\n",
      "(Epoch 3872 / 10000) Train_Loss: 26.016; Val_Loss: 954.398   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.390; Val_NMI: 3.606\n",
      "(Epoch 3873 / 10000) Train_Loss: 28.645; Val_Loss: 1007.122   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.536\n",
      "(Epoch 3874 / 10000) Train_Loss: 27.784; Val_Loss: 943.844   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.368; Val_NMI: 4.276\n",
      "(Epoch 3875 / 10000) Train_Loss: 27.296; Val_Loss: 991.717   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.283\n",
      "(Epoch 3876 / 10000) Train_Loss: 25.989; Val_Loss: 956.418   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.067\n",
      "(Epoch 3877 / 10000) Train_Loss: 27.808; Val_Loss: 1009.291   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.417; Val_NMI: 4.442\n",
      "(Epoch 3878 / 10000) Train_Loss: 30.186; Val_Loss: 972.460   Train_ACC: 14.827; Val_ACC: 18.148   Train_NMI: 0.368; Val_NMI: 2.998\n",
      "(Epoch 3879 / 10000) Train_Loss: 28.705; Val_Loss: 1011.704   Train_ACC: 15.321; Val_ACC: 18.519   Train_NMI: 0.401; Val_NMI: 3.343\n",
      "(Epoch 3880 / 10000) Train_Loss: 29.261; Val_Loss: 977.971   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.382; Val_NMI: 3.606\n",
      "(Epoch 3881 / 10000) Train_Loss: 31.995; Val_Loss: 1032.763   Train_ACC: 15.033; Val_ACC: 18.519   Train_NMI: 0.363; Val_NMI: 3.470\n",
      "(Epoch 3882 / 10000) Train_Loss: 28.282; Val_Loss: 1036.767   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.339; Val_NMI: 3.307\n",
      "(Epoch 3883 / 10000) Train_Loss: 27.054; Val_Loss: 995.190   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.375; Val_NMI: 4.341\n",
      "(Epoch 3884 / 10000) Train_Loss: 26.990; Val_Loss: 945.492   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 4.398\n",
      "(Epoch 3885 / 10000) Train_Loss: 26.990; Val_Loss: 1019.509   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.076\n",
      "(Epoch 3886 / 10000) Train_Loss: 26.175; Val_Loss: 947.543   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 3.818\n",
      "(Epoch 3887 / 10000) Train_Loss: 26.223; Val_Loss: 987.214   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 3.975\n",
      "(Epoch 3888 / 10000) Train_Loss: 26.061; Val_Loss: 987.951   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 4.138\n",
      "(Epoch 3889 / 10000) Train_Loss: 27.828; Val_Loss: 995.951   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.440\n",
      "(Epoch 3890 / 10000) Train_Loss: 26.855; Val_Loss: 897.886   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.359; Val_NMI: 4.397\n",
      "(Epoch 3891 / 10000) Train_Loss: 26.589; Val_Loss: 999.756   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.991\n",
      "(Epoch 3892 / 10000) Train_Loss: 27.920; Val_Loss: 974.471   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.153\n",
      "(Epoch 3893 / 10000) Train_Loss: 27.040; Val_Loss: 1012.058   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.002\n",
      "(Epoch 3894 / 10000) Train_Loss: 27.338; Val_Loss: 972.600   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.401; Val_NMI: 3.844\n",
      "(Epoch 3895 / 10000) Train_Loss: 27.630; Val_Loss: 945.322   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 4.424\n",
      "(Epoch 3896 / 10000) Train_Loss: 27.100; Val_Loss: 997.455   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.351; Val_NMI: 4.069\n",
      "(Epoch 3897 / 10000) Train_Loss: 28.087; Val_Loss: 984.090   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.340; Val_NMI: 3.912\n",
      "(Epoch 3898 / 10000) Train_Loss: 29.821; Val_Loss: 1011.919   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.311; Val_NMI: 3.805\n",
      "(Epoch 3899 / 10000) Train_Loss: 32.977; Val_Loss: 990.109   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 4.255\n",
      "(Epoch 3900 / 10000) Train_Loss: 30.060; Val_Loss: 1038.826   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.162\n",
      "(Epoch 3901 / 10000) Train_Loss: 27.182; Val_Loss: 985.526   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 3.830\n",
      "(Epoch 3902 / 10000) Train_Loss: 26.900; Val_Loss: 1050.368   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.283; Val_NMI: 4.255\n",
      "(Epoch 3903 / 10000) Train_Loss: 27.375; Val_Loss: 1017.174   Train_ACC: 14.786; Val_ACC: 18.519   Train_NMI: 0.326; Val_NMI: 4.171\n",
      "(Epoch 3904 / 10000) Train_Loss: 28.270; Val_Loss: 1026.915   Train_ACC: 14.703; Val_ACC: 18.519   Train_NMI: 0.348; Val_NMI: 3.476\n",
      "(Epoch 3905 / 10000) Train_Loss: 29.406; Val_Loss: 1039.767   Train_ACC: 14.703; Val_ACC: 18.148   Train_NMI: 0.285; Val_NMI: 3.287\n",
      "(Epoch 3906 / 10000) Train_Loss: 26.908; Val_Loss: 950.051   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.978\n",
      "(Epoch 3907 / 10000) Train_Loss: 26.232; Val_Loss: 993.202   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.319; Val_NMI: 4.340\n",
      "(Epoch 3908 / 10000) Train_Loss: 26.840; Val_Loss: 914.397   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.315; Val_NMI: 4.129\n",
      "(Epoch 3909 / 10000) Train_Loss: 26.796; Val_Loss: 1051.465   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.313; Val_NMI: 3.799\n",
      "(Epoch 3910 / 10000) Train_Loss: 26.628; Val_Loss: 988.382   Train_ACC: 14.621; Val_ACC: 18.148   Train_NMI: 0.325; Val_NMI: 3.287\n",
      "(Epoch 3911 / 10000) Train_Loss: 27.880; Val_Loss: 978.928   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 3.499\n",
      "(Epoch 3912 / 10000) Train_Loss: 26.498; Val_Loss: 1011.426   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 3.587\n",
      "(Epoch 3913 / 10000) Train_Loss: 28.037; Val_Loss: 957.668   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 3.893\n",
      "(Epoch 3914 / 10000) Train_Loss: 26.364; Val_Loss: 932.147   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 3.935\n",
      "(Epoch 3915 / 10000) Train_Loss: 26.586; Val_Loss: 1071.807   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 3.415\n",
      "(Epoch 3916 / 10000) Train_Loss: 26.684; Val_Loss: 983.071   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 4.077\n",
      "(Epoch 3917 / 10000) Train_Loss: 26.428; Val_Loss: 1009.291   Train_ACC: 15.239; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.300\n",
      "(Epoch 3918 / 10000) Train_Loss: 27.180; Val_Loss: 975.128   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.288; Val_NMI: 3.689\n",
      "(Epoch 3919 / 10000) Train_Loss: 26.316; Val_Loss: 973.805   Train_ACC: 14.745; Val_ACC: 18.519   Train_NMI: 0.349; Val_NMI: 3.873\n",
      "(Epoch 3920 / 10000) Train_Loss: 25.361; Val_Loss: 999.963   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.346; Val_NMI: 3.731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3921 / 10000) Train_Loss: 25.511; Val_Loss: 1024.048   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 4.306\n",
      "(Epoch 3922 / 10000) Train_Loss: 26.641; Val_Loss: 996.467   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.472\n",
      "(Epoch 3923 / 10000) Train_Loss: 27.804; Val_Loss: 993.523   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.313; Val_NMI: 4.075\n",
      "(Epoch 3924 / 10000) Train_Loss: 27.022; Val_Loss: 994.188   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.325; Val_NMI: 4.229\n",
      "(Epoch 3925 / 10000) Train_Loss: 28.703; Val_Loss: 998.651   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 3.601\n",
      "(Epoch 3926 / 10000) Train_Loss: 29.376; Val_Loss: 1027.642   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.407; Val_NMI: 3.608\n",
      "(Epoch 3927 / 10000) Train_Loss: 28.008; Val_Loss: 1000.388   Train_ACC: 14.909; Val_ACC: 18.148   Train_NMI: 0.422; Val_NMI: 3.829\n",
      "(Epoch 3928 / 10000) Train_Loss: 27.011; Val_Loss: 1026.494   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.381\n",
      "(Epoch 3929 / 10000) Train_Loss: 27.421; Val_Loss: 1005.778   Train_ACC: 15.198; Val_ACC: 18.519   Train_NMI: 0.366; Val_NMI: 3.416\n",
      "(Epoch 3930 / 10000) Train_Loss: 26.013; Val_Loss: 989.981   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.673\n",
      "(Epoch 3931 / 10000) Train_Loss: 26.979; Val_Loss: 1015.274   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.318; Val_NMI: 3.993\n",
      "(Epoch 3932 / 10000) Train_Loss: 28.371; Val_Loss: 989.070   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.369; Val_NMI: 4.049\n",
      "(Epoch 3933 / 10000) Train_Loss: 27.485; Val_Loss: 936.182   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.145\n",
      "(Epoch 3934 / 10000) Train_Loss: 26.260; Val_Loss: 1031.712   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.305; Val_NMI: 3.622\n",
      "(Epoch 3935 / 10000) Train_Loss: 27.791; Val_Loss: 993.741   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.315; Val_NMI: 4.037\n",
      "(Epoch 3936 / 10000) Train_Loss: 27.619; Val_Loss: 1027.815   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.282; Val_NMI: 3.334\n",
      "(Epoch 3937 / 10000) Train_Loss: 32.029; Val_Loss: 1038.835   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.367; Val_NMI: 3.941\n",
      "(Epoch 3938 / 10000) Train_Loss: 33.383; Val_Loss: 939.834   Train_ACC: 14.539; Val_ACC: 18.519   Train_NMI: 0.279; Val_NMI: 3.923\n",
      "(Epoch 3939 / 10000) Train_Loss: 29.801; Val_Loss: 960.609   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 3.648\n",
      "(Epoch 3940 / 10000) Train_Loss: 27.303; Val_Loss: 985.469   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.900\n",
      "(Epoch 3941 / 10000) Train_Loss: 28.171; Val_Loss: 948.186   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.378; Val_NMI: 4.283\n",
      "(Epoch 3942 / 10000) Train_Loss: 31.204; Val_Loss: 1015.267   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.745\n",
      "(Epoch 3943 / 10000) Train_Loss: 30.995; Val_Loss: 994.697   Train_ACC: 14.745; Val_ACC: 20.741   Train_NMI: 0.421; Val_NMI: 3.840\n",
      "(Epoch 3944 / 10000) Train_Loss: 28.227; Val_Loss: 1005.232   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 4.236\n",
      "(Epoch 3945 / 10000) Train_Loss: 27.972; Val_Loss: 1002.245   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 3.840\n",
      "(Epoch 3946 / 10000) Train_Loss: 27.194; Val_Loss: 939.458   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.347; Val_NMI: 4.202\n",
      "(Epoch 3947 / 10000) Train_Loss: 26.725; Val_Loss: 1009.892   Train_ACC: 15.033; Val_ACC: 20.370   Train_NMI: 0.368; Val_NMI: 4.465\n",
      "(Epoch 3948 / 10000) Train_Loss: 26.363; Val_Loss: 1029.311   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.317; Val_NMI: 4.153\n",
      "(Epoch 3949 / 10000) Train_Loss: 28.908; Val_Loss: 972.189   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.326; Val_NMI: 4.120\n",
      "(Epoch 3950 / 10000) Train_Loss: 28.085; Val_Loss: 1001.327   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.323; Val_NMI: 3.998\n",
      "(Epoch 3951 / 10000) Train_Loss: 27.633; Val_Loss: 1013.397   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.295; Val_NMI: 4.000\n",
      "(Epoch 3952 / 10000) Train_Loss: 26.613; Val_Loss: 957.963   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.321; Val_NMI: 4.100\n",
      "(Epoch 3953 / 10000) Train_Loss: 26.171; Val_Loss: 1029.628   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 3.574\n",
      "(Epoch 3954 / 10000) Train_Loss: 26.018; Val_Loss: 1027.239   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.354; Val_NMI: 4.297\n",
      "(Epoch 3955 / 10000) Train_Loss: 26.032; Val_Loss: 1032.928   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 3.529\n",
      "(Epoch 3956 / 10000) Train_Loss: 29.163; Val_Loss: 908.687   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.279; Val_NMI: 3.917\n",
      "(Epoch 3957 / 10000) Train_Loss: 28.396; Val_Loss: 962.096   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.327; Val_NMI: 3.981\n",
      "(Epoch 3958 / 10000) Train_Loss: 27.539; Val_Loss: 1067.393   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 4.080\n",
      "(Epoch 3959 / 10000) Train_Loss: 27.678; Val_Loss: 987.157   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 3.981\n",
      "(Epoch 3960 / 10000) Train_Loss: 27.023; Val_Loss: 1019.589   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.366; Val_NMI: 4.347\n",
      "(Epoch 3961 / 10000) Train_Loss: 26.796; Val_Loss: 974.609   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.336\n",
      "(Epoch 3962 / 10000) Train_Loss: 26.123; Val_Loss: 1005.350   Train_ACC: 14.580; Val_ACC: 20.370   Train_NMI: 0.292; Val_NMI: 3.982\n",
      "(Epoch 3963 / 10000) Train_Loss: 25.965; Val_Loss: 1050.881   Train_ACC: 14.498; Val_ACC: 20.370   Train_NMI: 0.298; Val_NMI: 4.392\n",
      "(Epoch 3964 / 10000) Train_Loss: 25.937; Val_Loss: 1030.855   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.105\n",
      "(Epoch 3965 / 10000) Train_Loss: 26.992; Val_Loss: 1008.452   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 4.212\n",
      "(Epoch 3966 / 10000) Train_Loss: 32.854; Val_Loss: 993.718   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.313; Val_NMI: 4.336\n",
      "(Epoch 3967 / 10000) Train_Loss: 27.958; Val_Loss: 953.402   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.332; Val_NMI: 4.893\n",
      "(Epoch 3968 / 10000) Train_Loss: 27.304; Val_Loss: 999.345   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.333; Val_NMI: 4.445\n",
      "(Epoch 3969 / 10000) Train_Loss: 28.945; Val_Loss: 1023.992   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 4.045\n",
      "(Epoch 3970 / 10000) Train_Loss: 28.462; Val_Loss: 969.922   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 4.072\n",
      "(Epoch 3971 / 10000) Train_Loss: 27.250; Val_Loss: 940.592   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.310; Val_NMI: 3.955\n",
      "(Epoch 3972 / 10000) Train_Loss: 28.051; Val_Loss: 1028.218   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.316; Val_NMI: 4.194\n",
      "(Epoch 3973 / 10000) Train_Loss: 27.401; Val_Loss: 1062.185   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.313; Val_NMI: 4.097\n",
      "(Epoch 3974 / 10000) Train_Loss: 27.312; Val_Loss: 989.530   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.286; Val_NMI: 4.356\n",
      "(Epoch 3975 / 10000) Train_Loss: 26.659; Val_Loss: 1037.376   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.314; Val_NMI: 4.251\n",
      "(Epoch 3976 / 10000) Train_Loss: 26.698; Val_Loss: 983.826   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.453\n",
      "(Epoch 3977 / 10000) Train_Loss: 25.729; Val_Loss: 1019.625   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 3.934\n",
      "(Epoch 3978 / 10000) Train_Loss: 28.778; Val_Loss: 953.916   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.306; Val_NMI: 4.003\n",
      "(Epoch 3979 / 10000) Train_Loss: 35.186; Val_Loss: 1051.561   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 3.895\n",
      "(Epoch 3980 / 10000) Train_Loss: 30.370; Val_Loss: 974.745   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.289; Val_NMI: 3.476\n",
      "(Epoch 3981 / 10000) Train_Loss: 27.116; Val_Loss: 971.504   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 3.671\n",
      "(Epoch 3982 / 10000) Train_Loss: 26.149; Val_Loss: 1033.041   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.102\n",
      "(Epoch 3983 / 10000) Train_Loss: 26.377; Val_Loss: 969.454   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.318; Val_NMI: 4.611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3984 / 10000) Train_Loss: 26.324; Val_Loss: 1012.573   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.302; Val_NMI: 4.522\n",
      "(Epoch 3985 / 10000) Train_Loss: 26.092; Val_Loss: 960.816   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.300; Val_NMI: 3.928\n",
      "(Epoch 3986 / 10000) Train_Loss: 26.429; Val_Loss: 973.627   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 3.819\n",
      "(Epoch 3987 / 10000) Train_Loss: 29.927; Val_Loss: 1010.496   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.256\n",
      "(Epoch 3988 / 10000) Train_Loss: 32.715; Val_Loss: 979.793   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.302; Val_NMI: 4.474\n",
      "(Epoch 3989 / 10000) Train_Loss: 27.853; Val_Loss: 998.205   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.363; Val_NMI: 4.032\n",
      "(Epoch 3990 / 10000) Train_Loss: 27.389; Val_Loss: 994.428   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.337; Val_NMI: 4.461\n",
      "(Epoch 3991 / 10000) Train_Loss: 27.032; Val_Loss: 999.552   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 4.558\n",
      "(Epoch 3992 / 10000) Train_Loss: 25.729; Val_Loss: 968.917   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.420\n",
      "(Epoch 3993 / 10000) Train_Loss: 27.061; Val_Loss: 1023.340   Train_ACC: 15.198; Val_ACC: 19.630   Train_NMI: 0.424; Val_NMI: 4.582\n",
      "(Epoch 3994 / 10000) Train_Loss: 29.773; Val_Loss: 975.854   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.315; Val_NMI: 4.134\n",
      "(Epoch 3995 / 10000) Train_Loss: 27.429; Val_Loss: 1021.272   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.364; Val_NMI: 3.882\n",
      "(Epoch 3996 / 10000) Train_Loss: 26.046; Val_Loss: 970.559   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.040\n",
      "(Epoch 3997 / 10000) Train_Loss: 25.949; Val_Loss: 975.029   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.377; Val_NMI: 4.223\n",
      "(Epoch 3998 / 10000) Train_Loss: 26.122; Val_Loss: 1009.722   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.339; Val_NMI: 3.921\n",
      "(Epoch 3999 / 10000) Train_Loss: 25.809; Val_Loss: 1028.575   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.382; Val_NMI: 4.613\n",
      "(Epoch 4000 / 10000) Train_Loss: 26.105; Val_Loss: 957.810   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.336; Val_NMI: 4.414\n",
      "(Epoch 4001 / 10000) Train_Loss: 26.271; Val_Loss: 1036.967   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.050\n",
      "(Epoch 4002 / 10000) Train_Loss: 28.723; Val_Loss: 973.570   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.324; Val_NMI: 3.759\n",
      "(Epoch 4003 / 10000) Train_Loss: 26.783; Val_Loss: 985.954   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.356; Val_NMI: 4.113\n",
      "(Epoch 4004 / 10000) Train_Loss: 25.962; Val_Loss: 975.910   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 4.165\n",
      "(Epoch 4005 / 10000) Train_Loss: 29.045; Val_Loss: 1017.171   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.293; Val_NMI: 4.458\n",
      "(Epoch 4006 / 10000) Train_Loss: 29.225; Val_Loss: 963.050   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.148\n",
      "(Epoch 4007 / 10000) Train_Loss: 27.421; Val_Loss: 937.707   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 3.862\n",
      "(Epoch 4008 / 10000) Train_Loss: 26.428; Val_Loss: 1016.768   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.159\n",
      "(Epoch 4009 / 10000) Train_Loss: 26.317; Val_Loss: 1020.345   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 3.620\n",
      "(Epoch 4010 / 10000) Train_Loss: 27.087; Val_Loss: 973.255   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 3.968\n",
      "(Epoch 4011 / 10000) Train_Loss: 29.307; Val_Loss: 989.307   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.169\n",
      "(Epoch 4012 / 10000) Train_Loss: 31.675; Val_Loss: 1029.826   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 3.974\n",
      "(Epoch 4013 / 10000) Train_Loss: 29.317; Val_Loss: 992.827   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 5.083\n",
      "(Epoch 4014 / 10000) Train_Loss: 26.971; Val_Loss: 934.332   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.345; Val_NMI: 3.890\n",
      "(Epoch 4015 / 10000) Train_Loss: 26.298; Val_Loss: 1046.071   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.310; Val_NMI: 3.831\n",
      "(Epoch 4016 / 10000) Train_Loss: 26.125; Val_Loss: 1051.677   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.368; Val_NMI: 4.262\n",
      "(Epoch 4017 / 10000) Train_Loss: 26.945; Val_Loss: 991.676   Train_ACC: 15.198; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.185\n",
      "(Epoch 4018 / 10000) Train_Loss: 26.320; Val_Loss: 968.571   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.182\n",
      "(Epoch 4019 / 10000) Train_Loss: 27.041; Val_Loss: 1050.750   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.109\n",
      "(Epoch 4020 / 10000) Train_Loss: 29.556; Val_Loss: 958.722   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.290; Val_NMI: 4.117\n",
      "(Epoch 4021 / 10000) Train_Loss: 28.076; Val_Loss: 1009.269   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 4.124\n",
      "(Epoch 4022 / 10000) Train_Loss: 26.999; Val_Loss: 970.423   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.289; Val_NMI: 4.064\n",
      "(Epoch 4023 / 10000) Train_Loss: 26.781; Val_Loss: 1029.342   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.051\n",
      "(Epoch 4024 / 10000) Train_Loss: 28.765; Val_Loss: 1026.018   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.312; Val_NMI: 3.883\n",
      "(Epoch 4025 / 10000) Train_Loss: 29.445; Val_Loss: 996.541   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.340; Val_NMI: 3.976\n",
      "(Epoch 4026 / 10000) Train_Loss: 26.830; Val_Loss: 1029.329   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 3.625\n",
      "(Epoch 4027 / 10000) Train_Loss: 26.165; Val_Loss: 1024.929   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.279; Val_NMI: 4.251\n",
      "(Epoch 4028 / 10000) Train_Loss: 26.277; Val_Loss: 982.920   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.342; Val_NMI: 4.653\n",
      "(Epoch 4029 / 10000) Train_Loss: 27.551; Val_Loss: 960.580   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.307; Val_NMI: 4.538\n",
      "(Epoch 4030 / 10000) Train_Loss: 26.934; Val_Loss: 983.549   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.309; Val_NMI: 4.383\n",
      "(Epoch 4031 / 10000) Train_Loss: 27.216; Val_Loss: 983.882   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.344; Val_NMI: 3.724\n",
      "(Epoch 4032 / 10000) Train_Loss: 26.204; Val_Loss: 1000.868   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.369; Val_NMI: 4.142\n",
      "(Epoch 4033 / 10000) Train_Loss: 26.640; Val_Loss: 988.134   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.462\n",
      "(Epoch 4034 / 10000) Train_Loss: 26.948; Val_Loss: 983.112   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.321; Val_NMI: 3.853\n",
      "(Epoch 4035 / 10000) Train_Loss: 26.091; Val_Loss: 1015.543   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.334\n",
      "(Epoch 4036 / 10000) Train_Loss: 26.278; Val_Loss: 991.171   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.703\n",
      "(Epoch 4037 / 10000) Train_Loss: 26.210; Val_Loss: 1021.963   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.397; Val_NMI: 4.416\n",
      "(Epoch 4038 / 10000) Train_Loss: 25.292; Val_Loss: 1057.632   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.537\n",
      "(Epoch 4039 / 10000) Train_Loss: 27.416; Val_Loss: 997.955   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 4.490\n",
      "(Epoch 4040 / 10000) Train_Loss: 27.580; Val_Loss: 991.760   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.332; Val_NMI: 4.164\n",
      "(Epoch 4041 / 10000) Train_Loss: 27.803; Val_Loss: 1031.531   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.613\n",
      "(Epoch 4042 / 10000) Train_Loss: 27.700; Val_Loss: 956.209   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.361; Val_NMI: 4.426\n",
      "(Epoch 4043 / 10000) Train_Loss: 28.011; Val_Loss: 1069.519   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.114\n",
      "(Epoch 4044 / 10000) Train_Loss: 27.324; Val_Loss: 1032.092   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 4.027\n",
      "(Epoch 4045 / 10000) Train_Loss: 26.822; Val_Loss: 1047.931   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.300; Val_NMI: 3.884\n",
      "(Epoch 4046 / 10000) Train_Loss: 26.114; Val_Loss: 1018.916   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.333; Val_NMI: 4.372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4047 / 10000) Train_Loss: 26.417; Val_Loss: 990.932   Train_ACC: 15.198; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.659\n",
      "(Epoch 4048 / 10000) Train_Loss: 26.828; Val_Loss: 966.280   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.322; Val_NMI: 4.305\n",
      "(Epoch 4049 / 10000) Train_Loss: 27.095; Val_Loss: 1018.586   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.318; Val_NMI: 4.044\n",
      "(Epoch 4050 / 10000) Train_Loss: 27.301; Val_Loss: 999.888   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.342; Val_NMI: 3.992\n",
      "(Epoch 4051 / 10000) Train_Loss: 26.155; Val_Loss: 1024.734   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.037\n",
      "(Epoch 4052 / 10000) Train_Loss: 30.195; Val_Loss: 1001.867   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.315; Val_NMI: 4.579\n",
      "(Epoch 4053 / 10000) Train_Loss: 33.027; Val_Loss: 996.116   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.276\n",
      "(Epoch 4054 / 10000) Train_Loss: 30.391; Val_Loss: 985.522   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.328; Val_NMI: 4.148\n",
      "(Epoch 4055 / 10000) Train_Loss: 29.026; Val_Loss: 995.284   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 4.159\n",
      "(Epoch 4056 / 10000) Train_Loss: 28.327; Val_Loss: 996.657   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.378; Val_NMI: 4.038\n",
      "(Epoch 4057 / 10000) Train_Loss: 26.587; Val_Loss: 1030.017   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.358; Val_NMI: 4.049\n",
      "(Epoch 4058 / 10000) Train_Loss: 26.991; Val_Loss: 1069.305   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.726\n",
      "(Epoch 4059 / 10000) Train_Loss: 27.304; Val_Loss: 959.328   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.315; Val_NMI: 3.863\n",
      "(Epoch 4060 / 10000) Train_Loss: 27.970; Val_Loss: 933.985   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.080\n",
      "(Epoch 4061 / 10000) Train_Loss: 27.906; Val_Loss: 1005.527   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.278; Val_NMI: 3.824\n",
      "(Epoch 4062 / 10000) Train_Loss: 26.288; Val_Loss: 1067.161   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.297; Val_NMI: 4.168\n",
      "(Epoch 4063 / 10000) Train_Loss: 26.900; Val_Loss: 990.641   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.271; Val_NMI: 4.002\n",
      "(Epoch 4064 / 10000) Train_Loss: 27.988; Val_Loss: 987.063   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.283; Val_NMI: 4.052\n",
      "(Epoch 4065 / 10000) Train_Loss: 28.256; Val_Loss: 988.272   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.344; Val_NMI: 4.051\n",
      "(Epoch 4066 / 10000) Train_Loss: 27.826; Val_Loss: 1016.416   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.322\n",
      "(Epoch 4067 / 10000) Train_Loss: 26.584; Val_Loss: 1035.634   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.298; Val_NMI: 4.083\n",
      "(Epoch 4068 / 10000) Train_Loss: 26.567; Val_Loss: 974.188   Train_ACC: 14.374; Val_ACC: 20.000   Train_NMI: 0.279; Val_NMI: 4.066\n",
      "(Epoch 4069 / 10000) Train_Loss: 26.074; Val_Loss: 982.861   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.093\n",
      "(Epoch 4070 / 10000) Train_Loss: 25.376; Val_Loss: 1032.558   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.298; Val_NMI: 3.863\n",
      "(Epoch 4071 / 10000) Train_Loss: 26.952; Val_Loss: 1008.428   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.345; Val_NMI: 3.742\n",
      "(Epoch 4072 / 10000) Train_Loss: 27.322; Val_Loss: 1038.117   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.358; Val_NMI: 3.889\n",
      "(Epoch 4073 / 10000) Train_Loss: 27.078; Val_Loss: 1023.006   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 3.953\n",
      "(Epoch 4074 / 10000) Train_Loss: 26.208; Val_Loss: 1042.539   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.377; Val_NMI: 3.928\n",
      "(Epoch 4075 / 10000) Train_Loss: 25.814; Val_Loss: 980.954   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.410; Val_NMI: 4.328\n",
      "(Epoch 4076 / 10000) Train_Loss: 27.563; Val_Loss: 1042.156   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 4.335\n",
      "(Epoch 4077 / 10000) Train_Loss: 30.335; Val_Loss: 979.935   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.357; Val_NMI: 4.327\n",
      "(Epoch 4078 / 10000) Train_Loss: 27.268; Val_Loss: 955.293   Train_ACC: 15.115; Val_ACC: 18.889   Train_NMI: 0.403; Val_NMI: 4.094\n",
      "(Epoch 4079 / 10000) Train_Loss: 27.691; Val_Loss: 1046.701   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.205\n",
      "(Epoch 4080 / 10000) Train_Loss: 28.951; Val_Loss: 1032.590   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.518\n",
      "(Epoch 4081 / 10000) Train_Loss: 28.528; Val_Loss: 1052.821   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 4.014\n",
      "(Epoch 4082 / 10000) Train_Loss: 26.168; Val_Loss: 1002.856   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.243\n",
      "(Epoch 4083 / 10000) Train_Loss: 26.235; Val_Loss: 964.948   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.337; Val_NMI: 3.991\n",
      "(Epoch 4084 / 10000) Train_Loss: 25.506; Val_Loss: 997.678   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.338; Val_NMI: 3.746\n",
      "(Epoch 4085 / 10000) Train_Loss: 26.217; Val_Loss: 1013.954   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.342; Val_NMI: 4.151\n",
      "(Epoch 4086 / 10000) Train_Loss: 28.625; Val_Loss: 1028.235   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.343; Val_NMI: 3.738\n",
      "(Epoch 4087 / 10000) Train_Loss: 27.334; Val_Loss: 1007.911   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 4.229\n",
      "(Epoch 4088 / 10000) Train_Loss: 28.202; Val_Loss: 1003.089   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.379; Val_NMI: 3.501\n",
      "(Epoch 4089 / 10000) Train_Loss: 38.892; Val_Loss: 990.186   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.375; Val_NMI: 3.602\n",
      "(Epoch 4090 / 10000) Train_Loss: 33.857; Val_Loss: 985.174   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.338; Val_NMI: 4.224\n",
      "(Epoch 4091 / 10000) Train_Loss: 28.201; Val_Loss: 975.301   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.040\n",
      "(Epoch 4092 / 10000) Train_Loss: 26.218; Val_Loss: 957.300   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 3.976\n",
      "(Epoch 4093 / 10000) Train_Loss: 26.434; Val_Loss: 1013.923   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 4.110\n",
      "(Epoch 4094 / 10000) Train_Loss: 25.544; Val_Loss: 989.539   Train_ACC: 14.909; Val_ACC: 18.519   Train_NMI: 0.341; Val_NMI: 3.898\n",
      "(Epoch 4095 / 10000) Train_Loss: 25.910; Val_Loss: 952.013   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.424; Val_NMI: 3.877\n",
      "(Epoch 4096 / 10000) Train_Loss: 26.234; Val_Loss: 1063.247   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.365; Val_NMI: 3.852\n",
      "(Epoch 4097 / 10000) Train_Loss: 27.945; Val_Loss: 987.067   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 3.934\n",
      "(Epoch 4098 / 10000) Train_Loss: 28.409; Val_Loss: 1067.272   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 3.834\n",
      "(Epoch 4099 / 10000) Train_Loss: 27.470; Val_Loss: 996.743   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 3.630\n",
      "(Epoch 4100 / 10000) Train_Loss: 26.186; Val_Loss: 1001.568   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.330; Val_NMI: 3.981\n",
      "(Epoch 4101 / 10000) Train_Loss: 26.737; Val_Loss: 1003.631   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 3.477\n",
      "(Epoch 4102 / 10000) Train_Loss: 27.167; Val_Loss: 958.709   Train_ACC: 14.456; Val_ACC: 20.741   Train_NMI: 0.301; Val_NMI: 4.104\n",
      "(Epoch 4103 / 10000) Train_Loss: 26.757; Val_Loss: 1016.767   Train_ACC: 14.498; Val_ACC: 18.889   Train_NMI: 0.286; Val_NMI: 3.934\n",
      "(Epoch 4104 / 10000) Train_Loss: 26.335; Val_Loss: 962.454   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.329; Val_NMI: 3.693\n",
      "(Epoch 4105 / 10000) Train_Loss: 26.020; Val_Loss: 951.742   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 3.831\n",
      "(Epoch 4106 / 10000) Train_Loss: 25.531; Val_Loss: 1035.367   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.393; Val_NMI: 3.884\n",
      "(Epoch 4107 / 10000) Train_Loss: 25.751; Val_Loss: 953.335   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.504\n",
      "(Epoch 4108 / 10000) Train_Loss: 26.020; Val_Loss: 1013.482   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 3.896\n",
      "(Epoch 4109 / 10000) Train_Loss: 25.958; Val_Loss: 988.925   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.339; Val_NMI: 4.041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4110 / 10000) Train_Loss: 27.620; Val_Loss: 974.785   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.321; Val_NMI: 3.698\n",
      "(Epoch 4111 / 10000) Train_Loss: 27.447; Val_Loss: 1034.842   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 3.974\n",
      "(Epoch 4112 / 10000) Train_Loss: 27.901; Val_Loss: 1013.808   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.335; Val_NMI: 3.898\n",
      "(Epoch 4113 / 10000) Train_Loss: 26.268; Val_Loss: 1021.244   Train_ACC: 14.703; Val_ACC: 20.741   Train_NMI: 0.336; Val_NMI: 4.635\n",
      "(Epoch 4114 / 10000) Train_Loss: 25.697; Val_Loss: 934.930   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 3.957\n",
      "(Epoch 4115 / 10000) Train_Loss: 26.990; Val_Loss: 1035.193   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.293; Val_NMI: 3.936\n",
      "(Epoch 4116 / 10000) Train_Loss: 26.739; Val_Loss: 994.544   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 4.539\n",
      "(Epoch 4117 / 10000) Train_Loss: 28.204; Val_Loss: 1027.733   Train_ACC: 15.527; Val_ACC: 19.630   Train_NMI: 0.411; Val_NMI: 4.297\n",
      "(Epoch 4118 / 10000) Train_Loss: 27.830; Val_Loss: 1049.465   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.436; Val_NMI: 4.570\n",
      "(Epoch 4119 / 10000) Train_Loss: 26.097; Val_Loss: 974.723   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.158\n",
      "(Epoch 4120 / 10000) Train_Loss: 26.297; Val_Loss: 1089.701   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.321; Val_NMI: 4.310\n",
      "(Epoch 4121 / 10000) Train_Loss: 27.142; Val_Loss: 941.200   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.184\n",
      "(Epoch 4122 / 10000) Train_Loss: 29.729; Val_Loss: 928.648   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.319; Val_NMI: 5.069\n",
      "(Epoch 4123 / 10000) Train_Loss: 27.262; Val_Loss: 932.661   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.350; Val_NMI: 4.379\n",
      "(Epoch 4124 / 10000) Train_Loss: 26.272; Val_Loss: 1017.397   Train_ACC: 14.703; Val_ACC: 20.370   Train_NMI: 0.342; Val_NMI: 4.940\n",
      "(Epoch 4125 / 10000) Train_Loss: 26.332; Val_Loss: 970.279   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 4.635\n",
      "(Epoch 4126 / 10000) Train_Loss: 26.417; Val_Loss: 939.146   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 4.239\n",
      "(Epoch 4127 / 10000) Train_Loss: 26.636; Val_Loss: 1045.871   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.255\n",
      "(Epoch 4128 / 10000) Train_Loss: 25.371; Val_Loss: 947.157   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 3.915\n",
      "(Epoch 4129 / 10000) Train_Loss: 27.645; Val_Loss: 1032.628   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 3.474\n",
      "(Epoch 4130 / 10000) Train_Loss: 29.643; Val_Loss: 1031.396   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.344; Val_NMI: 4.808\n",
      "(Epoch 4131 / 10000) Train_Loss: 30.011; Val_Loss: 1002.960   Train_ACC: 15.157; Val_ACC: 20.000   Train_NMI: 0.407; Val_NMI: 4.848\n",
      "(Epoch 4132 / 10000) Train_Loss: 28.373; Val_Loss: 1012.848   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 4.237\n",
      "(Epoch 4133 / 10000) Train_Loss: 28.024; Val_Loss: 972.995   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.364; Val_NMI: 3.414\n",
      "(Epoch 4134 / 10000) Train_Loss: 28.573; Val_Loss: 1046.134   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.357; Val_NMI: 4.117\n",
      "(Epoch 4135 / 10000) Train_Loss: 27.266; Val_Loss: 951.653   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.695\n",
      "(Epoch 4136 / 10000) Train_Loss: 25.932; Val_Loss: 1004.014   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.361; Val_NMI: 4.301\n",
      "(Epoch 4137 / 10000) Train_Loss: 26.626; Val_Loss: 968.670   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.363; Val_NMI: 4.046\n",
      "(Epoch 4138 / 10000) Train_Loss: 27.603; Val_Loss: 983.618   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.364; Val_NMI: 4.058\n",
      "(Epoch 4139 / 10000) Train_Loss: 28.166; Val_Loss: 967.643   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.176\n",
      "(Epoch 4140 / 10000) Train_Loss: 30.036; Val_Loss: 1023.043   Train_ACC: 14.868; Val_ACC: 18.519   Train_NMI: 0.324; Val_NMI: 3.454\n",
      "(Epoch 4141 / 10000) Train_Loss: 29.830; Val_Loss: 1024.361   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.343; Val_NMI: 4.545\n",
      "(Epoch 4142 / 10000) Train_Loss: 28.097; Val_Loss: 997.115   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 4.397\n",
      "(Epoch 4143 / 10000) Train_Loss: 26.602; Val_Loss: 1042.265   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 3.954\n",
      "(Epoch 4144 / 10000) Train_Loss: 25.926; Val_Loss: 1000.674   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.616\n",
      "(Epoch 4145 / 10000) Train_Loss: 27.522; Val_Loss: 985.984   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.264\n",
      "(Epoch 4146 / 10000) Train_Loss: 26.603; Val_Loss: 951.504   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 4.142\n",
      "(Epoch 4147 / 10000) Train_Loss: 27.022; Val_Loss: 979.161   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.350; Val_NMI: 4.063\n",
      "(Epoch 4148 / 10000) Train_Loss: 25.890; Val_Loss: 935.614   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 4.338\n",
      "(Epoch 4149 / 10000) Train_Loss: 26.227; Val_Loss: 1006.812   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.369\n",
      "(Epoch 4150 / 10000) Train_Loss: 27.544; Val_Loss: 1068.150   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 3.735\n",
      "(Epoch 4151 / 10000) Train_Loss: 26.722; Val_Loss: 967.959   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.319; Val_NMI: 4.440\n",
      "(Epoch 4152 / 10000) Train_Loss: 26.974; Val_Loss: 1012.275   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.306; Val_NMI: 4.523\n",
      "(Epoch 4153 / 10000) Train_Loss: 26.542; Val_Loss: 1052.190   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 3.919\n",
      "(Epoch 4154 / 10000) Train_Loss: 26.956; Val_Loss: 1041.124   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.393; Val_NMI: 4.159\n",
      "(Epoch 4155 / 10000) Train_Loss: 27.861; Val_Loss: 1034.220   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 4.274\n",
      "(Epoch 4156 / 10000) Train_Loss: 27.301; Val_Loss: 996.029   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.357; Val_NMI: 4.765\n",
      "(Epoch 4157 / 10000) Train_Loss: 28.530; Val_Loss: 993.963   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 4.696\n",
      "(Epoch 4158 / 10000) Train_Loss: 26.447; Val_Loss: 1022.486   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.084\n",
      "(Epoch 4159 / 10000) Train_Loss: 26.146; Val_Loss: 981.086   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.316; Val_NMI: 4.090\n",
      "(Epoch 4160 / 10000) Train_Loss: 25.984; Val_Loss: 1041.503   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.311; Val_NMI: 3.989\n",
      "(Epoch 4161 / 10000) Train_Loss: 26.178; Val_Loss: 938.874   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 4.023\n",
      "(Epoch 4162 / 10000) Train_Loss: 26.981; Val_Loss: 983.910   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.340; Val_NMI: 4.236\n",
      "(Epoch 4163 / 10000) Train_Loss: 28.239; Val_Loss: 1037.985   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.321; Val_NMI: 3.894\n",
      "(Epoch 4164 / 10000) Train_Loss: 27.623; Val_Loss: 1014.412   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.388\n",
      "(Epoch 4165 / 10000) Train_Loss: 27.690; Val_Loss: 1015.354   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.068\n",
      "(Epoch 4166 / 10000) Train_Loss: 31.361; Val_Loss: 1029.647   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.333; Val_NMI: 3.311\n",
      "(Epoch 4167 / 10000) Train_Loss: 27.531; Val_Loss: 993.799   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.310; Val_NMI: 4.287\n",
      "(Epoch 4168 / 10000) Train_Loss: 28.219; Val_Loss: 968.424   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.345; Val_NMI: 3.665\n",
      "(Epoch 4169 / 10000) Train_Loss: 27.121; Val_Loss: 1005.125   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.383; Val_NMI: 3.995\n",
      "(Epoch 4170 / 10000) Train_Loss: 25.637; Val_Loss: 1022.322   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.394; Val_NMI: 4.377\n",
      "(Epoch 4171 / 10000) Train_Loss: 26.586; Val_Loss: 964.031   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.666\n",
      "(Epoch 4172 / 10000) Train_Loss: 26.214; Val_Loss: 1011.100   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.330; Val_NMI: 3.422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4173 / 10000) Train_Loss: 26.392; Val_Loss: 1004.596   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.145\n",
      "(Epoch 4174 / 10000) Train_Loss: 27.647; Val_Loss: 1044.577   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.332; Val_NMI: 3.894\n",
      "(Epoch 4175 / 10000) Train_Loss: 26.262; Val_Loss: 969.307   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 3.703\n",
      "(Epoch 4176 / 10000) Train_Loss: 26.776; Val_Loss: 1008.347   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.305; Val_NMI: 4.297\n",
      "(Epoch 4177 / 10000) Train_Loss: 27.199; Val_Loss: 1023.497   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.310; Val_NMI: 4.524\n",
      "(Epoch 4178 / 10000) Train_Loss: 27.533; Val_Loss: 991.240   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.300; Val_NMI: 4.056\n",
      "(Epoch 4179 / 10000) Train_Loss: 26.522; Val_Loss: 1001.188   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.433\n",
      "(Epoch 4180 / 10000) Train_Loss: 26.550; Val_Loss: 1012.639   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.317; Val_NMI: 4.568\n",
      "(Epoch 4181 / 10000) Train_Loss: 25.983; Val_Loss: 1030.933   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 4.479\n",
      "(Epoch 4182 / 10000) Train_Loss: 26.398; Val_Loss: 1033.666   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.294; Val_NMI: 4.201\n",
      "(Epoch 4183 / 10000) Train_Loss: 27.909; Val_Loss: 1031.918   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 4.403\n",
      "(Epoch 4184 / 10000) Train_Loss: 35.256; Val_Loss: 1068.985   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.234\n",
      "(Epoch 4185 / 10000) Train_Loss: 33.204; Val_Loss: 1008.464   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 3.922\n",
      "(Epoch 4186 / 10000) Train_Loss: 28.867; Val_Loss: 957.067   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.331; Val_NMI: 4.419\n",
      "(Epoch 4187 / 10000) Train_Loss: 26.397; Val_Loss: 1022.976   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 4.464\n",
      "(Epoch 4188 / 10000) Train_Loss: 25.442; Val_Loss: 1061.399   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.119\n",
      "(Epoch 4189 / 10000) Train_Loss: 26.739; Val_Loss: 954.850   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.314; Val_NMI: 4.503\n",
      "(Epoch 4190 / 10000) Train_Loss: 26.920; Val_Loss: 960.278   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.390; Val_NMI: 3.477\n",
      "(Epoch 4191 / 10000) Train_Loss: 27.323; Val_Loss: 1014.793   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.306; Val_NMI: 3.454\n",
      "(Epoch 4192 / 10000) Train_Loss: 26.371; Val_Loss: 992.805   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.206\n",
      "(Epoch 4193 / 10000) Train_Loss: 26.383; Val_Loss: 1028.948   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.285; Val_NMI: 4.135\n",
      "(Epoch 4194 / 10000) Train_Loss: 26.070; Val_Loss: 961.332   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.312; Val_NMI: 4.483\n",
      "(Epoch 4195 / 10000) Train_Loss: 25.854; Val_Loss: 1028.408   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.300; Val_NMI: 3.198\n",
      "(Epoch 4196 / 10000) Train_Loss: 27.230; Val_Loss: 973.046   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 4.568\n",
      "(Epoch 4197 / 10000) Train_Loss: 26.596; Val_Loss: 996.217   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.304; Val_NMI: 3.863\n",
      "(Epoch 4198 / 10000) Train_Loss: 26.967; Val_Loss: 1014.144   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.400; Val_NMI: 4.009\n",
      "(Epoch 4199 / 10000) Train_Loss: 26.488; Val_Loss: 1056.677   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.306; Val_NMI: 3.904\n",
      "(Epoch 4200 / 10000) Train_Loss: 26.395; Val_Loss: 977.361   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.308; Val_NMI: 4.071\n",
      "(Epoch 4201 / 10000) Train_Loss: 26.405; Val_Loss: 979.993   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.365; Val_NMI: 3.606\n",
      "(Epoch 4202 / 10000) Train_Loss: 26.729; Val_Loss: 981.730   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.327; Val_NMI: 3.805\n",
      "(Epoch 4203 / 10000) Train_Loss: 27.840; Val_Loss: 994.996   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.284; Val_NMI: 3.763\n",
      "(Epoch 4204 / 10000) Train_Loss: 28.238; Val_Loss: 1028.732   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.325; Val_NMI: 3.844\n",
      "(Epoch 4205 / 10000) Train_Loss: 29.130; Val_Loss: 1058.429   Train_ACC: 14.539; Val_ACC: 18.519   Train_NMI: 0.316; Val_NMI: 3.613\n",
      "(Epoch 4206 / 10000) Train_Loss: 28.908; Val_Loss: 996.905   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.319; Val_NMI: 3.772\n",
      "(Epoch 4207 / 10000) Train_Loss: 27.140; Val_Loss: 1034.642   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.358; Val_NMI: 3.172\n",
      "(Epoch 4208 / 10000) Train_Loss: 27.059; Val_Loss: 991.113   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 3.936\n",
      "(Epoch 4209 / 10000) Train_Loss: 26.261; Val_Loss: 1033.116   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.731\n",
      "(Epoch 4210 / 10000) Train_Loss: 27.516; Val_Loss: 1009.719   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.319; Val_NMI: 3.650\n",
      "(Epoch 4211 / 10000) Train_Loss: 27.299; Val_Loss: 1039.645   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.308; Val_NMI: 3.850\n",
      "(Epoch 4212 / 10000) Train_Loss: 26.030; Val_Loss: 1003.915   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.298; Val_NMI: 4.133\n",
      "(Epoch 4213 / 10000) Train_Loss: 26.179; Val_Loss: 961.800   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 3.720\n",
      "(Epoch 4214 / 10000) Train_Loss: 26.749; Val_Loss: 930.639   Train_ACC: 14.992; Val_ACC: 18.519   Train_NMI: 0.340; Val_NMI: 3.434\n",
      "(Epoch 4215 / 10000) Train_Loss: 26.308; Val_Loss: 979.898   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.427\n",
      "(Epoch 4216 / 10000) Train_Loss: 26.338; Val_Loss: 1031.970   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.307; Val_NMI: 3.999\n",
      "(Epoch 4217 / 10000) Train_Loss: 26.402; Val_Loss: 1047.029   Train_ACC: 14.498; Val_ACC: 20.000   Train_NMI: 0.292; Val_NMI: 4.612\n",
      "(Epoch 4218 / 10000) Train_Loss: 27.847; Val_Loss: 1018.363   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.302; Val_NMI: 3.828\n",
      "(Epoch 4219 / 10000) Train_Loss: 28.523; Val_Loss: 1017.674   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.481\n",
      "(Epoch 4220 / 10000) Train_Loss: 27.442; Val_Loss: 956.144   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.386; Val_NMI: 4.466\n",
      "(Epoch 4221 / 10000) Train_Loss: 26.585; Val_Loss: 1032.083   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.395; Val_NMI: 4.436\n",
      "(Epoch 4222 / 10000) Train_Loss: 25.624; Val_Loss: 1027.749   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.064\n",
      "(Epoch 4223 / 10000) Train_Loss: 29.112; Val_Loss: 1087.154   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.323; Val_NMI: 5.109\n",
      "(Epoch 4224 / 10000) Train_Loss: 31.133; Val_Loss: 1001.872   Train_ACC: 14.621; Val_ACC: 20.741   Train_NMI: 0.375; Val_NMI: 4.438\n",
      "(Epoch 4225 / 10000) Train_Loss: 29.608; Val_Loss: 1016.233   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 3.613\n",
      "(Epoch 4226 / 10000) Train_Loss: 29.059; Val_Loss: 988.197   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.282\n",
      "(Epoch 4227 / 10000) Train_Loss: 32.631; Val_Loss: 1099.938   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.215\n",
      "(Epoch 4228 / 10000) Train_Loss: 31.706; Val_Loss: 1009.454   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.349; Val_NMI: 4.121\n",
      "(Epoch 4229 / 10000) Train_Loss: 27.564; Val_Loss: 1055.846   Train_ACC: 14.456; Val_ACC: 20.000   Train_NMI: 0.311; Val_NMI: 4.547\n",
      "(Epoch 4230 / 10000) Train_Loss: 26.181; Val_Loss: 1067.455   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.271\n",
      "(Epoch 4231 / 10000) Train_Loss: 26.334; Val_Loss: 940.816   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.203\n",
      "(Epoch 4232 / 10000) Train_Loss: 27.163; Val_Loss: 1029.007   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.312; Val_NMI: 4.370\n",
      "(Epoch 4233 / 10000) Train_Loss: 31.464; Val_Loss: 985.781   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 4.821\n",
      "(Epoch 4234 / 10000) Train_Loss: 27.437; Val_Loss: 1053.912   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 4.411\n",
      "(Epoch 4235 / 10000) Train_Loss: 27.440; Val_Loss: 1041.661   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.362; Val_NMI: 4.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4236 / 10000) Train_Loss: 26.809; Val_Loss: 987.112   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.386; Val_NMI: 4.600\n",
      "(Epoch 4237 / 10000) Train_Loss: 29.057; Val_Loss: 1038.454   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.363; Val_NMI: 4.480\n",
      "(Epoch 4238 / 10000) Train_Loss: 27.817; Val_Loss: 1015.670   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.338; Val_NMI: 4.848\n",
      "(Epoch 4239 / 10000) Train_Loss: 26.001; Val_Loss: 1007.146   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 4.624\n",
      "(Epoch 4240 / 10000) Train_Loss: 26.204; Val_Loss: 995.174   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.356; Val_NMI: 4.325\n",
      "(Epoch 4241 / 10000) Train_Loss: 27.991; Val_Loss: 996.963   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.333; Val_NMI: 4.921\n",
      "(Epoch 4242 / 10000) Train_Loss: 30.193; Val_Loss: 984.119   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.298; Val_NMI: 4.868\n",
      "(Epoch 4243 / 10000) Train_Loss: 28.861; Val_Loss: 987.125   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.316; Val_NMI: 4.873\n",
      "(Epoch 4244 / 10000) Train_Loss: 26.679; Val_Loss: 989.315   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.322; Val_NMI: 4.651\n",
      "(Epoch 4245 / 10000) Train_Loss: 26.639; Val_Loss: 1024.624   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.584\n",
      "(Epoch 4246 / 10000) Train_Loss: 26.894; Val_Loss: 1014.182   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 4.592\n",
      "(Epoch 4247 / 10000) Train_Loss: 26.381; Val_Loss: 1037.910   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 4.467\n",
      "(Epoch 4248 / 10000) Train_Loss: 25.689; Val_Loss: 922.690   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.361; Val_NMI: 4.601\n",
      "(Epoch 4249 / 10000) Train_Loss: 25.844; Val_Loss: 994.890   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.371\n",
      "(Epoch 4250 / 10000) Train_Loss: 25.719; Val_Loss: 1017.986   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.314; Val_NMI: 4.230\n",
      "(Epoch 4251 / 10000) Train_Loss: 25.582; Val_Loss: 970.274   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.311; Val_NMI: 4.703\n",
      "(Epoch 4252 / 10000) Train_Loss: 25.795; Val_Loss: 988.136   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.719\n",
      "(Epoch 4253 / 10000) Train_Loss: 28.985; Val_Loss: 1027.548   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 4.631\n",
      "(Epoch 4254 / 10000) Train_Loss: 28.479; Val_Loss: 1032.129   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.302; Val_NMI: 4.319\n",
      "(Epoch 4255 / 10000) Train_Loss: 27.167; Val_Loss: 991.331   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.276; Val_NMI: 4.300\n",
      "(Epoch 4256 / 10000) Train_Loss: 25.848; Val_Loss: 1018.855   Train_ACC: 14.539; Val_ACC: 20.000   Train_NMI: 0.335; Val_NMI: 4.682\n",
      "(Epoch 4257 / 10000) Train_Loss: 25.778; Val_Loss: 996.401   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.316; Val_NMI: 4.008\n",
      "(Epoch 4258 / 10000) Train_Loss: 35.065; Val_Loss: 1110.214   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.296; Val_NMI: 4.910\n",
      "(Epoch 4259 / 10000) Train_Loss: 34.819; Val_Loss: 989.699   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 4.614\n",
      "(Epoch 4260 / 10000) Train_Loss: 28.758; Val_Loss: 981.565   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.395; Val_NMI: 4.199\n",
      "(Epoch 4261 / 10000) Train_Loss: 26.195; Val_Loss: 971.049   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.295; Val_NMI: 4.182\n",
      "(Epoch 4262 / 10000) Train_Loss: 27.082; Val_Loss: 967.208   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.327; Val_NMI: 4.482\n",
      "(Epoch 4263 / 10000) Train_Loss: 28.233; Val_Loss: 1053.439   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.316; Val_NMI: 4.700\n",
      "(Epoch 4264 / 10000) Train_Loss: 28.824; Val_Loss: 996.966   Train_ACC: 14.539; Val_ACC: 19.630   Train_NMI: 0.285; Val_NMI: 4.181\n",
      "(Epoch 4265 / 10000) Train_Loss: 26.738; Val_Loss: 969.420   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.294; Val_NMI: 4.063\n",
      "(Epoch 4266 / 10000) Train_Loss: 26.401; Val_Loss: 996.487   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.279; Val_NMI: 4.183\n",
      "(Epoch 4267 / 10000) Train_Loss: 25.975; Val_Loss: 1005.126   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 5.131\n",
      "(Epoch 4268 / 10000) Train_Loss: 25.803; Val_Loss: 1054.913   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.304; Val_NMI: 4.710\n",
      "(Epoch 4269 / 10000) Train_Loss: 25.636; Val_Loss: 1050.550   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.674\n",
      "(Epoch 4270 / 10000) Train_Loss: 26.567; Val_Loss: 1009.419   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.578\n",
      "(Epoch 4271 / 10000) Train_Loss: 26.248; Val_Loss: 961.182   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 4.190\n",
      "(Epoch 4272 / 10000) Train_Loss: 25.864; Val_Loss: 1006.419   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.318; Val_NMI: 3.904\n",
      "(Epoch 4273 / 10000) Train_Loss: 26.747; Val_Loss: 955.799   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.378; Val_NMI: 4.433\n",
      "(Epoch 4274 / 10000) Train_Loss: 30.170; Val_Loss: 987.536   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.718\n",
      "(Epoch 4275 / 10000) Train_Loss: 30.406; Val_Loss: 998.612   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.288; Val_NMI: 4.041\n",
      "(Epoch 4276 / 10000) Train_Loss: 28.012; Val_Loss: 982.619   Train_ACC: 14.374; Val_ACC: 19.630   Train_NMI: 0.258; Val_NMI: 4.259\n",
      "(Epoch 4277 / 10000) Train_Loss: 26.334; Val_Loss: 1047.158   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.353; Val_NMI: 4.318\n",
      "(Epoch 4278 / 10000) Train_Loss: 26.105; Val_Loss: 1000.008   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.308\n",
      "(Epoch 4279 / 10000) Train_Loss: 26.511; Val_Loss: 1011.734   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.299; Val_NMI: 4.464\n",
      "(Epoch 4280 / 10000) Train_Loss: 27.392; Val_Loss: 991.566   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.363\n",
      "(Epoch 4281 / 10000) Train_Loss: 25.429; Val_Loss: 996.283   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 3.966\n",
      "(Epoch 4282 / 10000) Train_Loss: 25.923; Val_Loss: 1017.611   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.308; Val_NMI: 4.143\n",
      "(Epoch 4283 / 10000) Train_Loss: 27.115; Val_Loss: 1039.817   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.869\n",
      "(Epoch 4284 / 10000) Train_Loss: 26.823; Val_Loss: 993.866   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.288; Val_NMI: 4.456\n",
      "(Epoch 4285 / 10000) Train_Loss: 26.693; Val_Loss: 1033.923   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.284; Val_NMI: 4.723\n",
      "(Epoch 4286 / 10000) Train_Loss: 27.220; Val_Loss: 1020.018   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.276\n",
      "(Epoch 4287 / 10000) Train_Loss: 27.691; Val_Loss: 975.440   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 4.203\n",
      "(Epoch 4288 / 10000) Train_Loss: 25.926; Val_Loss: 945.199   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.296; Val_NMI: 4.042\n",
      "(Epoch 4289 / 10000) Train_Loss: 25.237; Val_Loss: 1026.414   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.325; Val_NMI: 4.694\n",
      "(Epoch 4290 / 10000) Train_Loss: 29.400; Val_Loss: 1001.495   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.043\n",
      "(Epoch 4291 / 10000) Train_Loss: 29.522; Val_Loss: 965.621   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.324; Val_NMI: 4.300\n",
      "(Epoch 4292 / 10000) Train_Loss: 27.627; Val_Loss: 976.307   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.282; Val_NMI: 4.085\n",
      "(Epoch 4293 / 10000) Train_Loss: 27.986; Val_Loss: 986.159   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.291; Val_NMI: 4.247\n",
      "(Epoch 4294 / 10000) Train_Loss: 27.426; Val_Loss: 958.924   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 4.117\n",
      "(Epoch 4295 / 10000) Train_Loss: 26.554; Val_Loss: 1060.097   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.306; Val_NMI: 4.248\n",
      "(Epoch 4296 / 10000) Train_Loss: 26.452; Val_Loss: 960.778   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.291; Val_NMI: 4.694\n",
      "(Epoch 4297 / 10000) Train_Loss: 26.172; Val_Loss: 995.277   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.297; Val_NMI: 4.879\n",
      "(Epoch 4298 / 10000) Train_Loss: 26.410; Val_Loss: 997.144   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.326; Val_NMI: 4.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4299 / 10000) Train_Loss: 26.348; Val_Loss: 976.574   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.321; Val_NMI: 4.254\n",
      "(Epoch 4300 / 10000) Train_Loss: 26.424; Val_Loss: 1021.451   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.291; Val_NMI: 4.007\n",
      "(Epoch 4301 / 10000) Train_Loss: 25.924; Val_Loss: 1001.908   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.290; Val_NMI: 4.627\n",
      "(Epoch 4302 / 10000) Train_Loss: 26.111; Val_Loss: 935.485   Train_ACC: 14.456; Val_ACC: 19.630   Train_NMI: 0.267; Val_NMI: 3.782\n",
      "(Epoch 4303 / 10000) Train_Loss: 27.186; Val_Loss: 988.009   Train_ACC: 14.539; Val_ACC: 20.370   Train_NMI: 0.337; Val_NMI: 4.880\n",
      "(Epoch 4304 / 10000) Train_Loss: 27.460; Val_Loss: 969.009   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.292; Val_NMI: 4.181\n",
      "(Epoch 4305 / 10000) Train_Loss: 26.517; Val_Loss: 1067.971   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.292; Val_NMI: 3.882\n",
      "(Epoch 4306 / 10000) Train_Loss: 27.144; Val_Loss: 983.947   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 4.370\n",
      "(Epoch 4307 / 10000) Train_Loss: 31.316; Val_Loss: 1010.906   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.331; Val_NMI: 4.072\n",
      "(Epoch 4308 / 10000) Train_Loss: 28.354; Val_Loss: 1001.611   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.005\n",
      "(Epoch 4309 / 10000) Train_Loss: 26.986; Val_Loss: 1014.169   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.356; Val_NMI: 3.999\n",
      "(Epoch 4310 / 10000) Train_Loss: 25.768; Val_Loss: 971.539   Train_ACC: 14.374; Val_ACC: 19.259   Train_NMI: 0.261; Val_NMI: 4.177\n",
      "(Epoch 4311 / 10000) Train_Loss: 25.781; Val_Loss: 1016.962   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 3.849\n",
      "(Epoch 4312 / 10000) Train_Loss: 25.955; Val_Loss: 978.551   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.378; Val_NMI: 3.822\n",
      "(Epoch 4313 / 10000) Train_Loss: 25.716; Val_Loss: 959.296   Train_ACC: 14.621; Val_ACC: 18.519   Train_NMI: 0.326; Val_NMI: 3.949\n",
      "(Epoch 4314 / 10000) Train_Loss: 26.314; Val_Loss: 1010.389   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.302; Val_NMI: 4.005\n",
      "(Epoch 4315 / 10000) Train_Loss: 29.654; Val_Loss: 988.431   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 4.135\n",
      "(Epoch 4316 / 10000) Train_Loss: 29.404; Val_Loss: 1040.089   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.305; Val_NMI: 4.584\n",
      "(Epoch 4317 / 10000) Train_Loss: 28.521; Val_Loss: 977.086   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.027\n",
      "(Epoch 4318 / 10000) Train_Loss: 27.007; Val_Loss: 1037.189   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.338; Val_NMI: 3.955\n",
      "(Epoch 4319 / 10000) Train_Loss: 26.245; Val_Loss: 999.035   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.345; Val_NMI: 4.272\n",
      "(Epoch 4320 / 10000) Train_Loss: 25.984; Val_Loss: 1059.355   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.304; Val_NMI: 3.941\n",
      "(Epoch 4321 / 10000) Train_Loss: 26.992; Val_Loss: 998.793   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.328; Val_NMI: 3.952\n",
      "(Epoch 4322 / 10000) Train_Loss: 25.680; Val_Loss: 1057.253   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.074\n",
      "(Epoch 4323 / 10000) Train_Loss: 25.844; Val_Loss: 1002.947   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.577\n",
      "(Epoch 4324 / 10000) Train_Loss: 26.141; Val_Loss: 962.224   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 4.139\n",
      "(Epoch 4325 / 10000) Train_Loss: 26.477; Val_Loss: 1027.667   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.341; Val_NMI: 3.751\n",
      "(Epoch 4326 / 10000) Train_Loss: 26.727; Val_Loss: 975.216   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.456\n",
      "(Epoch 4327 / 10000) Train_Loss: 28.196; Val_Loss: 972.127   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.276; Val_NMI: 3.927\n",
      "(Epoch 4328 / 10000) Train_Loss: 27.189; Val_Loss: 1021.757   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.513\n",
      "(Epoch 4329 / 10000) Train_Loss: 26.883; Val_Loss: 1012.337   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 3.940\n",
      "(Epoch 4330 / 10000) Train_Loss: 25.973; Val_Loss: 1035.915   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.313; Val_NMI: 4.354\n",
      "(Epoch 4331 / 10000) Train_Loss: 26.867; Val_Loss: 1014.435   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.326; Val_NMI: 4.158\n",
      "(Epoch 4332 / 10000) Train_Loss: 26.705; Val_Loss: 1014.079   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.296; Val_NMI: 4.244\n",
      "(Epoch 4333 / 10000) Train_Loss: 26.113; Val_Loss: 1016.076   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.311; Val_NMI: 4.085\n",
      "(Epoch 4334 / 10000) Train_Loss: 28.319; Val_Loss: 985.210   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 4.318\n",
      "(Epoch 4335 / 10000) Train_Loss: 27.665; Val_Loss: 1015.927   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.352; Val_NMI: 4.048\n",
      "(Epoch 4336 / 10000) Train_Loss: 26.167; Val_Loss: 1013.788   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 3.917\n",
      "(Epoch 4337 / 10000) Train_Loss: 27.025; Val_Loss: 962.720   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 4.609\n",
      "(Epoch 4338 / 10000) Train_Loss: 26.104; Val_Loss: 1021.533   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 4.244\n",
      "(Epoch 4339 / 10000) Train_Loss: 29.323; Val_Loss: 1013.313   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.302; Val_NMI: 4.470\n",
      "(Epoch 4340 / 10000) Train_Loss: 30.266; Val_Loss: 1033.339   Train_ACC: 14.662; Val_ACC: 20.370   Train_NMI: 0.345; Val_NMI: 4.681\n",
      "(Epoch 4341 / 10000) Train_Loss: 28.319; Val_Loss: 1024.367   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.310; Val_NMI: 4.380\n",
      "(Epoch 4342 / 10000) Train_Loss: 26.849; Val_Loss: 995.071   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.295; Val_NMI: 4.400\n",
      "(Epoch 4343 / 10000) Train_Loss: 26.013; Val_Loss: 974.667   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.305; Val_NMI: 4.397\n",
      "(Epoch 4344 / 10000) Train_Loss: 27.349; Val_Loss: 963.704   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.334; Val_NMI: 4.476\n",
      "(Epoch 4345 / 10000) Train_Loss: 27.300; Val_Loss: 979.165   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.325; Val_NMI: 4.299\n",
      "(Epoch 4346 / 10000) Train_Loss: 27.258; Val_Loss: 970.177   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.979\n",
      "(Epoch 4347 / 10000) Train_Loss: 27.410; Val_Loss: 1039.516   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 3.932\n",
      "(Epoch 4348 / 10000) Train_Loss: 28.145; Val_Loss: 963.979   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.391; Val_NMI: 3.542\n",
      "(Epoch 4349 / 10000) Train_Loss: 32.402; Val_Loss: 1045.120   Train_ACC: 14.456; Val_ACC: 19.630   Train_NMI: 0.300; Val_NMI: 4.081\n",
      "(Epoch 4350 / 10000) Train_Loss: 30.077; Val_Loss: 988.039   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.346; Val_NMI: 3.752\n",
      "(Epoch 4351 / 10000) Train_Loss: 29.219; Val_Loss: 981.380   Train_ACC: 15.074; Val_ACC: 18.519   Train_NMI: 0.373; Val_NMI: 3.954\n",
      "(Epoch 4352 / 10000) Train_Loss: 29.334; Val_Loss: 966.892   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.571\n",
      "(Epoch 4353 / 10000) Train_Loss: 28.339; Val_Loss: 1007.077   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.307; Val_NMI: 4.166\n",
      "(Epoch 4354 / 10000) Train_Loss: 28.726; Val_Loss: 1015.514   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.332; Val_NMI: 4.135\n",
      "(Epoch 4355 / 10000) Train_Loss: 27.903; Val_Loss: 997.150   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.784\n",
      "(Epoch 4356 / 10000) Train_Loss: 26.506; Val_Loss: 1055.930   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.301; Val_NMI: 4.017\n",
      "(Epoch 4357 / 10000) Train_Loss: 27.295; Val_Loss: 1002.352   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.298; Val_NMI: 4.349\n",
      "(Epoch 4358 / 10000) Train_Loss: 26.532; Val_Loss: 1023.521   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 4.231\n",
      "(Epoch 4359 / 10000) Train_Loss: 25.574; Val_Loss: 945.456   Train_ACC: 14.456; Val_ACC: 18.519   Train_NMI: 0.322; Val_NMI: 3.800\n",
      "(Epoch 4360 / 10000) Train_Loss: 27.196; Val_Loss: 1019.458   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.344; Val_NMI: 4.571\n",
      "(Epoch 4361 / 10000) Train_Loss: 26.126; Val_Loss: 1013.473   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.345; Val_NMI: 4.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4362 / 10000) Train_Loss: 25.531; Val_Loss: 964.671   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.371; Val_NMI: 4.076\n",
      "(Epoch 4363 / 10000) Train_Loss: 27.006; Val_Loss: 1022.490   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.360; Val_NMI: 3.988\n",
      "(Epoch 4364 / 10000) Train_Loss: 28.596; Val_Loss: 997.241   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.363; Val_NMI: 4.460\n",
      "(Epoch 4365 / 10000) Train_Loss: 26.533; Val_Loss: 987.113   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.337; Val_NMI: 3.672\n",
      "(Epoch 4366 / 10000) Train_Loss: 25.651; Val_Loss: 1012.384   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 4.186\n",
      "(Epoch 4367 / 10000) Train_Loss: 26.186; Val_Loss: 1012.801   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 4.139\n",
      "(Epoch 4368 / 10000) Train_Loss: 27.458; Val_Loss: 1025.879   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.340; Val_NMI: 4.189\n",
      "(Epoch 4369 / 10000) Train_Loss: 26.326; Val_Loss: 1004.433   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.293; Val_NMI: 4.411\n",
      "(Epoch 4370 / 10000) Train_Loss: 26.952; Val_Loss: 994.369   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.274; Val_NMI: 4.050\n",
      "(Epoch 4371 / 10000) Train_Loss: 26.961; Val_Loss: 1006.932   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.360; Val_NMI: 4.508\n",
      "(Epoch 4372 / 10000) Train_Loss: 29.939; Val_Loss: 1011.613   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.367; Val_NMI: 4.752\n",
      "(Epoch 4373 / 10000) Train_Loss: 29.533; Val_Loss: 1033.979   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.295; Val_NMI: 4.753\n",
      "(Epoch 4374 / 10000) Train_Loss: 28.343; Val_Loss: 990.981   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.378\n",
      "(Epoch 4375 / 10000) Train_Loss: 29.396; Val_Loss: 1016.497   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.511\n",
      "(Epoch 4376 / 10000) Train_Loss: 31.485; Val_Loss: 1017.418   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.381; Val_NMI: 4.370\n",
      "(Epoch 4377 / 10000) Train_Loss: 27.688; Val_Loss: 993.732   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.313; Val_NMI: 3.944\n",
      "(Epoch 4378 / 10000) Train_Loss: 25.734; Val_Loss: 1052.916   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.289; Val_NMI: 4.374\n",
      "(Epoch 4379 / 10000) Train_Loss: 25.947; Val_Loss: 993.562   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 4.600\n",
      "(Epoch 4380 / 10000) Train_Loss: 28.404; Val_Loss: 1039.608   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.457; Val_NMI: 4.985\n",
      "(Epoch 4381 / 10000) Train_Loss: 27.663; Val_Loss: 986.495   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.171\n",
      "(Epoch 4382 / 10000) Train_Loss: 26.564; Val_Loss: 1002.472   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.329; Val_NMI: 4.165\n",
      "(Epoch 4383 / 10000) Train_Loss: 26.490; Val_Loss: 1052.125   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.388; Val_NMI: 4.055\n",
      "(Epoch 4384 / 10000) Train_Loss: 27.285; Val_Loss: 1029.362   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.382; Val_NMI: 3.786\n",
      "(Epoch 4385 / 10000) Train_Loss: 27.546; Val_Loss: 963.104   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.315; Val_NMI: 3.822\n",
      "(Epoch 4386 / 10000) Train_Loss: 26.211; Val_Loss: 1019.413   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.172\n",
      "(Epoch 4387 / 10000) Train_Loss: 25.831; Val_Loss: 1054.148   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.310; Val_NMI: 4.207\n",
      "(Epoch 4388 / 10000) Train_Loss: 26.983; Val_Loss: 1012.900   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.316; Val_NMI: 4.612\n",
      "(Epoch 4389 / 10000) Train_Loss: 26.364; Val_Loss: 1072.192   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.007\n",
      "(Epoch 4390 / 10000) Train_Loss: 25.997; Val_Loss: 1092.716   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.306; Val_NMI: 3.952\n",
      "(Epoch 4391 / 10000) Train_Loss: 27.265; Val_Loss: 1019.113   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 3.953\n",
      "(Epoch 4392 / 10000) Train_Loss: 30.511; Val_Loss: 999.081   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.165\n",
      "(Epoch 4393 / 10000) Train_Loss: 27.392; Val_Loss: 1088.813   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.372; Val_NMI: 3.882\n",
      "(Epoch 4394 / 10000) Train_Loss: 27.224; Val_Loss: 949.765   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.309; Val_NMI: 3.983\n",
      "(Epoch 4395 / 10000) Train_Loss: 26.225; Val_Loss: 986.574   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.362; Val_NMI: 4.076\n",
      "(Epoch 4396 / 10000) Train_Loss: 26.487; Val_Loss: 1005.135   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.352; Val_NMI: 4.163\n",
      "(Epoch 4397 / 10000) Train_Loss: 26.585; Val_Loss: 1004.556   Train_ACC: 14.456; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 4.441\n",
      "(Epoch 4398 / 10000) Train_Loss: 27.091; Val_Loss: 981.974   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.311; Val_NMI: 3.866\n",
      "(Epoch 4399 / 10000) Train_Loss: 26.929; Val_Loss: 1003.272   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 4.641\n",
      "(Epoch 4400 / 10000) Train_Loss: 28.733; Val_Loss: 1034.253   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 4.344\n",
      "(Epoch 4401 / 10000) Train_Loss: 28.721; Val_Loss: 1020.123   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 4.104\n",
      "(Epoch 4402 / 10000) Train_Loss: 26.814; Val_Loss: 1010.621   Train_ACC: 14.539; Val_ACC: 18.519   Train_NMI: 0.312; Val_NMI: 3.882\n",
      "(Epoch 4403 / 10000) Train_Loss: 28.851; Val_Loss: 955.148   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.311; Val_NMI: 4.090\n",
      "(Epoch 4404 / 10000) Train_Loss: 27.848; Val_Loss: 973.694   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.305; Val_NMI: 3.874\n",
      "(Epoch 4405 / 10000) Train_Loss: 28.594; Val_Loss: 1060.154   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.379\n",
      "(Epoch 4406 / 10000) Train_Loss: 26.494; Val_Loss: 1047.130   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.321; Val_NMI: 4.410\n",
      "(Epoch 4407 / 10000) Train_Loss: 31.882; Val_Loss: 1037.189   Train_ACC: 14.415; Val_ACC: 19.630   Train_NMI: 0.282; Val_NMI: 4.506\n",
      "(Epoch 4408 / 10000) Train_Loss: 27.774; Val_Loss: 1000.145   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.307; Val_NMI: 4.268\n",
      "(Epoch 4409 / 10000) Train_Loss: 25.787; Val_Loss: 991.117   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.210\n",
      "(Epoch 4410 / 10000) Train_Loss: 25.291; Val_Loss: 965.004   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 4.031\n",
      "(Epoch 4411 / 10000) Train_Loss: 25.915; Val_Loss: 964.884   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.322; Val_NMI: 3.868\n",
      "(Epoch 4412 / 10000) Train_Loss: 26.347; Val_Loss: 950.669   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.292; Val_NMI: 3.809\n",
      "(Epoch 4413 / 10000) Train_Loss: 27.629; Val_Loss: 1004.311   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.327; Val_NMI: 3.934\n",
      "(Epoch 4414 / 10000) Train_Loss: 26.431; Val_Loss: 1042.408   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 4.062\n",
      "(Epoch 4415 / 10000) Train_Loss: 25.498; Val_Loss: 989.914   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.336; Val_NMI: 4.159\n",
      "(Epoch 4416 / 10000) Train_Loss: 26.334; Val_Loss: 1013.041   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.340; Val_NMI: 4.251\n",
      "(Epoch 4417 / 10000) Train_Loss: 27.043; Val_Loss: 1004.205   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.347; Val_NMI: 4.218\n",
      "(Epoch 4418 / 10000) Train_Loss: 26.226; Val_Loss: 1039.653   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.383; Val_NMI: 4.480\n",
      "(Epoch 4419 / 10000) Train_Loss: 26.626; Val_Loss: 1025.508   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 3.801\n",
      "(Epoch 4420 / 10000) Train_Loss: 29.526; Val_Loss: 1049.010   Train_ACC: 14.909; Val_ACC: 18.889   Train_NMI: 0.355; Val_NMI: 3.997\n",
      "(Epoch 4421 / 10000) Train_Loss: 27.539; Val_Loss: 1041.343   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.354; Val_NMI: 4.271\n",
      "(Epoch 4422 / 10000) Train_Loss: 25.651; Val_Loss: 1051.913   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.336; Val_NMI: 3.986\n",
      "(Epoch 4423 / 10000) Train_Loss: 26.062; Val_Loss: 984.103   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.274; Val_NMI: 3.997\n",
      "(Epoch 4424 / 10000) Train_Loss: 26.585; Val_Loss: 1017.207   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 4.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4425 / 10000) Train_Loss: 28.391; Val_Loss: 994.131   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.306; Val_NMI: 4.263\n",
      "(Epoch 4426 / 10000) Train_Loss: 27.758; Val_Loss: 1044.239   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.330; Val_NMI: 4.149\n",
      "(Epoch 4427 / 10000) Train_Loss: 27.844; Val_Loss: 1008.462   Train_ACC: 14.580; Val_ACC: 20.000   Train_NMI: 0.306; Val_NMI: 4.356\n",
      "(Epoch 4428 / 10000) Train_Loss: 28.326; Val_Loss: 1013.046   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.327; Val_NMI: 3.757\n",
      "(Epoch 4429 / 10000) Train_Loss: 26.801; Val_Loss: 1048.510   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.284; Val_NMI: 3.566\n",
      "(Epoch 4430 / 10000) Train_Loss: 26.055; Val_Loss: 1026.459   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 3.772\n",
      "(Epoch 4431 / 10000) Train_Loss: 25.708; Val_Loss: 1000.958   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.351; Val_NMI: 4.265\n",
      "(Epoch 4432 / 10000) Train_Loss: 26.769; Val_Loss: 981.066   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.318; Val_NMI: 3.987\n",
      "(Epoch 4433 / 10000) Train_Loss: 26.306; Val_Loss: 1028.384   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.327; Val_NMI: 3.816\n",
      "(Epoch 4434 / 10000) Train_Loss: 26.286; Val_Loss: 1060.331   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 4.093\n",
      "(Epoch 4435 / 10000) Train_Loss: 29.171; Val_Loss: 985.250   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 4.414\n",
      "(Epoch 4436 / 10000) Train_Loss: 28.556; Val_Loss: 1017.904   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.297; Val_NMI: 4.263\n",
      "(Epoch 4437 / 10000) Train_Loss: 27.959; Val_Loss: 1034.187   Train_ACC: 14.580; Val_ACC: 19.259   Train_NMI: 0.316; Val_NMI: 4.113\n",
      "(Epoch 4438 / 10000) Train_Loss: 28.074; Val_Loss: 974.396   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.312; Val_NMI: 3.720\n",
      "(Epoch 4439 / 10000) Train_Loss: 27.058; Val_Loss: 976.413   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.297; Val_NMI: 4.111\n",
      "(Epoch 4440 / 10000) Train_Loss: 26.359; Val_Loss: 970.720   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.313; Val_NMI: 3.791\n",
      "(Epoch 4441 / 10000) Train_Loss: 29.020; Val_Loss: 1036.610   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 4.001\n",
      "(Epoch 4442 / 10000) Train_Loss: 31.015; Val_Loss: 1005.722   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.309; Val_NMI: 3.603\n",
      "(Epoch 4443 / 10000) Train_Loss: 28.660; Val_Loss: 1107.445   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.311; Val_NMI: 4.134\n",
      "(Epoch 4444 / 10000) Train_Loss: 27.279; Val_Loss: 1055.423   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.315; Val_NMI: 3.797\n",
      "(Epoch 4445 / 10000) Train_Loss: 28.881; Val_Loss: 1039.632   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.334; Val_NMI: 3.948\n",
      "(Epoch 4446 / 10000) Train_Loss: 26.413; Val_Loss: 1025.116   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.343; Val_NMI: 4.185\n",
      "(Epoch 4447 / 10000) Train_Loss: 25.086; Val_Loss: 1050.867   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.278; Val_NMI: 4.288\n",
      "(Epoch 4448 / 10000) Train_Loss: 25.941; Val_Loss: 1051.935   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.313; Val_NMI: 4.218\n",
      "(Epoch 4449 / 10000) Train_Loss: 26.468; Val_Loss: 1039.515   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.295; Val_NMI: 4.121\n",
      "(Epoch 4450 / 10000) Train_Loss: 29.761; Val_Loss: 943.452   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.330; Val_NMI: 4.309\n",
      "(Epoch 4451 / 10000) Train_Loss: 28.007; Val_Loss: 1051.711   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.303; Val_NMI: 4.000\n",
      "(Epoch 4452 / 10000) Train_Loss: 26.197; Val_Loss: 1022.596   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.339; Val_NMI: 4.420\n",
      "(Epoch 4453 / 10000) Train_Loss: 25.430; Val_Loss: 1014.762   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 4.086\n",
      "(Epoch 4454 / 10000) Train_Loss: 25.725; Val_Loss: 983.929   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.295; Val_NMI: 3.760\n",
      "(Epoch 4455 / 10000) Train_Loss: 25.916; Val_Loss: 1066.772   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.333; Val_NMI: 4.403\n",
      "(Epoch 4456 / 10000) Train_Loss: 25.824; Val_Loss: 1006.577   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.346; Val_NMI: 4.059\n",
      "(Epoch 4457 / 10000) Train_Loss: 25.647; Val_Loss: 996.075   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.336; Val_NMI: 4.144\n",
      "(Epoch 4458 / 10000) Train_Loss: 26.636; Val_Loss: 948.991   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.107\n",
      "(Epoch 4459 / 10000) Train_Loss: 27.715; Val_Loss: 1008.675   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.327; Val_NMI: 4.262\n",
      "(Epoch 4460 / 10000) Train_Loss: 26.541; Val_Loss: 1038.849   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.428; Val_NMI: 4.236\n",
      "(Epoch 4461 / 10000) Train_Loss: 26.109; Val_Loss: 1047.430   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.375; Val_NMI: 4.152\n",
      "(Epoch 4462 / 10000) Train_Loss: 26.068; Val_Loss: 1059.478   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.258; Val_NMI: 4.204\n",
      "(Epoch 4463 / 10000) Train_Loss: 26.209; Val_Loss: 970.675   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.308; Val_NMI: 4.108\n",
      "(Epoch 4464 / 10000) Train_Loss: 30.618; Val_Loss: 1011.391   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.399; Val_NMI: 3.973\n",
      "(Epoch 4465 / 10000) Train_Loss: 33.027; Val_Loss: 1019.705   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.328; Val_NMI: 4.297\n",
      "(Epoch 4466 / 10000) Train_Loss: 32.635; Val_Loss: 1010.320   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 3.817\n",
      "(Epoch 4467 / 10000) Train_Loss: 29.492; Val_Loss: 1030.758   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 4.494\n",
      "(Epoch 4468 / 10000) Train_Loss: 27.260; Val_Loss: 997.328   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.317; Val_NMI: 3.919\n",
      "(Epoch 4469 / 10000) Train_Loss: 26.566; Val_Loss: 1028.295   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.341; Val_NMI: 3.874\n",
      "(Epoch 4470 / 10000) Train_Loss: 26.153; Val_Loss: 980.443   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.305; Val_NMI: 3.239\n",
      "(Epoch 4471 / 10000) Train_Loss: 29.393; Val_Loss: 990.136   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.341\n",
      "(Epoch 4472 / 10000) Train_Loss: 28.128; Val_Loss: 1029.035   Train_ACC: 14.580; Val_ACC: 19.630   Train_NMI: 0.331; Val_NMI: 4.033\n",
      "(Epoch 4473 / 10000) Train_Loss: 26.473; Val_Loss: 1034.356   Train_ACC: 14.415; Val_ACC: 18.889   Train_NMI: 0.275; Val_NMI: 3.845\n",
      "(Epoch 4474 / 10000) Train_Loss: 26.806; Val_Loss: 1008.595   Train_ACC: 14.539; Val_ACC: 18.889   Train_NMI: 0.237; Val_NMI: 3.764\n",
      "(Epoch 4475 / 10000) Train_Loss: 25.713; Val_Loss: 998.101   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.304; Val_NMI: 3.811\n",
      "(Epoch 4476 / 10000) Train_Loss: 25.798; Val_Loss: 999.204   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.369; Val_NMI: 3.345\n",
      "(Epoch 4477 / 10000) Train_Loss: 26.652; Val_Loss: 957.699   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 4.473\n",
      "(Epoch 4478 / 10000) Train_Loss: 26.977; Val_Loss: 1083.171   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.299; Val_NMI: 3.917\n",
      "(Epoch 4479 / 10000) Train_Loss: 28.174; Val_Loss: 1061.766   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.360; Val_NMI: 4.236\n",
      "(Epoch 4480 / 10000) Train_Loss: 27.934; Val_Loss: 1012.671   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.329; Val_NMI: 3.968\n",
      "(Epoch 4481 / 10000) Train_Loss: 27.244; Val_Loss: 1017.623   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.292; Val_NMI: 4.534\n",
      "(Epoch 4482 / 10000) Train_Loss: 25.493; Val_Loss: 1016.105   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.299; Val_NMI: 4.535\n",
      "(Epoch 4483 / 10000) Train_Loss: 26.647; Val_Loss: 1014.609   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.319; Val_NMI: 3.947\n",
      "(Epoch 4484 / 10000) Train_Loss: 27.411; Val_Loss: 986.728   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 3.879\n",
      "(Epoch 4485 / 10000) Train_Loss: 31.022; Val_Loss: 1079.364   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 3.787\n",
      "(Epoch 4486 / 10000) Train_Loss: 30.812; Val_Loss: 1023.000   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.400; Val_NMI: 3.630\n",
      "(Epoch 4487 / 10000) Train_Loss: 31.306; Val_Loss: 1017.695   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.335; Val_NMI: 4.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4488 / 10000) Train_Loss: 27.127; Val_Loss: 949.559   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.372; Val_NMI: 4.195\n",
      "(Epoch 4489 / 10000) Train_Loss: 26.985; Val_Loss: 958.405   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.370; Val_NMI: 4.274\n",
      "(Epoch 4490 / 10000) Train_Loss: 25.595; Val_Loss: 1013.812   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.328; Val_NMI: 3.921\n",
      "(Epoch 4491 / 10000) Train_Loss: 25.777; Val_Loss: 978.296   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.316; Val_NMI: 3.945\n",
      "(Epoch 4492 / 10000) Train_Loss: 26.264; Val_Loss: 1015.659   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.295; Val_NMI: 3.683\n",
      "(Epoch 4493 / 10000) Train_Loss: 25.740; Val_Loss: 1045.997   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.370; Val_NMI: 4.075\n",
      "(Epoch 4494 / 10000) Train_Loss: 25.498; Val_Loss: 1012.955   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.362; Val_NMI: 4.297\n",
      "(Epoch 4495 / 10000) Train_Loss: 26.656; Val_Loss: 1049.712   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.081\n",
      "(Epoch 4496 / 10000) Train_Loss: 27.392; Val_Loss: 1047.531   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.319; Val_NMI: 3.953\n",
      "(Epoch 4497 / 10000) Train_Loss: 25.144; Val_Loss: 957.911   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.086\n",
      "(Epoch 4498 / 10000) Train_Loss: 25.864; Val_Loss: 1057.521   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.353; Val_NMI: 4.508\n",
      "(Epoch 4499 / 10000) Train_Loss: 25.732; Val_Loss: 979.768   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.354; Val_NMI: 4.006\n",
      "(Epoch 4500 / 10000) Train_Loss: 26.398; Val_Loss: 1025.658   Train_ACC: 14.580; Val_ACC: 18.889   Train_NMI: 0.280; Val_NMI: 3.939\n",
      "(Epoch 4501 / 10000) Train_Loss: 26.982; Val_Loss: 1034.806   Train_ACC: 14.786; Val_ACC: 20.370   Train_NMI: 0.314; Val_NMI: 4.703\n",
      "(Epoch 4502 / 10000) Train_Loss: 25.335; Val_Loss: 1015.730   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.366; Val_NMI: 4.114\n",
      "(Epoch 4503 / 10000) Train_Loss: 26.629; Val_Loss: 1001.288   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.306; Val_NMI: 4.096\n",
      "(Epoch 4504 / 10000) Train_Loss: 26.988; Val_Loss: 999.312   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.348; Val_NMI: 3.607\n",
      "(Epoch 4505 / 10000) Train_Loss: 30.504; Val_Loss: 1046.301   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.358; Val_NMI: 4.033\n",
      "(Epoch 4506 / 10000) Train_Loss: 29.006; Val_Loss: 995.056   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.389; Val_NMI: 4.532\n",
      "(Epoch 4507 / 10000) Train_Loss: 28.850; Val_Loss: 986.229   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 4.032\n",
      "(Epoch 4508 / 10000) Train_Loss: 27.040; Val_Loss: 971.436   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 3.784\n",
      "(Epoch 4509 / 10000) Train_Loss: 26.216; Val_Loss: 952.784   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 4.211\n",
      "(Epoch 4510 / 10000) Train_Loss: 26.651; Val_Loss: 1037.838   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.312; Val_NMI: 4.079\n",
      "(Epoch 4511 / 10000) Train_Loss: 30.631; Val_Loss: 994.557   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.320; Val_NMI: 4.068\n",
      "(Epoch 4512 / 10000) Train_Loss: 30.815; Val_Loss: 1001.537   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.322; Val_NMI: 4.362\n",
      "(Epoch 4513 / 10000) Train_Loss: 28.951; Val_Loss: 991.504   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.325; Val_NMI: 3.835\n",
      "(Epoch 4514 / 10000) Train_Loss: 30.798; Val_Loss: 1019.891   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.330; Val_NMI: 3.890\n",
      "(Epoch 4515 / 10000) Train_Loss: 31.247; Val_Loss: 998.744   Train_ACC: 14.374; Val_ACC: 19.259   Train_NMI: 0.304; Val_NMI: 4.334\n",
      "(Epoch 4516 / 10000) Train_Loss: 28.388; Val_Loss: 1037.528   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.294; Val_NMI: 3.919\n",
      "(Epoch 4517 / 10000) Train_Loss: 30.165; Val_Loss: 1051.967   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.310; Val_NMI: 3.861\n",
      "(Epoch 4518 / 10000) Train_Loss: 28.952; Val_Loss: 1051.946   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.249\n",
      "(Epoch 4519 / 10000) Train_Loss: 27.464; Val_Loss: 1016.750   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.379; Val_NMI: 4.087\n",
      "(Epoch 4520 / 10000) Train_Loss: 26.296; Val_Loss: 1040.700   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.331; Val_NMI: 4.322\n",
      "(Epoch 4521 / 10000) Train_Loss: 27.632; Val_Loss: 1025.797   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.324; Val_NMI: 4.274\n",
      "(Epoch 4522 / 10000) Train_Loss: 27.443; Val_Loss: 960.487   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.391; Val_NMI: 3.839\n",
      "(Epoch 4523 / 10000) Train_Loss: 25.849; Val_Loss: 982.137   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.350; Val_NMI: 3.986\n",
      "(Epoch 4524 / 10000) Train_Loss: 25.654; Val_Loss: 1043.827   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.365; Val_NMI: 3.857\n",
      "(Epoch 4525 / 10000) Train_Loss: 28.020; Val_Loss: 1022.721   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.384; Val_NMI: 4.173\n",
      "(Epoch 4526 / 10000) Train_Loss: 27.374; Val_Loss: 1029.312   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.278; Val_NMI: 3.989\n",
      "(Epoch 4527 / 10000) Train_Loss: 27.852; Val_Loss: 1009.692   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.410; Val_NMI: 3.983\n",
      "(Epoch 4528 / 10000) Train_Loss: 26.817; Val_Loss: 1000.590   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 4.103\n",
      "(Epoch 4529 / 10000) Train_Loss: 26.593; Val_Loss: 1047.898   Train_ACC: 14.745; Val_ACC: 20.370   Train_NMI: 0.346; Val_NMI: 4.149\n",
      "(Epoch 4530 / 10000) Train_Loss: 26.583; Val_Loss: 959.406   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.327; Val_NMI: 4.600\n",
      "(Epoch 4531 / 10000) Train_Loss: 25.856; Val_Loss: 991.502   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 3.613\n",
      "(Epoch 4532 / 10000) Train_Loss: 25.650; Val_Loss: 998.639   Train_ACC: 14.498; Val_ACC: 19.630   Train_NMI: 0.323; Val_NMI: 3.873\n",
      "(Epoch 4533 / 10000) Train_Loss: 25.916; Val_Loss: 983.996   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.387; Val_NMI: 4.723\n",
      "(Epoch 4534 / 10000) Train_Loss: 26.383; Val_Loss: 956.967   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 3.716\n",
      "(Epoch 4535 / 10000) Train_Loss: 28.750; Val_Loss: 1028.054   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.362; Val_NMI: 4.352\n",
      "(Epoch 4536 / 10000) Train_Loss: 28.842; Val_Loss: 1002.595   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.333; Val_NMI: 4.076\n",
      "(Epoch 4537 / 10000) Train_Loss: 26.756; Val_Loss: 987.478   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.359; Val_NMI: 4.495\n",
      "(Epoch 4538 / 10000) Train_Loss: 25.992; Val_Loss: 1040.758   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.382; Val_NMI: 4.526\n",
      "(Epoch 4539 / 10000) Train_Loss: 26.047; Val_Loss: 989.363   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 4.518\n",
      "(Epoch 4540 / 10000) Train_Loss: 25.239; Val_Loss: 1001.477   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.355; Val_NMI: 4.936\n",
      "(Epoch 4541 / 10000) Train_Loss: 25.929; Val_Loss: 986.143   Train_ACC: 14.621; Val_ACC: 19.630   Train_NMI: 0.312; Val_NMI: 3.849\n",
      "(Epoch 4542 / 10000) Train_Loss: 26.600; Val_Loss: 974.028   Train_ACC: 14.621; Val_ACC: 20.370   Train_NMI: 0.317; Val_NMI: 4.328\n",
      "(Epoch 4543 / 10000) Train_Loss: 26.264; Val_Loss: 1030.498   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.334; Val_NMI: 3.948\n",
      "(Epoch 4544 / 10000) Train_Loss: 27.366; Val_Loss: 1013.567   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.295; Val_NMI: 4.408\n",
      "(Epoch 4545 / 10000) Train_Loss: 26.149; Val_Loss: 985.790   Train_ACC: 14.539; Val_ACC: 19.259   Train_NMI: 0.298; Val_NMI: 3.786\n",
      "(Epoch 4546 / 10000) Train_Loss: 25.994; Val_Loss: 997.490   Train_ACC: 14.662; Val_ACC: 18.519   Train_NMI: 0.303; Val_NMI: 3.342\n",
      "(Epoch 4547 / 10000) Train_Loss: 25.668; Val_Loss: 1029.584   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.348; Val_NMI: 4.348\n",
      "(Epoch 4548 / 10000) Train_Loss: 25.970; Val_Loss: 984.538   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.317; Val_NMI: 3.662\n",
      "(Epoch 4549 / 10000) Train_Loss: 27.966; Val_Loss: 975.093   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 4.235\n",
      "(Epoch 4550 / 10000) Train_Loss: 27.576; Val_Loss: 1045.797   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.317; Val_NMI: 3.931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4551 / 10000) Train_Loss: 27.654; Val_Loss: 993.953   Train_ACC: 14.662; Val_ACC: 19.259   Train_NMI: 0.321; Val_NMI: 3.826\n",
      "(Epoch 4552 / 10000) Train_Loss: 27.433; Val_Loss: 1040.101   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.233\n",
      "(Epoch 4553 / 10000) Train_Loss: 25.834; Val_Loss: 995.460   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 4.116\n",
      "(Epoch 4554 / 10000) Train_Loss: 25.811; Val_Loss: 1002.397   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.342; Val_NMI: 3.710\n",
      "(Epoch 4555 / 10000) Train_Loss: 26.332; Val_Loss: 985.265   Train_ACC: 14.786; Val_ACC: 18.148   Train_NMI: 0.337; Val_NMI: 3.440\n",
      "(Epoch 4556 / 10000) Train_Loss: 27.176; Val_Loss: 974.949   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.328; Val_NMI: 3.896\n",
      "(Epoch 4557 / 10000) Train_Loss: 28.566; Val_Loss: 1022.214   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.400; Val_NMI: 3.822\n",
      "(Epoch 4558 / 10000) Train_Loss: 27.079; Val_Loss: 1053.202   Train_ACC: 14.621; Val_ACC: 18.889   Train_NMI: 0.353; Val_NMI: 3.653\n",
      "(Epoch 4559 / 10000) Train_Loss: 25.841; Val_Loss: 1013.424   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.331; Val_NMI: 4.089\n",
      "(Epoch 4560 / 10000) Train_Loss: 27.058; Val_Loss: 1059.925   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.339; Val_NMI: 3.721\n",
      "(Epoch 4561 / 10000) Train_Loss: 26.191; Val_Loss: 939.264   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.320; Val_NMI: 3.842\n",
      "(Epoch 4562 / 10000) Train_Loss: 31.170; Val_Loss: 1057.883   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.315; Val_NMI: 4.207\n",
      "(Epoch 4563 / 10000) Train_Loss: 34.972; Val_Loss: 1016.123   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.342; Val_NMI: 4.032\n",
      "(Epoch 4564 / 10000) Train_Loss: 28.564; Val_Loss: 1048.479   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.271\n",
      "(Epoch 4565 / 10000) Train_Loss: 27.343; Val_Loss: 1006.409   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.340; Val_NMI: 3.859\n",
      "(Epoch 4566 / 10000) Train_Loss: 26.799; Val_Loss: 1046.854   Train_ACC: 14.415; Val_ACC: 18.889   Train_NMI: 0.326; Val_NMI: 4.027\n",
      "(Epoch 4567 / 10000) Train_Loss: 27.661; Val_Loss: 1064.875   Train_ACC: 14.786; Val_ACC: 18.889   Train_NMI: 0.356; Val_NMI: 4.041\n",
      "(Epoch 4568 / 10000) Train_Loss: 26.244; Val_Loss: 973.909   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.363; Val_NMI: 3.865\n",
      "(Epoch 4569 / 10000) Train_Loss: 26.322; Val_Loss: 1023.061   Train_ACC: 14.703; Val_ACC: 18.889   Train_NMI: 0.335; Val_NMI: 4.234\n",
      "(Epoch 4570 / 10000) Train_Loss: 27.357; Val_Loss: 1003.673   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.372; Val_NMI: 4.315\n",
      "(Epoch 4571 / 10000) Train_Loss: 26.304; Val_Loss: 965.341   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.370; Val_NMI: 3.638\n",
      "(Epoch 4572 / 10000) Train_Loss: 25.661; Val_Loss: 984.359   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 3.587\n",
      "(Epoch 4573 / 10000) Train_Loss: 26.701; Val_Loss: 985.343   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.346; Val_NMI: 4.429\n",
      "(Epoch 4574 / 10000) Train_Loss: 26.359; Val_Loss: 1020.677   Train_ACC: 14.827; Val_ACC: 18.519   Train_NMI: 0.404; Val_NMI: 3.799\n",
      "(Epoch 4575 / 10000) Train_Loss: 26.411; Val_Loss: 1012.938   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.335; Val_NMI: 4.691\n",
      "(Epoch 4576 / 10000) Train_Loss: 25.241; Val_Loss: 1065.071   Train_ACC: 14.745; Val_ACC: 18.889   Train_NMI: 0.283; Val_NMI: 4.062\n",
      "(Epoch 4577 / 10000) Train_Loss: 27.237; Val_Loss: 1101.891   Train_ACC: 14.827; Val_ACC: 20.370   Train_NMI: 0.316; Val_NMI: 4.878\n",
      "(Epoch 4578 / 10000) Train_Loss: 26.143; Val_Loss: 1039.543   Train_ACC: 14.703; Val_ACC: 19.259   Train_NMI: 0.288; Val_NMI: 3.658\n",
      "(Epoch 4579 / 10000) Train_Loss: 26.090; Val_Loss: 1081.192   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 3.826\n",
      "(Epoch 4580 / 10000) Train_Loss: 25.898; Val_Loss: 963.358   Train_ACC: 15.157; Val_ACC: 18.889   Train_NMI: 0.352; Val_NMI: 3.454\n",
      "(Epoch 4581 / 10000) Train_Loss: 26.153; Val_Loss: 1035.855   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.332; Val_NMI: 3.723\n",
      "(Epoch 4582 / 10000) Train_Loss: 27.672; Val_Loss: 1009.850   Train_ACC: 15.033; Val_ACC: 18.889   Train_NMI: 0.323; Val_NMI: 3.513\n",
      "(Epoch 4583 / 10000) Train_Loss: 27.426; Val_Loss: 1038.793   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 4.397\n",
      "(Epoch 4584 / 10000) Train_Loss: 26.890; Val_Loss: 990.621   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.448; Val_NMI: 4.284\n",
      "(Epoch 4585 / 10000) Train_Loss: 26.971; Val_Loss: 1025.358   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.396; Val_NMI: 3.894\n",
      "(Epoch 4586 / 10000) Train_Loss: 27.644; Val_Loss: 1003.842   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.380; Val_NMI: 4.449\n",
      "(Epoch 4587 / 10000) Train_Loss: 26.898; Val_Loss: 985.459   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.371; Val_NMI: 3.602\n",
      "(Epoch 4588 / 10000) Train_Loss: 25.725; Val_Loss: 1052.397   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 4.646\n",
      "(Epoch 4589 / 10000) Train_Loss: 26.402; Val_Loss: 1056.352   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.404; Val_NMI: 3.832\n",
      "(Epoch 4590 / 10000) Train_Loss: 26.533; Val_Loss: 950.610   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.366; Val_NMI: 4.230\n",
      "(Epoch 4591 / 10000) Train_Loss: 25.743; Val_Loss: 1040.501   Train_ACC: 15.115; Val_ACC: 19.630   Train_NMI: 0.450; Val_NMI: 4.224\n",
      "(Epoch 4592 / 10000) Train_Loss: 27.703; Val_Loss: 1022.875   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.372; Val_NMI: 3.617\n",
      "(Epoch 4593 / 10000) Train_Loss: 26.829; Val_Loss: 1016.879   Train_ACC: 14.951; Val_ACC: 18.519   Train_NMI: 0.389; Val_NMI: 3.679\n",
      "(Epoch 4594 / 10000) Train_Loss: 26.829; Val_Loss: 1064.550   Train_ACC: 14.868; Val_ACC: 18.889   Train_NMI: 0.374; Val_NMI: 3.947\n",
      "(Epoch 4595 / 10000) Train_Loss: 29.454; Val_Loss: 989.928   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.292; Val_NMI: 4.615\n",
      "(Epoch 4596 / 10000) Train_Loss: 31.241; Val_Loss: 997.842   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.472; Val_NMI: 3.621\n",
      "(Epoch 4597 / 10000) Train_Loss: 28.762; Val_Loss: 999.051   Train_ACC: 14.992; Val_ACC: 18.148   Train_NMI: 0.454; Val_NMI: 4.651\n",
      "(Epoch 4598 / 10000) Train_Loss: 27.076; Val_Loss: 1035.618   Train_ACC: 14.992; Val_ACC: 18.889   Train_NMI: 0.440; Val_NMI: 4.355\n",
      "(Epoch 4599 / 10000) Train_Loss: 27.748; Val_Loss: 938.960   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.415; Val_NMI: 4.271\n",
      "(Epoch 4600 / 10000) Train_Loss: 31.430; Val_Loss: 1085.353   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.454; Val_NMI: 4.523\n",
      "(Epoch 4601 / 10000) Train_Loss: 33.354; Val_Loss: 1020.569   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.383; Val_NMI: 4.785\n",
      "(Epoch 4602 / 10000) Train_Loss: 31.437; Val_Loss: 1061.403   Train_ACC: 14.951; Val_ACC: 18.889   Train_NMI: 0.348; Val_NMI: 4.535\n",
      "(Epoch 4603 / 10000) Train_Loss: 30.475; Val_Loss: 1027.174   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.355; Val_NMI: 4.385\n",
      "(Epoch 4604 / 10000) Train_Loss: 27.462; Val_Loss: 1090.911   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.371; Val_NMI: 4.066\n",
      "(Epoch 4605 / 10000) Train_Loss: 26.482; Val_Loss: 1039.360   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.442; Val_NMI: 4.435\n",
      "(Epoch 4606 / 10000) Train_Loss: 26.123; Val_Loss: 1018.950   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.379; Val_NMI: 3.925\n",
      "(Epoch 4607 / 10000) Train_Loss: 25.317; Val_Loss: 1008.525   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.424; Val_NMI: 4.246\n",
      "(Epoch 4608 / 10000) Train_Loss: 25.799; Val_Loss: 994.193   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.351; Val_NMI: 4.502\n",
      "(Epoch 4609 / 10000) Train_Loss: 25.957; Val_Loss: 1033.858   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 4.512\n",
      "(Epoch 4610 / 10000) Train_Loss: 26.463; Val_Loss: 950.296   Train_ACC: 15.115; Val_ACC: 18.519   Train_NMI: 0.476; Val_NMI: 3.902\n",
      "(Epoch 4611 / 10000) Train_Loss: 27.515; Val_Loss: 1034.677   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.409; Val_NMI: 4.246\n",
      "(Epoch 4612 / 10000) Train_Loss: 27.251; Val_Loss: 1049.767   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.393; Val_NMI: 4.768\n",
      "(Epoch 4613 / 10000) Train_Loss: 26.842; Val_Loss: 937.289   Train_ACC: 15.074; Val_ACC: 19.259   Train_NMI: 0.381; Val_NMI: 4.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4614 / 10000) Train_Loss: 27.532; Val_Loss: 1036.694   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 4.901\n",
      "(Epoch 4615 / 10000) Train_Loss: 26.249; Val_Loss: 1094.479   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.453; Val_NMI: 5.082\n",
      "(Epoch 4616 / 10000) Train_Loss: 25.928; Val_Loss: 1036.773   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.493; Val_NMI: 4.977\n",
      "(Epoch 4617 / 10000) Train_Loss: 27.204; Val_Loss: 1058.329   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.422; Val_NMI: 4.944\n",
      "(Epoch 4618 / 10000) Train_Loss: 27.679; Val_Loss: 1007.184   Train_ACC: 15.280; Val_ACC: 19.259   Train_NMI: 0.465; Val_NMI: 4.977\n",
      "(Epoch 4619 / 10000) Train_Loss: 30.248; Val_Loss: 1030.695   Train_ACC: 15.115; Val_ACC: 20.000   Train_NMI: 0.383; Val_NMI: 4.653\n",
      "(Epoch 4620 / 10000) Train_Loss: 27.405; Val_Loss: 1037.802   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.470; Val_NMI: 5.072\n",
      "(Epoch 4621 / 10000) Train_Loss: 25.664; Val_Loss: 995.037   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.445; Val_NMI: 5.316\n",
      "(Epoch 4622 / 10000) Train_Loss: 25.464; Val_Loss: 1018.801   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.450; Val_NMI: 5.167\n",
      "(Epoch 4623 / 10000) Train_Loss: 26.033; Val_Loss: 1013.365   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.802\n",
      "(Epoch 4624 / 10000) Train_Loss: 25.440; Val_Loss: 965.078   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.397; Val_NMI: 5.088\n",
      "(Epoch 4625 / 10000) Train_Loss: 26.281; Val_Loss: 1003.124   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.951\n",
      "(Epoch 4626 / 10000) Train_Loss: 28.638; Val_Loss: 1039.555   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.046\n",
      "(Epoch 4627 / 10000) Train_Loss: 27.527; Val_Loss: 1021.834   Train_ACC: 14.662; Val_ACC: 18.889   Train_NMI: 0.432; Val_NMI: 5.171\n",
      "(Epoch 4628 / 10000) Train_Loss: 27.587; Val_Loss: 1049.667   Train_ACC: 14.498; Val_ACC: 19.259   Train_NMI: 0.405; Val_NMI: 5.132\n",
      "(Epoch 4629 / 10000) Train_Loss: 34.451; Val_Loss: 1051.737   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.415; Val_NMI: 5.103\n",
      "(Epoch 4630 / 10000) Train_Loss: 29.455; Val_Loss: 1007.344   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.424; Val_NMI: 5.244\n",
      "(Epoch 4631 / 10000) Train_Loss: 26.515; Val_Loss: 977.050   Train_ACC: 15.074; Val_ACC: 19.630   Train_NMI: 0.452; Val_NMI: 5.402\n",
      "(Epoch 4632 / 10000) Train_Loss: 26.889; Val_Loss: 1003.310   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.399; Val_NMI: 5.410\n",
      "(Epoch 4633 / 10000) Train_Loss: 26.051; Val_Loss: 1033.099   Train_ACC: 15.404; Val_ACC: 19.259   Train_NMI: 0.433; Val_NMI: 5.018\n",
      "(Epoch 4634 / 10000) Train_Loss: 26.109; Val_Loss: 976.504   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.414; Val_NMI: 4.910\n",
      "(Epoch 4635 / 10000) Train_Loss: 29.286; Val_Loss: 1011.013   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.518; Val_NMI: 5.278\n",
      "(Epoch 4636 / 10000) Train_Loss: 30.055; Val_Loss: 1053.443   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.458; Val_NMI: 5.620\n",
      "(Epoch 4637 / 10000) Train_Loss: 27.569; Val_Loss: 986.980   Train_ACC: 15.115; Val_ACC: 19.259   Train_NMI: 0.508; Val_NMI: 4.984\n",
      "(Epoch 4638 / 10000) Train_Loss: 26.720; Val_Loss: 1039.958   Train_ACC: 14.827; Val_ACC: 19.630   Train_NMI: 0.465; Val_NMI: 5.138\n",
      "(Epoch 4639 / 10000) Train_Loss: 25.782; Val_Loss: 1019.325   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.443; Val_NMI: 4.996\n",
      "(Epoch 4640 / 10000) Train_Loss: 26.300; Val_Loss: 1021.318   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.424; Val_NMI: 4.954\n",
      "(Epoch 4641 / 10000) Train_Loss: 25.841; Val_Loss: 1054.837   Train_ACC: 14.786; Val_ACC: 20.741   Train_NMI: 0.412; Val_NMI: 4.983\n",
      "(Epoch 4642 / 10000) Train_Loss: 27.837; Val_Loss: 1036.517   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.373; Val_NMI: 4.040\n",
      "(Epoch 4643 / 10000) Train_Loss: 25.942; Val_Loss: 1105.329   Train_ACC: 14.868; Val_ACC: 20.000   Train_NMI: 0.337; Val_NMI: 4.276\n",
      "(Epoch 4644 / 10000) Train_Loss: 25.836; Val_Loss: 990.503   Train_ACC: 14.662; Val_ACC: 19.630   Train_NMI: 0.335; Val_NMI: 4.585\n",
      "(Epoch 4645 / 10000) Train_Loss: 25.369; Val_Loss: 1027.551   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.311; Val_NMI: 5.102\n",
      "(Epoch 4646 / 10000) Train_Loss: 25.004; Val_Loss: 993.730   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.420; Val_NMI: 5.389\n",
      "(Epoch 4647 / 10000) Train_Loss: 25.958; Val_Loss: 1027.771   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.400; Val_NMI: 4.481\n",
      "(Epoch 4648 / 10000) Train_Loss: 26.245; Val_Loss: 983.997   Train_ACC: 14.786; Val_ACC: 19.630   Train_NMI: 0.351; Val_NMI: 4.992\n",
      "(Epoch 4649 / 10000) Train_Loss: 26.580; Val_Loss: 1027.339   Train_ACC: 14.868; Val_ACC: 19.259   Train_NMI: 0.354; Val_NMI: 4.486\n",
      "(Epoch 4650 / 10000) Train_Loss: 25.470; Val_Loss: 963.731   Train_ACC: 14.992; Val_ACC: 20.370   Train_NMI: 0.384; Val_NMI: 5.420\n",
      "(Epoch 4651 / 10000) Train_Loss: 25.424; Val_Loss: 1017.642   Train_ACC: 14.909; Val_ACC: 20.370   Train_NMI: 0.378; Val_NMI: 5.735\n",
      "(Epoch 4652 / 10000) Train_Loss: 25.574; Val_Loss: 1054.815   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.463; Val_NMI: 5.077\n",
      "(Epoch 4653 / 10000) Train_Loss: 25.708; Val_Loss: 1040.762   Train_ACC: 15.074; Val_ACC: 20.000   Train_NMI: 0.428; Val_NMI: 5.035\n",
      "(Epoch 4654 / 10000) Train_Loss: 27.149; Val_Loss: 991.490   Train_ACC: 14.909; Val_ACC: 20.741   Train_NMI: 0.385; Val_NMI: 5.276\n",
      "(Epoch 4655 / 10000) Train_Loss: 28.637; Val_Loss: 1048.090   Train_ACC: 14.827; Val_ACC: 19.259   Train_NMI: 0.359; Val_NMI: 4.905\n",
      "(Epoch 4656 / 10000) Train_Loss: 33.817; Val_Loss: 1035.361   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 4.712\n",
      "(Epoch 4657 / 10000) Train_Loss: 33.130; Val_Loss: 1007.371   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.450; Val_NMI: 5.091\n",
      "(Epoch 4658 / 10000) Train_Loss: 29.199; Val_Loss: 1051.811   Train_ACC: 14.827; Val_ACC: 18.889   Train_NMI: 0.376; Val_NMI: 4.122\n",
      "(Epoch 4659 / 10000) Train_Loss: 28.221; Val_Loss: 1029.655   Train_ACC: 14.909; Val_ACC: 19.259   Train_NMI: 0.343; Val_NMI: 4.712\n",
      "(Epoch 4660 / 10000) Train_Loss: 26.808; Val_Loss: 1020.004   Train_ACC: 14.703; Val_ACC: 20.000   Train_NMI: 0.394; Val_NMI: 5.113\n",
      "(Epoch 4661 / 10000) Train_Loss: 26.724; Val_Loss: 1011.743   Train_ACC: 14.745; Val_ACC: 20.000   Train_NMI: 0.419; Val_NMI: 5.397\n",
      "(Epoch 4662 / 10000) Train_Loss: 26.566; Val_Loss: 986.365   Train_ACC: 14.745; Val_ACC: 19.630   Train_NMI: 0.392; Val_NMI: 5.700\n",
      "(Epoch 4663 / 10000) Train_Loss: 28.836; Val_Loss: 1015.028   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.391; Val_NMI: 5.005\n",
      "(Epoch 4664 / 10000) Train_Loss: 28.918; Val_Loss: 1069.065   Train_ACC: 14.951; Val_ACC: 20.370   Train_NMI: 0.404; Val_NMI: 5.414\n",
      "(Epoch 4665 / 10000) Train_Loss: 26.951; Val_Loss: 1045.057   Train_ACC: 14.621; Val_ACC: 20.000   Train_NMI: 0.364; Val_NMI: 5.386\n",
      "(Epoch 4666 / 10000) Train_Loss: 25.781; Val_Loss: 1020.091   Train_ACC: 14.909; Val_ACC: 20.000   Train_NMI: 0.381; Val_NMI: 5.556\n",
      "(Epoch 4667 / 10000) Train_Loss: 25.915; Val_Loss: 996.983   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.381; Val_NMI: 5.508\n",
      "(Epoch 4668 / 10000) Train_Loss: 27.628; Val_Loss: 1047.471   Train_ACC: 15.033; Val_ACC: 19.259   Train_NMI: 0.428; Val_NMI: 4.664\n",
      "(Epoch 4669 / 10000) Train_Loss: 25.968; Val_Loss: 1074.783   Train_ACC: 15.157; Val_ACC: 19.630   Train_NMI: 0.409; Val_NMI: 4.606\n",
      "(Epoch 4670 / 10000) Train_Loss: 25.350; Val_Loss: 1027.794   Train_ACC: 14.662; Val_ACC: 20.000   Train_NMI: 0.354; Val_NMI: 5.243\n",
      "(Epoch 4671 / 10000) Train_Loss: 25.222; Val_Loss: 1062.175   Train_ACC: 14.827; Val_ACC: 20.000   Train_NMI: 0.412; Val_NMI: 5.384\n",
      "(Epoch 4672 / 10000) Train_Loss: 26.096; Val_Loss: 1026.978   Train_ACC: 14.786; Val_ACC: 20.000   Train_NMI: 0.348; Val_NMI: 5.115\n",
      "(Epoch 4673 / 10000) Train_Loss: 26.517; Val_Loss: 1010.019   Train_ACC: 15.198; Val_ACC: 20.741   Train_NMI: 0.445; Val_NMI: 5.655\n",
      "(Epoch 4674 / 10000) Train_Loss: 28.096; Val_Loss: 1035.307   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.371; Val_NMI: 5.112\n",
      "(Epoch 4675 / 10000) Train_Loss: 27.995; Val_Loss: 1027.522   Train_ACC: 15.115; Val_ACC: 20.741   Train_NMI: 0.412; Val_NMI: 4.787\n",
      "(Epoch 4676 / 10000) Train_Loss: 26.559; Val_Loss: 975.273   Train_ACC: 14.992; Val_ACC: 19.630   Train_NMI: 0.412; Val_NMI: 4.528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4677 / 10000) Train_Loss: 27.071; Val_Loss: 1027.428   Train_ACC: 14.703; Val_ACC: 19.630   Train_NMI: 0.403; Val_NMI: 4.465\n",
      "(Epoch 4678 / 10000) Train_Loss: 26.044; Val_Loss: 1032.880   Train_ACC: 14.909; Val_ACC: 19.630   Train_NMI: 0.477; Val_NMI: 4.291\n",
      "(Epoch 4679 / 10000) Train_Loss: 25.129; Val_Loss: 1033.057   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.443; Val_NMI: 5.083\n",
      "(Epoch 4680 / 10000) Train_Loss: 26.031; Val_Loss: 1025.764   Train_ACC: 15.157; Val_ACC: 20.370   Train_NMI: 0.469; Val_NMI: 5.224\n",
      "(Epoch 4681 / 10000) Train_Loss: 26.808; Val_Loss: 1078.184   Train_ACC: 14.992; Val_ACC: 19.259   Train_NMI: 0.432; Val_NMI: 4.029\n",
      "(Epoch 4682 / 10000) Train_Loss: 26.164; Val_Loss: 1021.013   Train_ACC: 14.745; Val_ACC: 19.259   Train_NMI: 0.380; Val_NMI: 4.499\n",
      "(Epoch 4683 / 10000) Train_Loss: 26.486; Val_Loss: 1044.244   Train_ACC: 14.786; Val_ACC: 19.259   Train_NMI: 0.389; Val_NMI: 4.905\n",
      "(Epoch 4684 / 10000) Train_Loss: 27.487; Val_Loss: 1026.250   Train_ACC: 14.951; Val_ACC: 20.000   Train_NMI: 0.426; Val_NMI: 5.166\n",
      "(Epoch 4685 / 10000) Train_Loss: 26.690; Val_Loss: 1016.636   Train_ACC: 14.868; Val_ACC: 19.630   Train_NMI: 0.405; Val_NMI: 4.610\n",
      "(Epoch 4686 / 10000) Train_Loss: 26.257; Val_Loss: 1050.614   Train_ACC: 14.951; Val_ACC: 19.259   Train_NMI: 0.445; Val_NMI: 4.810\n",
      "(Epoch 4687 / 10000) Train_Loss: 28.949; Val_Loss: 1018.356   Train_ACC: 15.198; Val_ACC: 20.000   Train_NMI: 0.460; Val_NMI: 4.992\n",
      "(Epoch 4688 / 10000) Train_Loss: 29.364; Val_Loss: 1031.663   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.440; Val_NMI: 4.514\n",
      "(Epoch 4689 / 10000) Train_Loss: 28.194; Val_Loss: 1044.952   Train_ACC: 15.033; Val_ACC: 20.000   Train_NMI: 0.407; Val_NMI: 4.939\n",
      "(Epoch 4690 / 10000) Train_Loss: 26.534; Val_Loss: 1020.743   Train_ACC: 14.868; Val_ACC: 20.370   Train_NMI: 0.398; Val_NMI: 4.747\n",
      "(Epoch 4691 / 10000) Train_Loss: 26.089; Val_Loss: 1052.913   Train_ACC: 15.033; Val_ACC: 19.630   Train_NMI: 0.424; Val_NMI: 4.428\n",
      "(Epoch 4692 / 10000) Train_Loss: 25.421; Val_Loss: 1028.477   Train_ACC: 14.992; Val_ACC: 20.000   Train_NMI: 0.437; Val_NMI: 4.879\n",
      "(Epoch 4693 / 10000) Train_Loss: 25.299; Val_Loss: 1007.465   Train_ACC: 14.621; Val_ACC: 19.259   Train_NMI: 0.376; Val_NMI: 4.557\n",
      "(Epoch 4694 / 10000) Train_Loss: 25.505; Val_Loss: 994.435   Train_ACC: 14.951; Val_ACC: 19.630   Train_NMI: 0.422; Val_NMI: 4.747\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c1591b0c583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgmvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/gmvae_and_gmmvae/smba_gmvae_8/pytorch/model/GMVAE.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gauss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_nmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m       \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_gauss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_nmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gmvae_and_gmmvae/smba_gmvae_8/pytorch/model/GMVAE.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, optimizer, data_loader)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0;31m# perform backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m       \u001b[0mtotal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gmvae.train(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gmvae.network.state_dict(), f'smba_gmvae_8_{num_epochs}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmvae.network.load_state_dict(torch.load('smba_gmvae_8.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('training_history.json', 'w+') as json_f:\n",
    "#     json.dump(history_loss, json_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bHWNxV-gAl2"
   },
   "source": [
    "## Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "wd5jQFFHgCbD",
    "outputId": "8e1d4654-fb01-49dc-b512-e8e4bb259e0f"
   },
   "outputs": [],
   "source": [
    "original, reconstructed = gmvae.reconstruct_data(train_dl, 15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_int = original.reshape(15, 16, 16, 12).argmax(axis=-1)\n",
    "reconstructed_int = reconstructed.reshape(15, 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(chunks_int):\n",
    "    classes = []\n",
    "    for i in chunks_int:\n",
    "        if i.max() == 6:\n",
    "            classes.append('kia')\n",
    "        else:\n",
    "            classes.append('smba')\n",
    "    return np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_classes = get_classes(original_int)\n",
    "rec_classes = get_classes(reconstructed_int)\n",
    "assert np.sum(org_classes == rec_classes) == len(org_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(chunks_int):\n",
    "    images = []\n",
    "    for game, chunk in zip(get_classes(chunks_int), chunks_int):\n",
    "        images.append(vglc_with_path_encodings.array_to_image([chunk], game=game)[0])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_images = get_images(original_int)\n",
    "rec_images = get_images(reconstructed_int)\n",
    "len(org_images), len(rec_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x576 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=10, figsize=(24, 8))\n",
    "axes = axes.flatten()\n",
    "nrows, ncols = 3, 10\n",
    "\n",
    "org_idxs = np.arange(0, 29, 2)\n",
    "rec_idxs = org_idxs + 1\n",
    "\n",
    "for idx in org_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(org_images[idx // 2]))\n",
    "    ax.set_title(f'Org {idx // 2 + 1}')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "for idx in rec_idxs:\n",
    "        \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.imshow(np.asarray(rec_images[idx // 2]))\n",
    "    ax.set_title(f'Rec {idx // 2 + 1}')\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAyoGFFRgMgC"
   },
   "source": [
    "## Random Generation per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "xE84c3U2gLjA",
    "outputId": "cd52f356-e53a-4844-9db2-3723d15ddb00"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 64 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_random_generation(generated, num_classes, n=10):\n",
    "    plt.figure(figsize=[24,24])\n",
    "    for c in range(num_classes):\n",
    "        for i in range(n):\n",
    "            plt.subplot(num_classes, n, (c * n) + i + 1)\n",
    "            chunk_int = generated[(c * n) + i].reshape(16, 16, 12).argmax(axis=-1)\n",
    "            chunk_pix = vglc_with_path_encodings.array_to_image([chunk_int], game='smba')[0]\n",
    "            plt.imshow(chunk_pix)\n",
    "            plt.gray()\n",
    "            plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "elem_per_category = 8\n",
    "generated = gmvae.random_generation(elem_per_category)\n",
    "display_random_generation(generated, args.num_classes, elem_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_per_category = 10000 // 8\n",
    "generated = gmvae.random_generation(elem_per_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_int = generated.reshape(-1, 16, 16, 12).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 16)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since this code chunk depends on random seed, it shouldn't be run again\n",
    "# with open('../smba_generations/smba_gmvae_8.json', 'w+') as json_f:\n",
    "#     json.dump(generated_int.tolist(), json_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SbXR7FkhIcq"
   },
   "source": [
    "## Visualization of the feature latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTkEBA9JhQ2C"
   },
   "outputs": [],
   "source": [
    "# get feature representations\n",
    "test_features, test_labels = gmvae.latent_features(train_dl, return_learned_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150, 258, 270, 445, 431, 201, 335, 338])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNmsz5rahZAY"
   },
   "outputs": [],
   "source": [
    "# import TSNE from scikit-learn library\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# reduce dimensionality to 2D, we consider a subset of data because TSNE\n",
    "# is a slow algorithm\n",
    "\n",
    "first_n = 1000\n",
    "tsne_features = TSNE(n_components=2).fit_transform(test_features[:first_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_subset = test_labels[:first_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, Y_ = np.s_[:,0], np.s_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "wyTtDdwyha-L",
    "outputId": "350e806a-6dd3-47f2-bd91-444aaf61b3dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.scatter(tsne_features[X_], tsne_features[Y_])\n",
    "\n",
    "plt.title('Projection from latent space to 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GMVAE_Pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
